{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udfac Movie Genie Documentation","text":"<p>Welcome to the comprehensive documentation for Movie Genie - an AI-powered movie recommendation system that demonstrates modern ML engineering and full-stack development best practices.</p> <p></p> <p>Movie Genie is a complete movie recommendation system that showcases:</p> <ul> <li>\ud83e\udde0 Advanced ML Models: BERT4Rec, Two-Tower, and Semantic Search</li> <li>\ud83c\udf10 Full-Stack Integration: React frontend + Flask backend</li> <li>\ud83d\udd04 MLOps Pipeline: DVC-managed data and model workflows</li> <li>\ud83d\udcca Production Ready: Docker deployment and monitoring</li> </ul> <p>This project serves as both a functional recommendation system and a comprehensive learning reference for building modern ML applications.</p>"},{"location":"#quick-navigation","title":"\ud83d\ude80 Quick Navigation","text":"<ul> <li> <p> Getting Started</p> <p>New to Movie Genie? Start here for setup and overview.</p> <p> Quick Start</p> </li> <li> <p> Machine Learning</p> <p>Deep dive into recommendation models and ML architecture.</p> <p> ML Models</p> </li> <li> <p> Data Pipeline</p> <p>Learn about data processing and DVC workflows.</p> <p> Data Pipeline</p> </li> <li> <p> Backend &amp; Frontend</p> <p>Full-stack development and ML integration patterns.</p> <p> Architecture</p> </li> <li> <p> Deployment</p> <p>Deploy Movie Genie to development and production.</p> <p> Deploy</p> </li> <li> <p> Troubleshooting</p> <p>Solve common issues and debug problems.</p> <p> Help</p> </li> </ul>"},{"location":"#what-youll-learn","title":"\ud83c\udfaf What You'll Learn","text":"<p>After working through this documentation, you'll understand:</p>"},{"location":"#machine-learning-engineering","title":"Machine Learning Engineering","text":"<ul> <li> Model Architecture: Transformer-based recommendations</li> <li> Training Pipelines: Reproducible ML workflows</li> <li> Model Evaluation: Performance metrics and comparison</li> <li> Production ML: Serving models in web applications</li> </ul>"},{"location":"#full-stack-development","title":"Full-Stack Development","text":"<ul> <li> API Design: RESTful services for ML applications</li> <li> Frontend Integration: Connect ML outputs to UI</li> <li> State Management: Handle complex application state</li> <li> Performance: Optimize for real-time experience</li> </ul>"},{"location":"#mlops-devops","title":"MLOps &amp; DevOps","text":"<ul> <li> Data Versioning: Track datasets and model artifacts</li> <li> Pipeline Automation: Reproducible workflows</li> <li> Environment Management: Consistent deployments</li> <li> Monitoring: System health and model performance</li> </ul>"},{"location":"#system-architecture","title":"\ud83c\udfd7\ufe0f System Architecture","text":"<pre><code>graph TB\n    A[User Interface - React] --&gt; B[Backend API - Flask]\n    B --&gt; C[ML Services]\n    B --&gt; D[Database - SQLite]\n    C --&gt; E[BERT4Rec Model]\n    C --&gt; F[Two-Tower Model]\n    C --&gt; G[Semantic Search]\n    H[DVC Pipeline] --&gt; I[Data Processing]\n    I --&gt; J[Model Training]\n    J --&gt; E\n    J --&gt; F\n    J --&gt; G</code></pre>"},{"location":"#key-technologies","title":"\ud83d\udcca Key Technologies","text":"Category Technology Purpose Frontend React + TypeScript Modern, responsive UI Backend Flask + Python RESTful API server ML Models PyTorch + Transformers BERT4Rec, Two-Tower models Search Sentence Transformers Semantic movie search Data Pipeline DVC + Pandas Data versioning &amp; processing Database SQLite Movie and user data storage Deployment Docker + Gunicorn Production deployment"},{"location":"#quick-start","title":"\u26a1 Quick Start","text":"<p>Get Movie Genie running in 5 minutes:</p> <pre><code># 1. Clone and install\ngit clone &lt;repository-url&gt;\ncd movie-genie\npip install -e .\n\n# 2. Run the complete pipeline\ndvc repro\n\n# 3. Access the application\n# Open browser to: http://127.0.0.1:5001\n</code></pre> <p>That's it!</p> <p>Choose a user ID (1-610) and start exploring AI-powered movie recommendations.</p>"},{"location":"#documentation-structure","title":"\ud83d\udcda Documentation Structure","text":"<p>The documentation is organized into logical sections for progressive learning:</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Essential guides to get you up and running quickly.</p>"},{"location":"#machine-learning","title":"Machine Learning","text":"<p>Comprehensive coverage of all ML models and techniques.</p>"},{"location":"#data-pipeline","title":"Data Pipeline","text":"<p>Data processing, feature engineering, and DVC workflows.</p>"},{"location":"#backend-frontend","title":"Backend &amp; Frontend","text":"<p>Full-stack architecture and integration patterns.</p>"},{"location":"#configuration","title":"Configuration","text":"<p>Environment setup and configuration management.</p>"},{"location":"#troubleshooting","title":"Troubleshooting","text":"<p>Common issues, debugging, and problem solving.</p>"},{"location":"#reference","title":"Reference","text":"<p>Technical reference, APIs, and implementation details.</p>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>This is a learning project, but contributions are welcome:</p> <ol> <li>Documentation: Improve clarity or add missing information</li> <li>Examples: Add more use cases or integration examples</li> <li>Models: Implement additional recommendation algorithms</li> <li>Features: Enhance the UI or add new functionality</li> </ol>"},{"location":"#external-links","title":"\ud83d\udd17 External Links","text":"<ul> <li> GitHub Repository</li> <li> Python Package</li> <li> Paper</li> </ul> <p>Learning Path</p> <p>New to recommendation systems? Start with Project Overview to understand the big picture, then follow the Quick Start guide.</p> <p>Need Help?</p> <p>Check the Troubleshooting section for common issues, or open an issue on GitHub for project-specific questions.</p> <p>Movie Genie demonstrates modern ML engineering practices in a complete, working application. Perfect for learning recommendation systems, full-stack development, and MLOps workflows. \ud83c\udfac</p>"},{"location":"commands/","title":"Commands","text":""},{"location":"commands/#database-test","title":"database test","text":"<p><code>rm -f movie_genie.db*  # Remove any existing database files python test_db.py</code></p>"},{"location":"commands/#running-scrapper","title":"running scrapper","text":"<p><code>python scripts/imdb_featured_reviews.py \\   --links-csv data/raw/ml-100k/links.csv \\   --limit 25 \\   --out data/raw/imdb-reviews/ml-100k_reviews.csv \\   --lang en \\   --min-delay 0.05 \\   --max-delay 0.1 \\   --checkpoint data/raw/imdb-reviews/ml-100k_checkpoint.json \\   --filter-by-movies</code></p>"},{"location":"backend-frontend/","title":"\ud83c\udf10 Backend &amp; Frontend Architecture","text":"<p>Complete guide to Movie Genie's full-stack architecture, from Flask API design to React frontend integration.</p>"},{"location":"backend-frontend/#architecture-overview","title":"\ud83c\udfaf Architecture Overview","text":"<p>Movie Genie follows a modern full-stack architecture with clear separation of concerns:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    HTTP/REST    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Frontend      \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502    Backend      \u2502\n\u2502   (React TS)    \u2502    JSON API     \u2502    (Flask)      \u2502\n\u2502                 \u2502                 \u2502                 \u2502\n\u2502 \u2022 Components    \u2502                 \u2502 \u2022 API Endpoints \u2502\n\u2502 \u2022 State Mgmt    \u2502                 \u2502 \u2022 Business Logic\u2502\n\u2502 \u2022 Data Services \u2502                 \u2502 \u2022 ML Integration\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                                   \u2502\n         \u2502                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502                          \u2502   Database      \u2502\n         \u2502                          \u2502   (SQLite)      \u2502\n         \u2502                          \u2502                 \u2502\n         \u2502                          \u2502 \u2022 Movies        \u2502\n         \u2502                          \u2502 \u2022 Ratings       \u2502\n         \u2502                          \u2502 \u2022 Users         \u2502\n         \u2502                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502   ML Models     \u2502\n                  Via API           \u2502   (PyTorch)     \u2502\n                                    \u2502                 \u2502\n                                    \u2502 \u2022 BERT4Rec      \u2502\n                                    \u2502 \u2022 Two-Tower     \u2502\n                                    \u2502 \u2022 Semantic      \u2502\n                                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"backend-frontend/#documentation-sections","title":"\ud83d\udccb Documentation Sections","text":""},{"location":"backend-frontend/#backend-integration","title":"\ud83d\udd27 Backend Integration","text":"<p>Perfect for: Understanding Flask API development and ML model integration - Flask application structure and blueprints - Database models and queries - Service layer design patterns - Error handling and logging</p>"},{"location":"backend-frontend/#ml-integration","title":"\ud83e\udd16 ML Integration","text":"<p>Perfect for: Connecting ML models to web applications - Model loading and inference - API endpoint design for ML services - Real/mock data switching for development - Performance optimization and caching</p>"},{"location":"backend-frontend/#api-reference","title":"\ud83d\udcda API Reference","text":"<p>Perfect for: Complete API documentation and testing - All endpoint specifications - Request/response formats - Authentication and error codes - Example API calls and responses</p>"},{"location":"backend-frontend/#frontend-components","title":"\ud83c\udfa8 Frontend Components","text":"<p>Perfect for: React development and UI architecture - Component hierarchy and props - State management patterns - Styling with Tailwind CSS - TypeScript integration</p>"},{"location":"backend-frontend/#backend-architecture","title":"\ud83c\udfd7\ufe0f Backend Architecture","text":""},{"location":"backend-frontend/#flask-application-structure","title":"Flask Application Structure","text":"<pre><code>movie_genie/backend/\n\u251c\u2500\u2500 app.py                 # Main Flask application\n\u251c\u2500\u2500 config.py             # Configuration settings\n\u251c\u2500\u2500 movie_genie.db        # SQLite database\n\u251c\u2500\u2500 app/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 api/              # API blueprints\n\u2502   \u2502   \u251c\u2500\u2500 movies.py     # Movie endpoints\n\u2502   \u2502   \u251c\u2500\u2500 search.py     # Search endpoints\n\u2502   \u2502   \u251c\u2500\u2500 recommendations.py # Recommendation endpoints\n\u2502   \u2502   \u2514\u2500\u2500 users.py      # User endpoints\n\u2502   \u251c\u2500\u2500 services/         # Business logic\n\u2502   \u2502   \u251c\u2500\u2500 movie_service.py\n\u2502   \u2502   \u251c\u2500\u2500 search_service.py\n\u2502   \u2502   \u251c\u2500\u2500 recommendation_service.py\n\u2502   \u2502   \u2514\u2500\u2500 user_service.py\n\u2502   \u251c\u2500\u2500 models/           # Database models\n\u2502   \u2502   \u251c\u2500\u2500 movie.py\n\u2502   \u2502   \u251c\u2500\u2500 rating.py\n\u2502   \u2502   \u2514\u2500\u2500 user.py\n\u2502   \u2514\u2500\u2500 utils/            # Utility functions\n\u2502       \u251c\u2500\u2500 ml_loader.py\n\u2502       \u2514\u2500\u2500 validators.py\n\u251c\u2500\u2500 templates/            # Static assets served by Flask\n\u2502   \u251c\u2500\u2500 index.html        # React app entry point\n\u2502   \u251c\u2500\u2500 favicon.ico\n\u2502   \u2514\u2500\u2500 assets/           # Built frontend assets\n\u2514\u2500\u2500 logs/                 # Application logs\n</code></pre>"},{"location":"backend-frontend/#api-design-principles","title":"API Design Principles","text":"<ul> <li>RESTful Routes: Standard HTTP methods and resource naming</li> <li>JSON Responses: Consistent response format with success/error handling</li> <li>Service Layer: Business logic separated from route handlers</li> <li>Error Handling: Comprehensive error messages and status codes</li> <li>Validation: Input validation and sanitization</li> <li>Documentation: Clear endpoint documentation with examples</li> </ul>"},{"location":"backend-frontend/#database-schema","title":"Database Schema","text":"<pre><code>-- Core entities\nCREATE TABLE movies (\n    id INTEGER PRIMARY KEY,\n    title TEXT NOT NULL,\n    genres TEXT,\n    release_date DATE,\n    overview TEXT,\n    poster_path TEXT,\n    vote_average REAL\n);\n\nCREATE TABLE users (\n    id INTEGER PRIMARY KEY,\n    age INTEGER,\n    gender TEXT,\n    occupation TEXT\n);\n\nCREATE TABLE ratings (\n    user_id INTEGER,\n    movie_id INTEGER,\n    rating INTEGER,\n    timestamp INTEGER,\n    FOREIGN KEY (user_id) REFERENCES users(id),\n    FOREIGN KEY (movie_id) REFERENCES movies(id)\n);\n</code></pre>"},{"location":"backend-frontend/#frontend-architecture","title":"\ud83c\udfa8 Frontend Architecture","text":""},{"location":"backend-frontend/#react-application-structure","title":"React Application Structure","text":"<pre><code>movie_genie/frontend/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 components/       # Reusable UI components\n\u2502   \u2502   \u251c\u2500\u2500 UserSelectionModal.tsx\n\u2502   \u2502   \u251c\u2500\u2500 MovieSearch.tsx\n\u2502   \u2502   \u251c\u2500\u2500 SearchResultsGrid.tsx\n\u2502   \u2502   \u251c\u2500\u2500 MovieThumbnail.tsx\n\u2502   \u2502   \u251c\u2500\u2500 RecommendationCarousel.tsx\n\u2502   \u2502   \u2514\u2500\u2500 MovieDetailsPanel.tsx\n\u2502   \u251c\u2500\u2500 services/         # Data access layer\n\u2502   \u2502   \u251c\u2500\u2500 movieDataService.ts\n\u2502   \u2502   \u2514\u2500\u2500 api.ts\n\u2502   \u251c\u2500\u2500 lib/              # Utilities and helpers\n\u2502   \u2502   \u251c\u2500\u2500 api.ts\n\u2502   \u2502   \u2514\u2500\u2500 mockData.ts\n\u2502   \u251c\u2500\u2500 types/            # TypeScript type definitions\n\u2502   \u2502   \u2514\u2500\u2500 movie.ts\n\u2502   \u251c\u2500\u2500 styles/           # CSS and styling\n\u2502   \u2502   \u2514\u2500\u2500 index.css\n\u2502   \u251c\u2500\u2500 App.tsx           # Main application component\n\u2502   \u251c\u2500\u2500 main.tsx          # Application entry point\n\u2502   \u2514\u2500\u2500 vite-env.d.ts     # Vite type definitions\n\u251c\u2500\u2500 public/               # Static assets\n\u251c\u2500\u2500 dist/                 # Built application (production)\n\u251c\u2500\u2500 package.json          # Dependencies and scripts\n\u251c\u2500\u2500 vite.config.ts        # Vite configuration\n\u251c\u2500\u2500 tailwind.config.js    # Tailwind CSS configuration\n\u2514\u2500\u2500 tsconfig.json         # TypeScript configuration\n</code></pre>"},{"location":"backend-frontend/#component-architecture","title":"Component Architecture","text":"<pre><code>// Component hierarchy\nApp\n\u251c\u2500\u2500 UserSelectionModal     // User authentication\n\u251c\u2500\u2500 MovieSearch           // Search interface\n\u251c\u2500\u2500 SearchResultsGrid     // Search results display\n\u2502   \u2514\u2500\u2500 MovieThumbnail[]  // Individual movie cards\n\u251c\u2500\u2500 RecommendationCarousel // Personalized suggestions\n\u2502   \u2514\u2500\u2500 MovieThumbnail[]  // Movie cards in carousel\n\u2514\u2500\u2500 MovieDetailsPanel     // Detailed movie information\n    \u2514\u2500\u2500 MovieThumbnail[]  // Similar movies\n</code></pre>"},{"location":"backend-frontend/#state-management","title":"State Management","text":"<pre><code>// Application state structure\ninterface AppState {\n  currentUser: UserInfo | null;\n  searchQuery: string;\n  searchResults: MovieData[];\n  isSearching: boolean;\n  selectedMovie: MovieData | null;\n  popularMovies: MovieData[];\n  recommendations: MovieData[];\n  loading: {\n    popular: boolean;\n    search: boolean;\n    recommendations: boolean;\n  };\n  errors: {\n    [key: string]: string | null;\n  };\n}\n</code></pre>"},{"location":"backend-frontend/#data-flow-patterns","title":"\ud83d\udd04 Data Flow Patterns","text":""},{"location":"backend-frontend/#api-request-flow","title":"API Request Flow","text":"<pre><code>// 1. User Action (e.g., search)\nconst handleSearch = async (query: string) =&gt; {\n  setIsSearching(true);\n\n  try {\n    // 2. Service Layer Call\n    const results = await MovieDataService.searchMovies(query);\n\n    // 3. State Update\n    setSearchResults(results.movies);\n    setIsSearching(false);\n  } catch (error) {\n    // 4. Error Handling\n    setError('Search failed');\n    setIsSearching(false);\n  }\n};\n\n// Service Layer Implementation\nexport class MovieDataService {\n  static async searchMovies(query: string): Promise&lt;SearchResults&gt; {\n    // 5. API Call\n    const response = await fetch(`${API_URL}/search/semantic?q=${query}`);\n    const data = await response.json();\n\n    // 6. Data Transformation\n    if (data.success) {\n      return {\n        movies: data.data.movies.map(this.transformApiMovie),\n        total: data.data.total,\n        query\n      };\n    }\n\n    throw new Error(data.message);\n  }\n}\n</code></pre>"},{"location":"backend-frontend/#realmock-data-switching","title":"Real/Mock Data Switching","text":"<pre><code>// Environment-controlled data sources\nconst DATA_SOURCE_CONFIG = {\n  popular: import.meta.env.VITE_USE_REAL_POPULAR === 'true',\n  search: import.meta.env.VITE_USE_REAL_SEARCH === 'true',\n  recommendations: import.meta.env.VITE_USE_REAL_RECOMMENDATIONS === 'true',\n  movieDetails: import.meta.env.VITE_USE_REAL_MOVIE_DETAILS === 'true'\n};\n\n// Service method with fallback\nstatic async getPopularMovies(limit: number = 20): Promise&lt;MovieData[]&gt; {\n  if (DATA_SOURCE_CONFIG.popular) {\n    try {\n      // Try real API first\n      const response = await fetch(`${API_URL}/movies/popular?limit=${limit}`);\n      const data = await response.json();\n\n      if (data.success) {\n        return data.data.movies.map(this.transformApiMovie);\n      }\n    } catch (error) {\n      console.warn('Real API failed, falling back to mock data:', error);\n    }\n  }\n\n  // Fallback to mock data\n  return this.getMockPopularMovies(limit);\n}\n</code></pre>"},{"location":"backend-frontend/#development-workflow","title":"\ud83d\udd27 Development Workflow","text":""},{"location":"backend-frontend/#backend-development","title":"Backend Development","text":"<pre><code># Start backend development server\ncd movie_genie/backend\npython app.py\n\n# Test API endpoints\ncurl http://127.0.0.1:5001/api/health\ncurl http://127.0.0.1:5001/api/movies/popular\n\n# Run backend tests\npytest movie_genie/backend/tests/\n\n# Format code\nblack movie_genie/backend/\n</code></pre>"},{"location":"backend-frontend/#frontend-development","title":"Frontend Development","text":"<pre><code># Start frontend development server\ncd movie_genie/frontend\nnpm run dev\n\n# Open browser to http://localhost:5173\n# Hot reload enabled for development\n\n# Run frontend tests\nnpm test\n\n# Build for production\nnpm run build\n</code></pre>"},{"location":"backend-frontend/#full-stack-development","title":"Full-Stack Development","text":"<pre><code># Terminal 1: Backend\ncd movie_genie/backend &amp;&amp; python app.py\n\n# Terminal 2: Frontend\ncd movie_genie/frontend &amp;&amp; npm run dev\n\n# Or use DVC pipeline for integrated setup\ndvc repro backend_server\n</code></pre>"},{"location":"backend-frontend/#production-deployment","title":"\ud83d\ude80 Production Deployment","text":""},{"location":"backend-frontend/#build-process","title":"Build Process","text":"<pre><code># 1. Build frontend\ncd movie_genie/frontend\nnpm run build\n\n# 2. Copy built assets to backend\ncp -r dist/* ../backend/templates/\n\n# 3. Start production server\ncd ../backend\ngunicorn -w 4 -b 0.0.0.0:5001 app:app\n</code></pre>"},{"location":"backend-frontend/#docker-deployment","title":"Docker Deployment","text":"<pre><code># Multi-stage Docker build\nFROM node:16 AS frontend-build\nWORKDIR /app/frontend\nCOPY movie_genie/frontend/package*.json ./\nRUN npm install\nCOPY movie_genie/frontend/ ./\nRUN npm run build\n\nFROM python:3.9-slim AS backend\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY movie_genie/backend/ ./backend/\nCOPY --from=frontend-build /app/frontend/dist/ ./backend/templates/\nEXPOSE 5001\nCMD [\"gunicorn\", \"-w\", \"4\", \"-b\", \"0.0.0.0:5001\", \"backend.app:app\"]\n</code></pre>"},{"location":"backend-frontend/#performance-considerations","title":"\ud83d\udcca Performance Considerations","text":""},{"location":"backend-frontend/#backend-optimization","title":"Backend Optimization","text":"<ul> <li>Database Indexing: Optimize queries with proper indexes</li> <li>Caching: Use Redis for frequently accessed data</li> <li>Connection Pooling: Manage database connections efficiently</li> <li>Async Processing: Use Celery for background tasks</li> </ul>"},{"location":"backend-frontend/#frontend-optimization","title":"Frontend Optimization","text":"<ul> <li>Code Splitting: Load components on demand</li> <li>Image Optimization: Compress and lazy-load images</li> <li>Bundle Analysis: Monitor and optimize bundle size</li> <li>Service Workers: Cache API responses and assets</li> </ul>"},{"location":"backend-frontend/#api-performance","title":"API Performance","text":"<pre><code># Example caching implementation\nfrom functools import lru_cache\n\n@lru_cache(maxsize=1000)\ndef get_popular_movies(limit: int) -&gt; List[Dict]:\n    \"\"\"Cache popular movies for 5 minutes\"\"\"\n    return movie_service.get_popular_movies(limit)\n\n# Rate limiting\nfrom flask_limiter import Limiter\n\nlimiter = Limiter(\n    app,\n    key_func=get_remote_address,\n    default_limits=[\"100 per hour\"]\n)\n\n@app.route('/api/search')\n@limiter.limit(\"10 per minute\")\ndef search_movies():\n    pass\n</code></pre>"},{"location":"backend-frontend/#testing-strategy","title":"\ud83d\udd0d Testing Strategy","text":""},{"location":"backend-frontend/#backend-testing","title":"Backend Testing","text":"<pre><code># Unit tests for services\ndef test_movie_service_get_popular():\n    service = MovieService()\n    movies = service.get_popular_movies(limit=10)\n    assert len(movies) &lt;= 10\n    assert all('title' in movie for movie in movies)\n\n# Integration tests for API\ndef test_api_popular_movies(client):\n    response = client.get('/api/movies/popular?limit=5')\n    assert response.status_code == 200\n    data = response.get_json()\n    assert data['success'] is True\n    assert len(data['data']) &lt;= 5\n</code></pre>"},{"location":"backend-frontend/#frontend-testing","title":"Frontend Testing","text":"<pre><code>// Component tests\nimport { render, screen } from '@testing-library/react';\nimport { MovieThumbnail } from './MovieThumbnail';\n\ntest('renders movie title', () =&gt; {\n  const movie = { id: '1', title: 'Test Movie', genres: [] };\n  render(&lt;MovieThumbnail movie={movie} /&gt;);\n  expect(screen.getByText('Test Movie')).toBeInTheDocument();\n});\n\n// Integration tests\ntest('search functionality', async () =&gt; {\n  render(&lt;App /&gt;);\n  const searchInput = screen.getByPlaceholderText('Search movies...');\n  fireEvent.change(searchInput, { target: { value: 'action' } });\n  fireEvent.keyDown(searchInput, { key: 'Enter' });\n\n  await waitFor(() =&gt; {\n    expect(screen.getByText('Search Results')).toBeInTheDocument();\n  });\n});\n</code></pre> <p>This architecture provides a scalable, maintainable foundation for modern full-stack ML applications. Each layer is designed to be modular, testable, and easy to extend. \ud83c\udf10</p>"},{"location":"backend-frontend/api-reference/","title":"\ud83d\udcda API Reference","text":"<p>Complete documentation for Movie Genie's REST API endpoints, including request/response formats, authentication, and examples.</p>"},{"location":"backend-frontend/api-reference/#api-overview","title":"\ud83c\udf10 API Overview","text":"<p>Base URL: <code>http://127.0.0.1:5001/api</code></p> <p>Content Type: <code>application/json</code></p> <p>Response Format: All endpoints return JSON with the following structure: <pre><code>{\n  \"success\": boolean,\n  \"message\": string,\n  \"data\": object | array | null,\n  \"timestamp\": string (ISO 8601)\n}\n</code></pre></p>"},{"location":"backend-frontend/api-reference/#system-endpoints","title":"\ud83d\udd27 System Endpoints","text":""},{"location":"backend-frontend/api-reference/#health-check","title":"Health Check","text":"<p>Check if the API server is running and healthy.</p>"},{"location":"backend-frontend/api-reference/#get-health","title":"<code>GET /health</code>","text":"<p>Description: Returns the current system status and health information.</p> <p>Parameters: None</p> <p>Response: <pre><code>{\n  \"success\": true,\n  \"message\": \"System is healthy\",\n  \"data\": {\n    \"status\": \"healthy\",\n    \"version\": \"1.0.0\",\n    \"uptime\": 3600,\n    \"models_loaded\": {\n      \"bert4rec\": true,\n      \"two_tower\": true,\n      \"semantic_search\": true\n    },\n    \"database_status\": \"connected\"\n  },\n  \"timestamp\": \"2024-01-01T12:00:00.000Z\"\n}\n</code></pre></p> <p>Example: <pre><code>curl http://127.0.0.1:5001/api/health\n</code></pre></p>"},{"location":"backend-frontend/api-reference/#user-endpoints","title":"\ud83d\udc65 User Endpoints","text":""},{"location":"backend-frontend/api-reference/#get-user-information","title":"Get User Information","text":"<p>Retrieve information about a specific user or current user context.</p>"},{"location":"backend-frontend/api-reference/#get-usersinfo","title":"<code>GET /users/info</code>","text":"<p>Description: Returns user information and statistics.</p> <p>Parameters: - <code>user_id</code> (query, optional): Specific user ID to query (1-610)</p> <p>Response: <pre><code>{\n  \"success\": true,\n  \"message\": \"User information retrieved successfully\",\n  \"data\": {\n    \"current_user\": 123,\n    \"total_users\": 943,\n    \"user_range\": {\n      \"min\": 1,\n      \"max\": 610\n    },\n    \"user_stats\": {\n      \"ratings_count\": 150,\n      \"avg_rating\": 3.8,\n      \"favorite_genres\": [\"Action\", \"Sci-Fi\"],\n      \"last_activity\": \"2024-01-01T10:30:00.000Z\"\n    }\n  },\n  \"timestamp\": \"2024-01-01T12:00:00.000Z\"\n}\n</code></pre></p> <p>Example: <pre><code># Get general user info\ncurl http://127.0.0.1:5001/api/users/info\n\n# Get specific user info\ncurl \"http://127.0.0.1:5001/api/users/info?user_id=123\"\n</code></pre></p>"},{"location":"backend-frontend/api-reference/#movie-endpoints","title":"\ud83c\udfac Movie Endpoints","text":""},{"location":"backend-frontend/api-reference/#get-popular-movies","title":"Get Popular Movies","text":"<p>Retrieve a list of popular movies with optional personalization.</p>"},{"location":"backend-frontend/api-reference/#get-moviespopular","title":"<code>GET /movies/popular</code>","text":"<p>Description: Returns popular movies, optionally personalized for a specific user.</p> <p>Parameters: - <code>limit</code> (query, optional): Number of movies to return (default: 20, max: 100) - <code>user_id</code> (query, optional): User ID for personalization (1-610)</p> <p>Response: <pre><code>{\n  \"success\": true,\n  \"message\": \"Retrieved 20 popular movies\",\n  \"data\": {\n    \"movies\": [\n      {\n        \"movieId\": 1,\n        \"title\": \"Toy Story\",\n        \"genres\": [\"Animation\", \"Children's\", \"Comedy\"],\n        \"poster_path\": \"/w4pJJ6VsZPNHdKJxCZZLfYRyPac.jpg\",\n        \"vote_average\": 8.3,\n        \"release_date\": \"1995-10-30\",\n        \"overview\": \"A cowboy doll is profoundly threatened...\",\n        \"runtime\": 81,\n        \"personalized_score\": 0.92,\n        \"rank\": 1\n      }\n    ],\n    \"total\": 20,\n    \"recommendation_type\": \"popular\",\n    \"personalized\": true,\n    \"user_context\": {\n      \"user_id\": \"123\",\n      \"model_used\": \"two_tower\",\n      \"inference_time\": 15\n    }\n  },\n  \"timestamp\": \"2024-01-01T12:00:00.000Z\"\n}\n</code></pre></p> <p>Example: <pre><code># Get popular movies\ncurl \"http://127.0.0.1:5001/api/movies/popular?limit=10\"\n\n# Get personalized popular movies\ncurl \"http://127.0.0.1:5001/api/movies/popular?limit=10&amp;user_id=123\"\n</code></pre></p>"},{"location":"backend-frontend/api-reference/#get-movie-details","title":"Get Movie Details","text":"<p>Retrieve detailed information about a specific movie.</p>"},{"location":"backend-frontend/api-reference/#get-moviesmovie_id","title":"<code>GET /movies/{movie_id}</code>","text":"<p>Description: Returns comprehensive movie information including similar movies.</p> <p>Parameters: - <code>movie_id</code> (path): Movie ID (integer) - <code>user_id</code> (query, optional): User ID for personalized similar movies</p> <p>Response: <pre><code>{\n  \"success\": true,\n  \"message\": \"Movie details retrieved successfully\",\n  \"data\": {\n    \"movieId\": 1,\n    \"title\": \"Toy Story\",\n    \"genres\": [\"Animation\", \"Children's\", \"Comedy\"],\n    \"poster_path\": \"/w4pJJ6VsZPNHdKJxCZZLfYRyPac.jpg\",\n    \"vote_average\": 8.3,\n    \"release_date\": \"1995-10-30\",\n    \"overview\": \"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\",\n    \"runtime\": 81,\n    \"director\": \"John Lasseter\",\n    \"cast\": [\"Tom Hanks\", \"Tim Allen\", \"Don Rickles\"],\n    \"similar_movies\": [\n      {\n        \"movieId\": 2,\n        \"title\": \"Jumanji\",\n        \"similarity_score\": 0.85,\n        \"genres\": [\"Adventure\", \"Children's\", \"Fantasy\"]\n      }\n    ],\n    \"ml_enhanced\": true\n  },\n  \"timestamp\": \"2024-01-01T12:00:00.000Z\"\n}\n</code></pre></p> <p>Example: <pre><code># Get movie details\ncurl http://127.0.0.1:5001/api/movies/1\n\n# Get movie details with personalized similar movies\ncurl \"http://127.0.0.1:5001/api/movies/1?user_id=123\"\n</code></pre></p>"},{"location":"backend-frontend/api-reference/#search-endpoints","title":"\ud83d\udd0d Search Endpoints","text":""},{"location":"backend-frontend/api-reference/#semantic-search","title":"Semantic Search","text":"<p>Search for movies using natural language queries.</p>"},{"location":"backend-frontend/api-reference/#get-searchsemantic","title":"<code>GET /search/semantic</code>","text":"<p>Description: Performs semantic search using ML-powered text embeddings.</p> <p>Parameters: - <code>q</code> (query, required): Search query string - <code>limit</code> (query, optional): Number of results to return (default: 20, max: 50) - <code>user_id</code> (query, optional): User ID for personalized ranking</p> <p>Response: <pre><code>{\n  \"success\": true,\n  \"message\": \"Semantic search completed successfully\",\n  \"data\": {\n    \"movies\": [\n      {\n        \"movieId\": 1,\n        \"title\": \"Toy Story\",\n        \"overview\": \"A cowboy doll is profoundly threatened...\",\n        \"genres\": [\"Animation\", \"Children's\", \"Comedy\"],\n        \"poster_path\": \"/w4pJJ6VsZPNHdKJxCZZLfYRyPac.jpg\",\n        \"vote_average\": 8.3,\n        \"similarity_score\": 0.95,\n        \"rank\": 1\n      }\n    ],\n    \"total\": 15,\n    \"query\": \"animated movies for kids\",\n    \"search_type\": \"semantic\",\n    \"ml_metadata\": {\n      \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n      \"search_time_ms\": 25,\n      \"total_candidates\": 1682\n    }\n  },\n  \"timestamp\": \"2024-01-01T12:00:00.000Z\"\n}\n</code></pre></p> <p>Example: <pre><code># Basic semantic search\ncurl \"http://127.0.0.1:5001/api/search/semantic?q=action%20movies%20with%20robots\"\n\n# Personalized semantic search\ncurl \"http://127.0.0.1:5001/api/search/semantic?q=funny%20movies&amp;limit=10&amp;user_id=123\"\n</code></pre></p>"},{"location":"backend-frontend/api-reference/#traditional-search","title":"Traditional Search","text":"<p>Search for movies by title, genre, or keywords.</p>"},{"location":"backend-frontend/api-reference/#get-searchtraditional","title":"<code>GET /search/traditional</code>","text":"<p>Description: Performs traditional text-based search using database queries.</p> <p>Parameters: - <code>q</code> (query, required): Search query string - <code>limit</code> (query, optional): Number of results to return (default: 20, max: 50) - <code>genre</code> (query, optional): Filter by specific genre - <code>year</code> (query, optional): Filter by release year</p> <p>Response: <pre><code>{\n  \"success\": true,\n  \"message\": \"Traditional search completed successfully\",\n  \"data\": {\n    \"movies\": [\n      {\n        \"movieId\": 1,\n        \"title\": \"Toy Story\",\n        \"genres\": [\"Animation\", \"Children's\", \"Comedy\"],\n        \"poster_path\": \"/w4pJJ6VsZPNHdKJxCZZLfYRyPac.jpg\",\n        \"vote_average\": 8.3,\n        \"release_date\": \"1995-10-30\",\n        \"match_score\": 0.98,\n        \"match_type\": \"title\"\n      }\n    ],\n    \"total\": 5,\n    \"query\": \"toy story\",\n    \"search_type\": \"traditional\",\n    \"filters\": {\n      \"genre\": null,\n      \"year\": null\n    }\n  },\n  \"timestamp\": \"2024-01-01T12:00:00.000Z\"\n}\n</code></pre></p> <p>Example: <pre><code># Basic traditional search\ncurl \"http://127.0.0.1:5001/api/search/traditional?q=star%20wars\"\n\n# Filtered search\ncurl \"http://127.0.0.1:5001/api/search/traditional?q=action&amp;genre=Action&amp;year=1995\"\n</code></pre></p>"},{"location":"backend-frontend/api-reference/#recommendation-endpoints","title":"\ud83e\udd16 Recommendation Endpoints","text":""},{"location":"backend-frontend/api-reference/#personalized-recommendations","title":"Personalized Recommendations","text":"<p>Get personalized movie recommendations for a specific user.</p>"},{"location":"backend-frontend/api-reference/#get-recommendationspersonalized","title":"<code>GET /recommendations/personalized</code>","text":"<p>Description: Returns ML-powered personalized recommendations using BERT4Rec model.</p> <p>Parameters: - <code>user_id</code> (query, required): User ID for recommendations (1-610) - <code>limit</code> (query, optional): Number of recommendations (default: 10, max: 50) - <code>model</code> (query, optional): ML model to use ('bert4rec', 'two_tower', 'hybrid')</p> <p>Response: <pre><code>{\n  \"success\": true,\n  \"message\": \"Personalized recommendations generated successfully\",\n  \"data\": {\n    \"movies\": [\n      {\n        \"movieId\": 1,\n        \"title\": \"Toy Story\",\n        \"genres\": [\"Animation\", \"Children's\", \"Comedy\"],\n        \"poster_path\": \"/w4pJJ6VsZPNHdKJxCZZLfYRyPac.jpg\",\n        \"vote_average\": 8.3,\n        \"personalized_score\": 0.95,\n        \"rank\": 1,\n        \"prediction_confidence\": 0.87\n      }\n    ],\n    \"total\": 10,\n    \"recommendation_type\": \"personalized\",\n    \"user_context\": {\n      \"user_id\": \"123\",\n      \"model_used\": \"bert4rec\",\n      \"sequence_length\": 50,\n      \"user_history_size\": 45,\n      \"inference_time_ms\": 75\n    }\n  },\n  \"timestamp\": \"2024-01-01T12:00:00.000Z\"\n}\n</code></pre></p> <p>Example: <pre><code># Get personalized recommendations\ncurl \"http://127.0.0.1:5001/api/recommendations/personalized?user_id=123\"\n\n# Get recommendations with specific model\ncurl \"http://127.0.0.1:5001/api/recommendations/personalized?user_id=123&amp;limit=20&amp;model=bert4rec\"\n</code></pre></p>"},{"location":"backend-frontend/api-reference/#similar-movies","title":"Similar Movies","text":"<p>Get movies similar to a specific movie.</p>"},{"location":"backend-frontend/api-reference/#get-recommendationssimilarmovie_id","title":"<code>GET /recommendations/similar/{movie_id}</code>","text":"<p>Description: Returns movies similar to the specified movie using content-based filtering.</p> <p>Parameters: - <code>movie_id</code> (path): Reference movie ID - <code>limit</code> (query, optional): Number of similar movies (default: 10, max: 20) - <code>user_id</code> (query, optional): User ID for personalized ranking</p> <p>Response: <pre><code>{\n  \"success\": true,\n  \"message\": \"Similar movies found successfully\",\n  \"data\": {\n    \"reference_movie\": {\n      \"movieId\": 1,\n      \"title\": \"Toy Story\"\n    },\n    \"similar_movies\": [\n      {\n        \"movieId\": 2,\n        \"title\": \"Jumanji\",\n        \"genres\": [\"Adventure\", \"Children's\", \"Fantasy\"],\n        \"similarity_score\": 0.85,\n        \"similarity_reason\": \"genre_and_content\",\n        \"rank\": 1\n      }\n    ],\n    \"total\": 10,\n    \"recommendation_type\": \"similar\",\n    \"similarity_method\": \"content_based\"\n  },\n  \"timestamp\": \"2024-01-01T12:00:00.000Z\"\n}\n</code></pre></p> <p>Example: <pre><code># Get similar movies\ncurl http://127.0.0.1:5001/api/recommendations/similar/1\n\n# Get personalized similar movies\ncurl \"http://127.0.0.1:5001/api/recommendations/similar/1?user_id=123&amp;limit=5\"\n</code></pre></p>"},{"location":"backend-frontend/api-reference/#analytics-endpoints","title":"\ud83d\udcca Analytics Endpoints","text":""},{"location":"backend-frontend/api-reference/#user-analytics","title":"User Analytics","text":"<p>Get analytics and statistics for user behavior.</p>"},{"location":"backend-frontend/api-reference/#get-analyticsuseruser_id","title":"<code>GET /analytics/user/{user_id}</code>","text":"<p>Description: Returns detailed analytics for a specific user's movie preferences and behavior.</p> <p>Parameters: - <code>user_id</code> (path): User ID for analytics</p> <p>Response: <pre><code>{\n  \"success\": true,\n  \"message\": \"User analytics retrieved successfully\",\n  \"data\": {\n    \"user_id\": 123,\n    \"rating_statistics\": {\n      \"total_ratings\": 150,\n      \"avg_rating\": 3.8,\n      \"rating_distribution\": {\n        \"1\": 5,\n        \"2\": 15,\n        \"3\": 45,\n        \"4\": 60,\n        \"5\": 25\n      }\n    },\n    \"genre_preferences\": [\n      {\n        \"genre\": \"Action\",\n        \"count\": 35,\n        \"avg_rating\": 4.1\n      },\n      {\n        \"genre\": \"Sci-Fi\",\n        \"count\": 28,\n        \"avg_rating\": 4.3\n      }\n    ],\n    \"activity_timeline\": {\n      \"first_rating\": \"1997-01-01T00:00:00.000Z\",\n      \"last_rating\": \"1998-12-31T23:59:59.000Z\",\n      \"most_active_month\": \"1998-06\"\n    }\n  },\n  \"timestamp\": \"2024-01-01T12:00:00.000Z\"\n}\n</code></pre></p> <p>Example: <pre><code>curl http://127.0.0.1:5001/api/analytics/user/123\n</code></pre></p>"},{"location":"backend-frontend/api-reference/#error-handling","title":"\u26a0\ufe0f Error Handling","text":""},{"location":"backend-frontend/api-reference/#error-response-format","title":"Error Response Format","text":"<p>All errors follow a consistent format:</p> <pre><code>{\n  \"success\": false,\n  \"message\": \"Human-readable error description\",\n  \"error\": {\n    \"code\": \"ERROR_CODE\",\n    \"details\": \"Technical error details\",\n    \"field\": \"field_name (for validation errors)\"\n  },\n  \"timestamp\": \"2024-01-01T12:00:00.000Z\"\n}\n</code></pre>"},{"location":"backend-frontend/api-reference/#http-status-codes","title":"HTTP Status Codes","text":"Status Code Description Example <code>200</code> Success Successful API call <code>400</code> Bad Request Invalid parameters or malformed request <code>404</code> Not Found Movie or user not found <code>422</code> Validation Error Invalid user ID or parameter values <code>500</code> Internal Server Error Database connection failed or ML model error <code>503</code> Service Unavailable ML models not loaded or system maintenance"},{"location":"backend-frontend/api-reference/#common-error-codes","title":"Common Error Codes","text":""},{"location":"backend-frontend/api-reference/#validation-errors-400","title":"Validation Errors (400)","text":"<pre><code>{\n  \"success\": false,\n  \"message\": \"Invalid user ID\",\n  \"error\": {\n    \"code\": \"INVALID_USER_ID\",\n    \"details\": \"User ID must be between 1 and 610\",\n    \"field\": \"user_id\"\n  }\n}\n</code></pre>"},{"location":"backend-frontend/api-reference/#not-found-errors-404","title":"Not Found Errors (404)","text":"<pre><code>{\n  \"success\": false,\n  \"message\": \"Movie not found\",\n  \"error\": {\n    \"code\": \"MOVIE_NOT_FOUND\",\n    \"details\": \"No movie found with ID 99999\"\n  }\n}\n</code></pre>"},{"location":"backend-frontend/api-reference/#ml-model-errors-500","title":"ML Model Errors (500)","text":"<pre><code>{\n  \"success\": false,\n  \"message\": \"Recommendation model unavailable\",\n  \"error\": {\n    \"code\": \"ML_MODEL_ERROR\",\n    \"details\": \"BERT4Rec model failed to load\"\n  }\n}\n</code></pre>"},{"location":"backend-frontend/api-reference/#rate-limiting","title":"\ud83d\udd27 Rate Limiting","text":""},{"location":"backend-frontend/api-reference/#rate-limits","title":"Rate Limits","text":"Endpoint Category Rate Limit Window Health/Info 60 requests 1 minute Search 30 requests 1 minute Recommendations 20 requests 1 minute Movie Details 100 requests 1 minute"},{"location":"backend-frontend/api-reference/#rate-limit-headers","title":"Rate Limit Headers","text":"<pre><code>X-RateLimit-Limit: 30\nX-RateLimit-Remaining: 25\nX-RateLimit-Reset: 1640995200\n</code></pre>"},{"location":"backend-frontend/api-reference/#rate-limit-exceeded-response","title":"Rate Limit Exceeded Response","text":"<pre><code>{\n  \"success\": false,\n  \"message\": \"Rate limit exceeded\",\n  \"error\": {\n    \"code\": \"RATE_LIMIT_EXCEEDED\",\n    \"details\": \"Maximum 30 requests per minute for search endpoints\"\n  }\n}\n</code></pre>"},{"location":"backend-frontend/api-reference/#testing-the-api","title":"\ud83e\uddea Testing the API","text":""},{"location":"backend-frontend/api-reference/#using-curl","title":"Using cURL","text":"<pre><code># Test all endpoints\ncurl http://127.0.0.1:5001/api/health\ncurl http://127.0.0.1:5001/api/users/info\ncurl \"http://127.0.0.1:5001/api/movies/popular?limit=5\"\ncurl \"http://127.0.0.1:5001/api/search/semantic?q=action%20movies\"\ncurl \"http://127.0.0.1:5001/api/recommendations/personalized?user_id=123\"\n</code></pre>"},{"location":"backend-frontend/api-reference/#using-python","title":"Using Python","text":"<pre><code>import requests\n\n# API base URL\nAPI_URL = \"http://127.0.0.1:5001/api\"\n\n# Test search\nresponse = requests.get(f\"{API_URL}/search/semantic\", params={\n    \"q\": \"funny movies for kids\",\n    \"limit\": 10,\n    \"user_id\": 123\n})\n\ndata = response.json()\nif data[\"success\"]:\n    movies = data[\"data\"][\"movies\"]\n    print(f\"Found {len(movies)} movies\")\nelse:\n    print(f\"Error: {data['message']}\")\n</code></pre>"},{"location":"backend-frontend/api-reference/#using-javascript","title":"Using JavaScript","text":"<pre><code>// API client example\nclass MovieAPI {\n  constructor(baseURL = 'http://127.0.0.1:5001/api') {\n    this.baseURL = baseURL;\n  }\n\n  async searchMovies(query, limit = 20, userId = null) {\n    const params = new URLSearchParams({ q: query, limit });\n    if (userId) params.append('user_id', userId);\n\n    const response = await fetch(`${this.baseURL}/search/semantic?${params}`);\n    const data = await response.json();\n\n    if (!data.success) {\n      throw new Error(data.message);\n    }\n\n    return data.data;\n  }\n\n  async getRecommendations(userId, limit = 10) {\n    const response = await fetch(\n      `${this.baseURL}/recommendations/personalized?user_id=${userId}&amp;limit=${limit}`\n    );\n    const data = await response.json();\n\n    if (!data.success) {\n      throw new Error(data.message);\n    }\n\n    return data.data;\n  }\n}\n\n// Usage\nconst api = new MovieAPI();\nconst movies = await api.searchMovies(\"action movies\", 10, 123);\n</code></pre> <p>This API reference provides complete documentation for integrating with Movie Genie's backend services. All endpoints are designed to be RESTful, well-documented, and easy to test. \ud83d\udcda</p>"},{"location":"backend-frontend/backend-integration/","title":"Backend Integration Guide","text":"<p>This document provides a comprehensive overview of how the Movie Genie backend integrates with the frontend, APIs, and ML infrastructure to deliver AI-powered movie recommendations.</p>"},{"location":"backend-frontend/backend-integration/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  React Frontend \u2502\u2500\u2500\u2500\u2500\u2502   Flask Backend  \u2502\u2500\u2500\u2500\u2500\u2502ML Infrastructure\u2502\n\u2502                 \u2502    \u2502                  \u2502    \u2502                 \u2502\n\u2502 - UI Components \u2502    \u2502 - API Routes     \u2502    \u2502 - BERT4Rec      \u2502\n\u2502 - State Mgmt    \u2502    \u2502 - Services Layer \u2502    \u2502 - Two-Tower     \u2502\n\u2502 - HTTP Client   \u2502    \u2502 - Model Loading  \u2502    \u2502 - Semantic Search\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"backend-frontend/backend-integration/#frontend-backend-integration","title":"Frontend-Backend Integration","text":""},{"location":"backend-frontend/backend-integration/#1-user-authentication-and-session-management","title":"1. User Authentication and Session Management","text":"<p>The application includes a user selection modal that integrates with the backend user management system:</p>"},{"location":"backend-frontend/backend-integration/#user-selection-modal-userselectionmodaltsx","title":"User Selection Modal (<code>UserSelectionModal.tsx</code>)","text":"<pre><code>// API call to get valid user range\nconst { data: userInfo, isLoading, error } = useQuery({\n  queryKey: ['userInfo'],\n  queryFn: () =&gt; MovieGenieAPI.getUserInfo()\n});\n\n// Validation logic\nconst isValidUserId = (id: string): boolean =&gt; {\n  if (!userInfo || !userInfo.user_id_range || !id.trim()) return false;\n  const numId = parseInt(id);\n  if (isNaN(numId)) return false;\n  return numId &gt;= userInfo.user_id_range.min &amp;&amp; numId &lt;= userInfo.user_id_range.max;\n};\n</code></pre>"},{"location":"backend-frontend/backend-integration/#backend-user-info-api-apiusersinfo","title":"Backend User Info API (<code>/api/users/info</code>)","text":"<pre><code>@api_bp.route('/users/info', methods=['GET'])\ndef get_user_info():\n    \"\"\"Get information about available users and valid ID ranges.\"\"\"\n    try:\n        user_data = load_user_data()\n        user_ids = user_data['user_id'].unique()\n\n        return jsonify({\n            \"success\": True,\n            \"message\": f\"User database contains {len(user_ids)} users\",\n            \"data\": {\n                \"user_id_range\": {\n                    \"min\": int(user_ids.min()),\n                    \"max\": int(user_ids.max()),\n                    \"total\": len(user_ids)\n                },\n                \"interaction_stats\": {\n                    \"mean_interactions_per_user\": float(interactions_per_user.mean()),\n                    \"min_interactions\": int(interactions_per_user.min()),\n                    \"max_interactions\": int(interactions_per_user.max()),\n                    \"median_interactions\": float(interactions_per_user.median())\n                },\n                \"sample_user_ids\": user_ids[:10].tolist(),\n                \"instructions\": {\n                    \"valid_range\": f\"Choose a user ID between {user_ids.min()} and {user_ids.max()}\",\n                    \"note\": \"Each user has different viewing preferences that affect personalized recommendations\"\n                }\n            }\n        })\n    except Exception as e:\n        logger.error(f\"Error getting user info: {e}\")\n        return jsonify({\"success\": False, \"message\": \"Failed to load user information\"}), 500\n</code></pre>"},{"location":"backend-frontend/backend-integration/#2-search-interface-integration","title":"2. Search Interface Integration","text":"<p>The frontend includes a sophisticated search interface with grid-based results display:</p>"},{"location":"backend-frontend/backend-integration/#search-grid-component-searchresultsgridtsx","title":"Search Grid Component (<code>SearchResultsGrid.tsx</code>)","text":"<pre><code>// Search results displayed in responsive grid\n&lt;div className=\"grid grid-cols-2 md:grid-cols-3 lg:grid-cols-4 xl:grid-cols-5 gap-4 max-h-[600px] overflow-y-auto\"&gt;\n  {searchResults.map((movie) =&gt; (\n    &lt;Card key={movie.id} className=\"movie-card-styling\" onClick={() =&gt; onMovieClick(movie.id)}&gt;\n      &lt;div className=\"aspect-[2/3] bg-muted flex items-center justify-center relative\"&gt;\n        &lt;img src={movie.poster} alt={movie.title} className=\"w-full h-full object-cover\"\n             onError={(e) =&gt; {\n               // Fallback to gradient display\n               e.currentTarget.style.display = 'none';\n               e.currentTarget.nextElementSibling.style.display = 'flex';\n             }}\n        /&gt;\n        &lt;div className=\"w-full h-full bg-gradient-to-br from-primary/20 to-accent/20 flex items-center justify-center text-muted-foreground text-sm hidden\"&gt;\n          {movie.title}\n        &lt;/div&gt;\n      &lt;/div&gt;\n    &lt;/Card&gt;\n  ))}\n&lt;/div&gt;\n</code></pre>"},{"location":"backend-frontend/backend-integration/#search-behavior","title":"Search Behavior","text":"<ul> <li>Trigger: Search executes only on Enter key press (not on every keystroke)</li> <li>Mode Switch: Search results replace carousel view completely</li> <li>Navigation: Back button returns to main carousel view and clears search</li> <li>Visual Consistency: Search grid cards use same styling as homepage movie thumbnails</li> </ul>"},{"location":"backend-frontend/backend-integration/#3-build-process-integration","title":"3. Build Process Integration","text":"<p>The frontend and backend are integrated through a sophisticated build process managed by DVC:</p>"},{"location":"backend-frontend/backend-integration/#frontend-build-configuration-movie_geniefrontendviteconfigts","title":"Frontend Build Configuration (<code>movie_genie/frontend/vite.config.ts</code>)","text":"<pre><code>build: {\n  outDir: \"../backend/dist\",      // Build to backend dist\n  emptyOutDir: true,\n  rollupOptions: {\n    output: {\n      // Place JS and CSS files in Flask's static directory structure\n      assetFileNames: (assetInfo) =&gt; {\n        const extType = assetInfo.name?.split('.').pop();\n        if (extType === 'css') {\n          return 'css/[name]-[hash][extname]';\n        }\n        if (['png', 'jpg', 'jpeg', 'svg', 'gif', 'webp'].includes(extType || '')) {\n          return 'img/[name]-[hash][extname]';\n        }\n        return 'assets/[name]-[hash][extname]';\n      },\n      chunkFileNames: 'js/[name]-[hash].js',\n      entryFileNames: 'js/[name]-[hash].js',\n    },\n  },\n},\n// Configure base path for Flask static files\nbase: mode === 'production' ? '/static/' : '/',\n</code></pre>"},{"location":"backend-frontend/backend-integration/#dvc-pipeline-integration-dvcyaml","title":"DVC Pipeline Integration (<code>dvc.yaml</code>)","text":"<pre><code>frontend_build:\n  cmd: &gt;\n    cd movie_genie/frontend &amp;&amp; npm run build &amp;&amp;\n    cp ../backend/dist/index.html ../backend/templates/ &amp;&amp;\n    mkdir -p ../backend/static &amp;&amp;\n    cp -r ../backend/dist/css ../backend/static/ &amp;&amp;\n    cp -r ../backend/dist/js ../backend/static/ &amp;&amp;\n    [ -d ../backend/dist/img ] &amp;&amp; cp -r ../backend/dist/img ../backend/static/ || true &amp;&amp;\n    [ -d ../backend/dist/assets ] &amp;&amp; cp -r ../backend/dist/assets ../backend/static/ || true\n  deps:\n    - movie_genie/frontend/src/\n    - movie_genie/frontend/package.json\n    - movie_genie/frontend/vite.config.ts\n    - movie_genie/frontend/.env.development\n  outs:\n    - movie_genie/backend/templates/index.html\n    - movie_genie/backend/static/\n</code></pre> <p>Process Flow: 1. Vite builds React app to <code>backend/dist/</code> 2. DVC copies <code>index.html</code> to <code>backend/templates/</code> 3. DVC copies <code>static/</code> directory to <code>backend/static/</code> 4. Flask serves frontend from these locations</p>"},{"location":"backend-frontend/backend-integration/#2-static-file-serving","title":"2. Static File Serving","text":"<p>The Flask backend serves the React frontend through configured static and template directories:</p>"},{"location":"backend-frontend/backend-integration/#flask-configuration-movie_geniebackendapppy","title":"Flask Configuration (<code>movie_genie/backend/app.py</code>)","text":"<pre><code>app = Flask(__name__,\n           static_folder='static',\n           template_folder='templates')\n\n@app.route('/')\ndef serve_frontend():\n    \"\"\"Serve the React frontend.\"\"\"\n    try:\n        return render_template('index.html')\n    except Exception as e:\n        logger.error(f\"Error serving frontend: {e}\")\n        return \"Frontend not available\", 404\n</code></pre>"},{"location":"backend-frontend/backend-integration/#frontend-status-monitoring","title":"Frontend Status Monitoring","text":"<pre><code>def check_frontend_build_status():\n    \"\"\"Check if frontend files are properly built.\"\"\"\n    template_path = Path(app.template_folder) / 'index.html'\n    static_path = Path(app.static_folder)\n\n    return {\n        'templates': '\u2705' if template_path.exists() else '\u274c',\n        'static_files': '\u2705' if static_path.exists() else '\u274c'\n    }\n</code></pre>"},{"location":"backend-frontend/backend-integration/#api-architecture","title":"API Architecture","text":""},{"location":"backend-frontend/backend-integration/#1-restful-api-design","title":"1. RESTful API Design","text":"<p>The backend exposes a comprehensive RESTful API with the following structure:</p> <pre><code>/api/\n\u251c\u2500\u2500 health              # Health check endpoint\n\u251c\u2500\u2500 users/\n\u2502   \u2514\u2500\u2500 info           # User information and valid ID ranges\n\u251c\u2500\u2500 movies/\n\u2502   \u251c\u2500\u2500 popular         # Popular movies\n\u2502   \u2514\u2500\u2500 &lt;id&gt;           # Movie details by ID\n\u251c\u2500\u2500 search/\n\u2502   \u2514\u2500\u2500 semantic       # Semantic search\n\u251c\u2500\u2500 recommendations/\n\u2502   \u2514\u2500\u2500 personalized   # Personalized recommendations\n\u2514\u2500\u2500 feedback           # User feedback collection\n</code></pre>"},{"location":"backend-frontend/backend-integration/#2-api-blueprints-structure","title":"2. API Blueprints Structure","text":""},{"location":"backend-frontend/backend-integration/#main-application-factory-movie_geniebackendapp__init__py","title":"Main Application Factory (<code>movie_genie/backend/app/__init__.py</code>)","text":"<pre><code>def create_app(config_class=DevelopmentConfig):\n    app = Flask(__name__)\n    app.config.from_object(config_class)\n\n    # Register API blueprints\n    from .api import api_bp\n    app.register_blueprint(api_bp, url_prefix='/api')\n\n    return app\n</code></pre>"},{"location":"backend-frontend/backend-integration/#api-blueprint-registration-movie_geniebackendappapi__init__py","title":"API Blueprint Registration (<code>movie_genie/backend/app/api/__init__.py</code>)","text":"<pre><code>from flask import Blueprint\n\napi_bp = Blueprint('api', __name__)\n\n# Import and register sub-modules\nfrom . import health, movies, search, recommendations, feedback\n</code></pre>"},{"location":"backend-frontend/backend-integration/#3-api-endpoints-detail","title":"3. API Endpoints Detail","text":""},{"location":"backend-frontend/backend-integration/#health-check-apihealth","title":"Health Check (<code>/api/health</code>)","text":"<pre><code>@api_bp.route('/health', methods=['GET'])\ndef health_check():\n    return jsonify({\n        \"status\": \"healthy\",\n        \"message\": \"Movie Genie API is running\",\n        \"version\": \"1.0.0\"\n    })\n</code></pre>"},{"location":"backend-frontend/backend-integration/#semantic-search-apisearchsemantic","title":"Semantic Search (<code>/api/search/semantic</code>)","text":"<pre><code>@api_bp.route('/search/semantic', methods=['GET'])\ndef semantic_search():\n    query = request.args.get('q', '')\n    k = int(request.args.get('k', 20))\n    user_id = request.args.get('user_id')\n\n    # Use search service\n    results = search_service.semantic_search(\n        query=query, k=k,\n        user_context={'user_id': user_id} if user_id else None\n    )\n\n    return jsonify({\n        \"success\": True,\n        \"message\": f\"Found {results['total']} movies for '{query}'\",\n        \"data\": results\n    })\n</code></pre>"},{"location":"backend-frontend/backend-integration/#personalized-recommendations-apirecommendationspersonalized","title":"Personalized Recommendations (<code>/api/recommendations/personalized</code>)","text":"<pre><code>@api_bp.route('/recommendations/personalized', methods=['POST'])\ndef personalized_recommendations():\n    data = request.get_json() or {}\n    user_id = data.get('user_id')\n    history = data.get('interaction_history', [])\n    limit = data.get('limit', 5)\n\n    # Use recommendation service\n    results = recommendation_service.get_personalized_recommendations(\n        user_id=user_id,\n        interaction_history=history,\n        limit=limit\n    )\n\n    return jsonify({\n        \"success\": True,\n        \"data\": results\n    })\n</code></pre>"},{"location":"backend-frontend/backend-integration/#ml-infrastructure-integration","title":"ML Infrastructure Integration","text":""},{"location":"backend-frontend/backend-integration/#1-service-layer-architecture","title":"1. Service Layer Architecture","text":"<p>The backend uses a service layer pattern to integrate with ML models:</p> <pre><code>Controllers (API Routes)\n    \u2193\nServices Layer\n    \u2193\nML Models &amp; Data Processing\n</code></pre>"},{"location":"backend-frontend/backend-integration/#services-structure","title":"Services Structure:","text":"<ul> <li><code>SearchService</code>: Handles semantic search operations</li> <li><code>RecommendationService</code>: Manages personalized recommendations</li> <li><code>MovieService</code>: Movie data operations</li> </ul>"},{"location":"backend-frontend/backend-integration/#2-semantic-search-integration","title":"2. Semantic Search Integration","text":""},{"location":"backend-frontend/backend-integration/#searchservice-movie_geniebackendappservicessearch_servicepy","title":"SearchService (<code>movie_genie/backend/app/services/search_service.py</code>)","text":"<pre><code>class SearchService:\n    def __init__(self, config_path=None):\n        self.semantic_engine = None\n        self.config_path = config_path or str(project_root / \"configs\" / \"semantic_search.yaml\")\n        self._initialize_search_engine()\n\n    def _initialize_search_engine(self):\n        \"\"\"Initialize the semantic search engine with path resolution.\"\"\"\n        try:\n            from movie_genie.search.semantic_engine import SemanticSearchEngine\n            self.semantic_engine = SemanticSearchEngine(self.config_path)\n            logger.info(\"\u2705 SemanticSearchEngine initialized successfully\")\n        except Exception as e:\n            logger.error(f\"\u274c Failed to initialize SemanticSearchEngine: {e}\")\n\n    def semantic_search(self, query: str, k: int = 20, user_context=None):\n        \"\"\"Perform semantic search with optional personalization.\"\"\"\n        if not self.semantic_engine:\n            return self._fallback_response(query)\n\n        results = self.semantic_engine.search(query, k, user_context)\n        return self._format_api_response(results, query)\n</code></pre>"},{"location":"backend-frontend/backend-integration/#semantic-search-engine-movie_geniesearchsemantic_enginepy","title":"Semantic Search Engine (<code>movie_genie/search/semantic_engine.py</code>)","text":"<pre><code>class SemanticSearchEngine:\n    def __init__(self, config_path: str = \"configs/semantic_search.yaml\"):\n        # Dynamic path resolution for deployment flexibility\n        self.project_root = self._find_project_root()\n\n        # Initialize components with resolved paths\n        self.query_encoder = QueryEncoder(config_path)\n\n        movies_path = self.config['movies_path']\n        if not Path(movies_path).is_absolute():\n            movies_path = str(self.project_root / movies_path)\n\n        self.movie_loader = MovieEmbeddingLoader(movies_path)\n        self.movie_embeddings, self.movie_metadata = self.movie_loader.get_embeddings_and_metadata()\n\n    def _find_project_root(self) -&gt; Path:\n        \"\"\"Find project root by looking for pyproject.toml or dvc.yaml.\"\"\"\n        current_path = Path(__file__).resolve()\n        for parent in current_path.parents:\n            if (parent / 'pyproject.toml').exists() or (parent / 'dvc.yaml').exists():\n                return parent\n        return Path.cwd()\n</code></pre>"},{"location":"backend-frontend/backend-integration/#3-recommendation-system-integration","title":"3. Recommendation System Integration","text":""},{"location":"backend-frontend/backend-integration/#recommendationservice-movie_geniebackendappservicesrecommendation_servicepy","title":"RecommendationService (<code>movie_genie/backend/app/services/recommendation_service.py</code>)","text":"<pre><code>class RecommendationService:\n    def __init__(self):\n        self.bert4rec_reranker = None\n        self.two_tower_reranker = None\n        self._initialize_models()\n\n    def _initialize_models(self):\n        \"\"\"Initialize recommendation models with proper error handling.\"\"\"\n        try:\n            # BERT4Rec for sequential recommendations\n            self.bert4rec_reranker = BERT4RecReranker(\n                model_path=\"models/bert4rec/bert4rec_model.pth\",\n                data_artifacts_path=\"models/bert4rec/data_artifacts.pkl\"\n            )\n\n            # Two-Tower for collaborative filtering\n            self.two_tower_reranker = TwoTowerReranker(\n                model_path=\"models/two_tower/two_tower_model.pth\"\n            )\n\n        except Exception as e:\n            logger.error(f\"Model initialization failed: {e}\")\n\n    def get_personalized_recommendations(self, user_id=None, interaction_history=None, limit=5):\n        \"\"\"Generate personalized recommendations using available models.\"\"\"\n        # Get base recommendations (popular movies as fallback)\n        base_movies = self.movie_service.get_popular_movies(limit * 3)\n\n        # Apply personalization if user context available\n        if interaction_history and self.bert4rec_reranker:\n            user_context = {\n                'user_id': user_id,\n                'interaction_history': interaction_history\n            }\n            personalized = self.bert4rec_reranker.rerank(base_movies, user_context)\n            return personalized[:limit]\n\n        return base_movies[:limit]\n</code></pre>"},{"location":"backend-frontend/backend-integration/#4-model-loading-and-management","title":"4. Model Loading and Management","text":""},{"location":"backend-frontend/backend-integration/#bert4rec-model-loading","title":"BERT4Rec Model Loading","text":"<pre><code>class BERT4RecReranker(SearchReranker):\n    def _load_model(self):\n        \"\"\"Load BERT4Rec model with proper reconstruction.\"\"\"\n        # Load data artifacts for model configuration\n        with open(self.data_artifacts_path, 'rb') as f:\n            self.data_artifacts = pickle.load(f)\n\n        # Load model state dict\n        state_dict = torch.load(self.model_path, map_location='cpu')\n\n        # Reconstruct model with correct parameters\n        from movie_genie.ranking.bert4rec_model import BERT4RecModel\n\n        self.model = BERT4RecModel(\n            num_items=self.data_artifacts['num_movies'],\n            content_feature_dim=768,  # EmbeddingGemma dimension\n            max_seq_len=50,\n            hidden_dim=256,\n            num_layers=4,\n            num_heads=8,\n            dropout_rate=0.1\n        )\n\n        self.model.load_state_dict(state_dict)\n        self.model.eval()\n</code></pre>"},{"location":"backend-frontend/backend-integration/#two-tower-model-loading-with-config","title":"Two-Tower Model Loading with Config","text":"<pre><code>class TwoTowerReranker(SearchReranker):\n    def _load_model(self):\n        \"\"\"Load Two-Tower model with configuration-based reconstruction.\"\"\"\n        # Load model configuration\n        config_path = self.model_path.parent / 'model_config.json'\n        with open(config_path, 'r') as f:\n            config = json.load(f)\n\n        # Load state dict\n        state_dict = torch.load(self.model_path, map_location='cpu')\n\n        # Reconstruct model if needed\n        if not hasattr(state_dict, 'eval'):\n            from movie_genie.retrieval.two_tower_model import TwoTowerModel\n\n            model_config = config.get('training_config', {}).get('model', config)\n            self.model = TwoTowerModel(\n                num_users=config['num_users'],\n                num_movies=config['num_movies'],\n                content_feature_dim=config['content_feature_dim'],\n                embedding_dim=model_config.get('embedding_dim', 128),\n                user_hidden_dims=model_config.get('user_hidden_dims', [128, 64]),\n                item_hidden_dims=model_config.get('item_hidden_dims', [256, 128]),\n                dropout_rate=model_config.get('dropout_rate', 0.1)\n            )\n\n            self.model.load_state_dict(state_dict)\n        else:\n            self.model = state_dict\n\n        self.model.eval()\n</code></pre>"},{"location":"backend-frontend/backend-integration/#data-flow-architecture","title":"Data Flow Architecture","text":""},{"location":"backend-frontend/backend-integration/#1-request-processing-flow","title":"1. Request Processing Flow","text":"<pre><code>graph TD\n    A[React Frontend] --&gt; B[Flask API Endpoint]\n    B --&gt; C[Service Layer]\n    C --&gt; D[ML Model/Engine]\n    D --&gt; E[Data Processing]\n    E --&gt; F[Response Formatting]\n    F --&gt; G[JSON API Response]\n    G --&gt; A</code></pre>"},{"location":"backend-frontend/backend-integration/#2-ml-pipeline-integration","title":"2. ML Pipeline Integration","text":""},{"location":"backend-frontend/backend-integration/#data-sources-and-processing","title":"Data Sources and Processing:","text":"<pre><code>Raw Data (MovieLens + TMDB)\n    \u2193 (DVC Pipeline: ingest)\nProcessed User Sequences\n    \u2193 (DVC Pipeline: training)\nTrained Models (BERT4Rec, Two-Tower)\n    \u2193 (DVC Pipeline: backend_server)\nLoaded Models in Flask App\n    \u2193 (Runtime)\nAPI Responses with Predictions\n</code></pre>"},{"location":"backend-frontend/backend-integration/#3-configuration-management","title":"3. Configuration Management","text":""},{"location":"backend-frontend/backend-integration/#centralized-configuration-configs","title":"Centralized Configuration (<code>configs/</code>)","text":"<pre><code># semantic_search.yaml\nmodel_name: \"google/embeddinggemma-300M\"\nmovies_path: \"data/processed/content_features.parquet\"\nreranker:\n  enabled: true\n  type: \"bert4rec\"\n  model_path: \"models/bert4rec/bert4rec_model.pth\"\n  data_artifacts_path: \"models/bert4rec/data_artifacts.pkl\"\n</code></pre>"},{"location":"backend-frontend/backend-integration/#environment-based-config-movie_geniebackendconfigpy","title":"Environment-Based Config (<code>movie_genie/backend/config.py</code>)","text":"<pre><code>class DevelopmentConfig(Config):\n    FLASK_ENV = 'development'\n    DEBUG = True\n\nclass ProductionConfig(Config):\n    FLASK_ENV = 'production'\n    DEBUG = False\n</code></pre>"},{"location":"backend-frontend/backend-integration/#error-handling-and-monitoring","title":"Error Handling and Monitoring","text":""},{"location":"backend-frontend/backend-integration/#1-graceful-degradation","title":"1. Graceful Degradation","text":"<pre><code>def semantic_search(self, query: str, k: int = 20, user_context=None):\n    \"\"\"Semantic search with fallback handling.\"\"\"\n    if not self.semantic_engine:\n        logger.error(\"SemanticSearchEngine not available\")\n        return {\n            'movies': [],\n            'total': 0,\n            'query': query,\n            'search_type': 'semantic',\n            'error': 'Search engine not available'\n        }\n\n    try:\n        results = self.semantic_engine.search(query, k, user_context)\n        return self._format_success_response(results, query)\n    except Exception as e:\n        logger.error(f\"Semantic search failed: {e}\")\n        return self._format_error_response(query, str(e))\n</code></pre>"},{"location":"backend-frontend/backend-integration/#2-health-monitoring","title":"2. Health Monitoring","text":"<pre><code>def get_system_status():\n    \"\"\"Get comprehensive system status.\"\"\"\n    return {\n        'frontend_status': check_frontend_build_status(),\n        'api_status': 'healthy',\n        'ml_models': {\n            'semantic_search': search_service.is_available(),\n            'bert4rec': recommendation_service.bert4rec_available(),\n            'two_tower': recommendation_service.two_tower_available()\n        },\n        'data_sources': check_data_availability()\n    }\n</code></pre>"},{"location":"backend-frontend/backend-integration/#deployment-and-devops","title":"Deployment and DevOps","text":""},{"location":"backend-frontend/backend-integration/#1-dvc-integration-for-ml-ops","title":"1. DVC Integration for ML Ops","text":"<pre><code># Complete pipeline from data to deployment\nbackend_server:\n  cmd: cd movie_genie/backend &amp;&amp; python app.py\n  deps:\n    - movie_genie/backend/app.py\n    - movie_genie/backend/templates/index.html  # Frontend dependency\n    - movie_genie/backend/static/               # Frontend assets\n    - models/two_tower/                         # ML models\n    - models/bert4rec/\n    - data/processed/content_features.parquet   # Data dependency\n  always_changed: true\n</code></pre>"},{"location":"backend-frontend/backend-integration/#2-production-deployment","title":"2. Production Deployment","text":"<pre><code># Production server setup\npip install gunicorn\nexport FLASK_ENV=production\nexport SECRET_KEY=your-production-secret\n\n# Run with WSGI server\ngunicorn -w 4 -b 0.0.0.0:5000 movie_genie.backend.app:app\n</code></pre>"},{"location":"backend-frontend/backend-integration/#3-container-deployment-docker","title":"3. Container Deployment (Docker)","text":"<pre><code># Multi-stage build for frontend and backend\nFROM node:18 AS frontend-build\nWORKDIR /app/frontend\n\nCOPY movie_genie/frontend/ .\nRUN npm install &amp;&amp; npm run build\n\nFROM python:3.9 AS backend\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY . .\nCOPY --from=frontend-build /app/frontend/../backend/dist/ /app/movie_genie/backend/\n\nEXPOSE 5000\nCMD [\"gunicorn\", \"-w\", \"4\", \"-b\", \"0.0.0.0:5000\", \"movie_genie.backend.app:app\"]\n</code></pre>"},{"location":"backend-frontend/backend-integration/#performance-considerations","title":"Performance Considerations","text":""},{"location":"backend-frontend/backend-integration/#1-model-loading-optimization","title":"1. Model Loading Optimization","text":"<ul> <li>Models loaded once at startup, not per request</li> <li>Lazy loading for non-critical components</li> <li>Caching of embeddings and frequently accessed data</li> </ul>"},{"location":"backend-frontend/backend-integration/#2-api-response-optimization","title":"2. API Response Optimization","text":"<ul> <li>Response compression for large result sets</li> <li>Pagination for large movie catalogs</li> <li>Caching of popular/frequent queries</li> </ul>"},{"location":"backend-frontend/backend-integration/#3-frontend-asset-optimization","title":"3. Frontend Asset Optimization","text":"<ul> <li>Static asset versioning with hash-based filenames</li> <li>Gzip compression for CSS/JS files</li> <li>CDN-ready static file structure</li> </ul>"},{"location":"backend-frontend/backend-integration/#security-considerations","title":"Security Considerations","text":""},{"location":"backend-frontend/backend-integration/#1-api-security","title":"1. API Security","text":"<ul> <li>Input validation and sanitization</li> <li>Rate limiting for API endpoints</li> <li>CORS configuration for frontend access</li> </ul>"},{"location":"backend-frontend/backend-integration/#2-model-security","title":"2. Model Security","text":"<ul> <li>Model files stored securely</li> <li>Access controls for sensitive data</li> <li>Input validation for ML model inputs</li> </ul>"},{"location":"backend-frontend/backend-integration/#current-working-implementation-status","title":"Current Working Implementation Status","text":""},{"location":"backend-frontend/backend-integration/#fully-functional-features-production-ready","title":"\u2705 Fully Functional Features (Production Ready)","text":""},{"location":"backend-frontend/backend-integration/#1-user-authentication-system","title":"1. User Authentication System","text":"<ul> <li>Status: \u2705 Working</li> <li>Components: User selection modal with validation</li> <li>API: <code>/api/users/info</code> returns valid user ID ranges (1-610)</li> <li>Validation: Real-time client-side validation with server data</li> <li>UX: Modal blocks access until valid user ID entered</li> </ul>"},{"location":"backend-frontend/backend-integration/#2-search-interface","title":"2. Search Interface","text":"<ul> <li>Status: \u2705 Working</li> <li>Trigger: Enter key press (not keystroke-based)</li> <li>Display: 5\u00d74 responsive grid layout with scrolling</li> <li>Visual: Gradient fallback cards matching homepage styling</li> <li>Navigation: Back button returns to main view and clears search</li> <li>Mode: Complete replacement of carousel view during search</li> </ul>"},{"location":"backend-frontend/backend-integration/#3-frontend-backend-integration","title":"3. Frontend-Backend Integration","text":"<ul> <li>Status: \u2705 Working</li> <li>Build Process: Automated via DVC pipeline</li> <li>API Communication: Proper error handling and data extraction</li> <li>Asset Serving: Static files served correctly via Flask</li> <li>Port Configuration: Backend on 5001, frontend properly configured</li> </ul>"},{"location":"backend-frontend/backend-integration/#4-api-response-structure","title":"4. API Response Structure","text":"<ul> <li>Status: \u2705 Working</li> <li>Format: Standardized <code>{data: {...}, success: boolean, message: string}</code> wrapper</li> <li>Client Handling: Frontend properly extracts data from wrapper</li> <li>Error Handling: Graceful degradation with user feedback</li> </ul>"},{"location":"backend-frontend/backend-integration/#using-mock-data-development-ready","title":"\ud83d\udea7 Using Mock Data (Development Ready)","text":""},{"location":"backend-frontend/backend-integration/#1-search-results","title":"1. Search Results","text":"<ul> <li>Current: 20 placeholder movies generated based on search query</li> <li>Display: Full grid layout with proper styling</li> <li>Integration Point: Ready for real semantic search API integration</li> </ul>"},{"location":"backend-frontend/backend-integration/#2-homepage-carousels","title":"2. Homepage Carousels","text":"<ul> <li>Current: Mock movie data for all recommendation sections</li> <li>Categories: Popular, Historical Interest, Recommendations, User History</li> <li>Integration Point: Ready for real ML recommendation API integration</li> </ul>"},{"location":"backend-frontend/backend-integration/#3-movie-details","title":"3. Movie Details","text":"<ul> <li>Current: Basic placeholder information</li> <li>Integration Point: Ready for detailed movie metadata API</li> </ul>"},{"location":"backend-frontend/backend-integration/#configuration-details","title":"\ud83d\udd27 Configuration Details","text":""},{"location":"backend-frontend/backend-integration/#environment-configuration-movie_geniefrontendenvdevelopment","title":"Environment Configuration (<code>movie_genie/frontend/.env.development</code>)","text":"<pre><code>VITE_API_URL=http://127.0.0.1:5001/api\nVITE_APP_TITLE=Movie Genie - Development\nVITE_ENABLE_MOCK_API=false\nVITE_LOG_LEVEL=debug\nVITE_ENABLE_DEVTOOLS=true\n</code></pre>"},{"location":"backend-frontend/backend-integration/#server-deployment","title":"Server Deployment","text":"<ul> <li>Backend: Flask server on port 5001</li> <li>Frontend: Built and served by Flask as static assets</li> <li>DVC Pipeline: Automated build and deployment process</li> <li>Development: Hot reload during development, production build for deployment</li> </ul>"},{"location":"backend-frontend/backend-integration/#getting-started-current-working-setup","title":"\ud83d\ude80 Getting Started (Current Working Setup)","text":""},{"location":"backend-frontend/backend-integration/#1-start-the-full-stack","title":"1. Start the Full Stack","text":"<pre><code># Start DVC pipeline (includes backend server)\ndvc repro\n\n# Or start manually:\ncd movie_genie/backend &amp;&amp; python app.py\n</code></pre>"},{"location":"backend-frontend/backend-integration/#2-access-the-application","title":"2. Access the Application","text":"<pre><code># Frontend served by Flask backend\nhttp://127.0.0.1:5001\n\n# API endpoints available at:\nhttp://127.0.0.1:5001/api/health\nhttp://127.0.0.1:5001/api/users/info\n</code></pre>"},{"location":"backend-frontend/backend-integration/#3-user-flow","title":"3. User Flow","text":"<ol> <li>User Selection: Enter user ID (1-610) in modal</li> <li>Main Interface: Browse recommendations in carousel format</li> <li>Search: Type query and press Enter for grid results</li> <li>Movie Details: Click any movie for details in sidebar</li> <li>Navigation: Use back button to return from search</li> </ol>"},{"location":"backend-frontend/backend-integration/#integration-readiness","title":"\ud83d\udcca Integration Readiness","text":"<p>The current implementation provides a solid foundation for ML integration:</p> <ul> <li>User Context: User ID properly passed through all API calls</li> <li>Search Interface: Ready for semantic search engine integration</li> <li>Recommendation Display: Components ready for personalized recommendations</li> <li>Error Handling: Graceful fallbacks when ML services unavailable</li> <li>Performance: Optimized build process and asset delivery</li> </ul> <p>This comprehensive integration ensures that Movie Genie operates as a cohesive, production-ready application with seamless frontend-backend-ML integration.</p>"},{"location":"backend-frontend/ml-integration/","title":"ML to Frontend Integration Guide","text":"<p>This guide provides step-by-step instructions for connecting ML model outputs to the backend API and then to the frontend interface. Each section includes precise code examples and implementation details.</p>"},{"location":"backend-frontend/ml-integration/#overview","title":"\ud83c\udfaf Overview","text":"<p>The integration flow follows this pattern: <pre><code>ML Models \u2192 Backend Services \u2192 API Endpoints \u2192 Frontend Data Service \u2192 UI Components\n</code></pre></p>"},{"location":"backend-frontend/ml-integration/#table-of-contents","title":"\ud83d\udccb Table of Contents","text":"<ol> <li>ML Model Output Integration</li> <li>Backend Service Implementation</li> <li>API Endpoint Creation</li> <li>Frontend Data Service Updates</li> <li>Environment Configuration</li> <li>Testing and Validation</li> </ol>"},{"location":"backend-frontend/ml-integration/#1-ml-model-output-integration","title":"1. ML Model Output Integration","text":""},{"location":"backend-frontend/ml-integration/#example-bert4rec-personalized-recommendations","title":"Example: BERT4Rec Personalized Recommendations","text":""},{"location":"backend-frontend/ml-integration/#step-1-ml-model-output-format","title":"Step 1: ML Model Output Format","text":"<p>Your ML models should return data in this standardized format:</p> <pre><code># Expected output from BERT4Rec model\nbert4rec_output = {\n    'user_id': 123,\n    'recommendations': [\n        {\n            'movie_id': 1001,\n            'title': 'The Matrix',\n            'score': 0.95,\n            'rank': 1,\n            'genres': ['Action', 'Sci-Fi'],\n            'year': 1999,\n            'poster_path': '/f89U3ADr1oiB1s9GkdPOEpXUk5H.jpg'\n        },\n        {\n            'movie_id': 1002,\n            'title': 'Inception',\n            'score': 0.87,\n            'rank': 2,\n            'genres': ['Action', 'Thriller'],\n            'year': 2010,\n            'poster_path': '/9gk7adHYeDvHkCSEqAvQNLV5Uge.jpg'\n        }\n    ],\n    'metadata': {\n        'model_type': 'bert4rec',\n        'sequence_length': 50,\n        'total_candidates': 1000,\n        'inference_time_ms': 45\n    }\n}\n</code></pre>"},{"location":"backend-frontend/ml-integration/#step-2-service-layer-integration","title":"Step 2: Service Layer Integration","text":"<p>Update your recommendation service to use ML outputs:</p> <pre><code># movie_genie/backend/app/services/recommendation_service.py\n\nclass RecommendationService:\n    def __init__(self):\n        self.bert4rec_reranker = BERT4RecReranker()\n        self.two_tower_reranker = TwoTowerReranker()\n\n    def get_personalized_recommendations(self, user_id: str, limit: int = 10):\n        \"\"\"Get personalized recommendations using BERT4Rec model.\"\"\"\n        try:\n            # 1. Get user interaction history\n            user_history = self._get_user_history(user_id)\n\n            # 2. Get ML model predictions\n            ml_output = self.bert4rec_reranker.predict(\n                user_id=int(user_id),\n                sequence_length=50,\n                num_recommendations=limit\n            )\n\n            # 3. Transform ML output to API format\n            recommendations = self._transform_ml_to_api(ml_output, limit)\n\n            return {\n                'movies': recommendations,\n                'recommendation_type': 'personalized',\n                'user_context': {\n                    'user_id': user_id,\n                    'model_used': 'bert4rec',\n                    'inference_time': ml_output.get('metadata', {}).get('inference_time_ms', 0)\n                }\n            }\n\n        except Exception as e:\n            logger.error(f\"ML recommendation failed for user {user_id}: {e}\")\n            # Fallback to popular movies\n            return self._get_popular_fallback(limit)\n\n    def _transform_ml_to_api(self, ml_output: dict, limit: int) -&gt; list:\n        \"\"\"Transform ML model output to standardized API format.\"\"\"\n        movies = []\n\n        for item in ml_output.get('recommendations', [])[:limit]:\n            movie = {\n                'movieId': item['movie_id'],\n                'title': item['title'],\n                'genres': item.get('genres', []),\n                'poster_path': item.get('poster_path'),\n                'vote_average': self._score_to_rating(item['score']),\n                'personalized_score': item['score'],\n                'rank': item['rank'],\n                'release_date': f\"{item.get('year', 2020)}-01-01\"\n            }\n            movies.append(movie)\n\n        return movies\n\n    def _score_to_rating(self, ml_score: float) -&gt; float:\n        \"\"\"Convert ML confidence score (0-1) to rating (1-10).\"\"\"\n        return round(1 + (ml_score * 9), 1)\n</code></pre>"},{"location":"backend-frontend/ml-integration/#2-backend-service-implementation","title":"2. Backend Service Implementation","text":""},{"location":"backend-frontend/ml-integration/#example-semantic-search-integration","title":"Example: Semantic Search Integration","text":""},{"location":"backend-frontend/ml-integration/#step-1-search-service-update","title":"Step 1: Search Service Update","text":"<pre><code># movie_genie/backend/app/services/search_service.py\n\nclass SearchService:\n    def __init__(self):\n        self.semantic_engine = SemanticSearchEngine()\n\n    def semantic_search(self, query: str, k: int = 20, user_context: dict = None):\n        \"\"\"Perform semantic search with ML-powered ranking.\"\"\"\n        try:\n            # 1. Get semantic search results from ML model\n            ml_results = self.semantic_engine.search(\n                query=query,\n                top_k=k,\n                user_id=user_context.get('user_id') if user_context else None\n            )\n\n            # 2. Transform results for API response\n            formatted_results = self._format_search_results(ml_results, query)\n\n            return {\n                'movies': formatted_results,\n                'total': len(formatted_results),\n                'query': query,\n                'search_type': 'semantic',\n                'ml_metadata': ml_results.get('metadata', {})\n            }\n\n        except Exception as e:\n            logger.error(f\"Semantic search failed: {e}\")\n            return self._fallback_search(query, k)\n\n    def _format_search_results(self, ml_results: dict, query: str) -&gt; list:\n        \"\"\"Format ML search results for API consumption.\"\"\"\n        movies = []\n\n        for item in ml_results.get('results', []):\n            movie = {\n                'movieId': item['movie_id'],\n                'title': item['title'],\n                'overview': item.get('overview', ''),\n                'genres': item.get('genres', []),\n                'poster_path': item.get('poster_path'),\n                'vote_average': item.get('rating', 0),\n                'similarity_score': item['similarity_score'],\n                'rank': item['rank']\n            }\n            movies.append(movie)\n\n        return movies\n</code></pre>"},{"location":"backend-frontend/ml-integration/#3-api-endpoint-creation","title":"3. API Endpoint Creation","text":""},{"location":"backend-frontend/ml-integration/#example-popular-movies-with-ml-ranking","title":"Example: Popular Movies with ML Ranking","text":""},{"location":"backend-frontend/ml-integration/#step-1-create-api-endpoint","title":"Step 1: Create API Endpoint","text":"<pre><code># movie_genie/backend/app/api/movies.py\n\nfrom flask import Blueprint, request, jsonify\nfrom ..services.movie_service import MovieService\n\nmovies_bp = Blueprint('movies', __name__)\nmovie_service = MovieService()\n\n@movies_bp.route('/popular', methods=['GET'])\ndef get_popular_movies():\n    \"\"\"Get popular movies with optional ML-based personalization.\"\"\"\n    try:\n        # Get parameters\n        limit = int(request.args.get('limit', 20))\n        user_id = request.args.get('user_id')  # Optional personalization\n\n        # Get ML-powered popular movies\n        result = movie_service.get_popular_movies(\n            limit=limit,\n            personalize_for_user=user_id\n        )\n\n        return jsonify({\n            \"success\": True,\n            \"message\": f\"Retrieved {len(result['movies'])} popular movies\",\n            \"data\": result\n        })\n\n    except Exception as e:\n        logger.error(f\"Error getting popular movies: {e}\")\n        return jsonify({\n            \"success\": False,\n            \"message\": \"Failed to retrieve popular movies\",\n            \"error\": str(e)\n        }), 500\n\n@movies_bp.route('/&lt;int:movie_id&gt;', methods=['GET'])\ndef get_movie_details(movie_id):\n    \"\"\"Get detailed movie information with ML-enhanced metadata.\"\"\"\n    try:\n        # Get base movie data\n        movie = movie_service.get_movie_by_id(movie_id)\n\n        if not movie:\n            return jsonify({\n                \"success\": False,\n                \"message\": \"Movie not found\"\n            }), 404\n\n        # Enhance with ML-generated similar movies\n        user_id = request.args.get('user_id')\n        similar_movies = movie_service.get_similar_movies(\n            movie_id=movie_id,\n            user_context={'user_id': user_id} if user_id else None,\n            limit=5\n        )\n\n        enhanced_movie = {\n            **movie,\n            'similar_movies': similar_movies,\n            'ml_enhanced': True\n        }\n\n        return jsonify({\n            \"success\": True,\n            \"data\": enhanced_movie\n        })\n\n    except Exception as e:\n        logger.error(f\"Error getting movie {movie_id}: {e}\")\n        return jsonify({\n            \"success\": False,\n            \"message\": \"Failed to retrieve movie details\"\n        }), 500\n</code></pre>"},{"location":"backend-frontend/ml-integration/#4-frontend-data-service-updates","title":"4. Frontend Data Service Updates","text":""},{"location":"backend-frontend/ml-integration/#step-1-enable-real-data-sources","title":"Step 1: Enable Real Data Sources","text":"<p>Update your environment configuration:</p> <pre><code># movie_genie/frontend/.env.development\n\n# Enable real data sources (set to true when ML integration is ready)\nVITE_USE_REAL_POPULAR=true\nVITE_USE_REAL_SEARCH=true\nVITE_USE_REAL_RECOMMENDATIONS=true\nVITE_USE_REAL_MOVIE_DETAILS=true\n</code></pre>"},{"location":"backend-frontend/ml-integration/#step-2-update-moviedataservice","title":"Step 2: Update MovieDataService","text":"<pre><code>// movie_genie/frontend/src/services/movieDataService.ts\n\nexport class MovieDataService {\n\n  // Enhanced popular movies with ML ranking\n  static async getPopularMovies(limit: number = 20, userId?: string): Promise&lt;MovieData[]&gt; {\n    if (DATA_SOURCE_CONFIG.popular) {\n      try {\n        console.log('\ud83d\udd04 Fetching ML-powered popular movies...');\n\n        // Include user context for personalization\n        const url = userId\n          ? `${API_ENDPOINTS.POPULAR_MOVIES}?limit=${limit}&amp;user_id=${userId}`\n          : `${API_ENDPOINTS.POPULAR_MOVIES}?limit=${limit}`;\n\n        const response = await fetch(url);\n        const data = await response.json();\n\n        if (data.success) {\n          const movies = data.data.movies?.map(this.transformApiMovie) || [];\n          console.log('\u2705 Got ML-powered popular movies:', movies.length);\n          return movies;\n        }\n\n      } catch (error) {\n        console.warn('\u26a0\ufe0f ML popular movies failed, falling back to mock data:', error);\n      }\n    }\n\n    console.log('\ud83d\udcdd Using mock popular movies');\n    return this.getMockPopularMovies(limit);\n  }\n\n  // Enhanced search with ML semantic search\n  static async searchMovies(query: string, limit: number = 20, userId?: string): Promise&lt;SearchResults&gt; {\n    if (DATA_SOURCE_CONFIG.search &amp;&amp; query.trim()) {\n      try {\n        console.log('\ud83d\udd04 Performing ML semantic search for:', query);\n\n        const searchParams = new URLSearchParams({\n          q: query,\n          limit: limit.toString(),\n          ...(userId &amp;&amp; { user_id: userId })\n        });\n\n        const response = await fetch(`${API_ENDPOINTS.SEMANTIC_SEARCH}?${searchParams}`);\n        const data = await response.json();\n\n        if (data.success) {\n          const movies = data.data.movies?.map(this.transformApiMovie) || [];\n          console.log('\u2705 Got ML search results:', movies.length);\n\n          return {\n            movies: movies.slice(0, limit),\n            total: data.data.total || movies.length,\n            query,\n            hasRealData: true,\n            mlMetadata: data.data.ml_metadata || {}\n          };\n        }\n\n      } catch (error) {\n        console.warn('\u26a0\ufe0f ML search failed, falling back to mock data:', error);\n      }\n    }\n\n    console.log('\ud83d\udcdd Using mock search results for:', query);\n    return this.getMockSearchResults(query, limit);\n  }\n\n  // Enhanced movie details with ML similar movies\n  static async getMovieDetails(movieId: string, userId?: string): Promise&lt;MovieData | null&gt; {\n    if (DATA_SOURCE_CONFIG.movieDetails) {\n      try {\n        console.log('\ud83d\udd04 Fetching ML-enhanced movie details for:', movieId);\n\n        const url = userId\n          ? `${API_ENDPOINTS.MOVIE_DETAILS(movieId)}?user_id=${userId}`\n          : API_ENDPOINTS.MOVIE_DETAILS(movieId);\n\n        const response = await fetch(url);\n        const data = await response.json();\n\n        if (data.success) {\n          console.log('\u2705 Got ML-enhanced movie details');\n          return this.transformApiMovie(data.data);\n        }\n\n      } catch (error) {\n        console.warn('\u26a0\ufe0f ML movie details failed, falling back to mock data:', error);\n      }\n    }\n\n    console.log('\ud83d\udcdd Using mock movie details for:', movieId);\n    return this.getMockMovieDetails(movieId);\n  }\n\n  // Transform API movie data (handles ML-specific fields)\n  private static transformApiMovie(apiMovie: any): MovieData {\n    return {\n      id: apiMovie.movieId?.toString() || apiMovie.id?.toString(),\n      title: apiMovie.title,\n      poster_url: apiMovie.poster_path ? `https://image.tmdb.org/t/p/w500${apiMovie.poster_path}` : null,\n      genres: apiMovie.genres || [],\n      rating: apiMovie.vote_average,\n      vote_average: apiMovie.vote_average,\n      overview: apiMovie.overview,\n      release_date: apiMovie.release_date,\n      runtime: apiMovie.runtime,\n\n      // ML-specific fields\n      personalized_score: apiMovie.personalized_score,\n      similarity_score: apiMovie.similarity_score,\n      rank: apiMovie.rank,\n      ml_enhanced: apiMovie.ml_enhanced || false,\n      similar_movies: apiMovie.similar_movies?.map(this.transformApiMovie) || []\n    };\n  }\n}\n</code></pre>"},{"location":"backend-frontend/ml-integration/#5-environment-configuration","title":"5. Environment Configuration","text":""},{"location":"backend-frontend/ml-integration/#development-vs-production-setup","title":"Development vs Production Setup","text":""},{"location":"backend-frontend/ml-integration/#development-environment","title":"Development Environment","text":"<pre><code># .env.development - Gradual ML integration\nVITE_USE_REAL_POPULAR=true          # Start with popular movies\nVITE_USE_REAL_SEARCH=false          # Keep search as mock for now\nVITE_USE_REAL_RECOMMENDATIONS=false # Keep recommendations as mock\nVITE_USE_REAL_MOVIE_DETAILS=false   # Keep details as mock\n</code></pre>"},{"location":"backend-frontend/ml-integration/#production-environment","title":"Production Environment","text":"<pre><code># .env.production - Full ML integration\nVITE_USE_REAL_POPULAR=true\nVITE_USE_REAL_SEARCH=true\nVITE_USE_REAL_RECOMMENDATIONS=true\nVITE_USE_REAL_MOVIE_DETAILS=true\n</code></pre>"},{"location":"backend-frontend/ml-integration/#6-testing-and-validation","title":"6. Testing and Validation","text":""},{"location":"backend-frontend/ml-integration/#step-1-backend-testing","title":"Step 1: Backend Testing","text":"<pre><code># test_ml_integration.py\n\nimport pytest\nfrom movie_genie.backend.app.services.recommendation_service import RecommendationService\n\ndef test_ml_personalized_recommendations():\n    \"\"\"Test ML-powered personalized recommendations.\"\"\"\n    service = RecommendationService()\n\n    # Test with real user ID\n    result = service.get_personalized_recommendations(user_id=\"123\", limit=10)\n\n    assert result['recommendation_type'] == 'personalized'\n    assert len(result['movies']) &lt;= 10\n    assert all('personalized_score' in movie for movie in result['movies'])\n    assert result['user_context']['model_used'] == 'bert4rec'\n\ndef test_ml_search_integration():\n    \"\"\"Test ML-powered semantic search.\"\"\"\n    service = SearchService()\n\n    result = service.semantic_search(query=\"action movies\", k=20)\n\n    assert result['search_type'] == 'semantic'\n    assert len(result['movies']) &lt;= 20\n    assert all('similarity_score' in movie for movie in result['movies'])\n</code></pre>"},{"location":"backend-frontend/ml-integration/#step-2-frontend-testing","title":"Step 2: Frontend Testing","text":"<pre><code>// Test real vs mock data switching\nconsole.log('Data source status:', MovieDataService.getDataSourceStatus());\n\n// Test ML-powered popular movies\nconst popularMovies = await MovieDataService.getPopularMovies(10, '123');\nconsole.log('Popular movies with ML:', popularMovies);\n\n// Test ML-powered search\nconst searchResults = await MovieDataService.searchMovies('action', 20, '123');\nconsole.log('Search results with ML:', searchResults);\n</code></pre>"},{"location":"backend-frontend/ml-integration/#step-3-ui-validation","title":"Step 3: UI Validation","text":"<ol> <li>Check Data Source Indicators: Look for \"\ud83c\udf10 Real Data\" badges in search results</li> <li>Verify ML Scores: Check hover tooltips show personalized/similarity scores</li> <li>Test Fallback Behavior: Disable ML services and verify graceful degradation</li> <li>Performance Monitoring: Check ML inference times in network tab</li> </ol>"},{"location":"backend-frontend/ml-integration/#quick-start-checklist","title":"\ud83d\ude80 Quick Start Checklist","text":""},{"location":"backend-frontend/ml-integration/#phase-1-popular-movies-integration","title":"Phase 1: Popular Movies Integration","text":"<ul> <li> Update <code>MovieService.get_popular_movies()</code> to use ML ranking</li> <li> Set <code>VITE_USE_REAL_POPULAR=true</code></li> <li> Test homepage carousels show real data</li> <li> Verify fallback works when ML service fails</li> </ul>"},{"location":"backend-frontend/ml-integration/#phase-2-search-integration","title":"Phase 2: Search Integration","text":"<ul> <li> Update <code>SearchService.semantic_search()</code> to use ML embeddings</li> <li> Set <code>VITE_USE_REAL_SEARCH=true</code></li> <li> Test search grid shows semantic results</li> <li> Verify data source indicator shows \"\ud83c\udf10 Real Data\"</li> </ul>"},{"location":"backend-frontend/ml-integration/#phase-3-recommendations-integration","title":"Phase 3: Recommendations Integration","text":"<ul> <li> Update <code>RecommendationService.get_personalized_recommendations()</code></li> <li> Set <code>VITE_USE_REAL_RECOMMENDATIONS=true</code></li> <li> Test personalized carousels show ML results</li> <li> Verify user context is passed correctly</li> </ul>"},{"location":"backend-frontend/ml-integration/#phase-4-movie-details-integration","title":"Phase 4: Movie Details Integration","text":"<ul> <li> Update <code>MovieService.get_movie_by_id()</code> to include similar movies</li> <li> Set <code>VITE_USE_REAL_MOVIE_DETAILS=true</code></li> <li> Test movie details panel shows enhanced data</li> <li> Verify similar movies section appears</li> </ul>"},{"location":"backend-frontend/ml-integration/#debugging-tips","title":"\ud83d\udd27 Debugging Tips","text":""},{"location":"backend-frontend/ml-integration/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<ol> <li> <p>ML Model Not Loading <pre><code># Add to service initialization\nif not self.bert4rec_reranker:\n    logger.error(\"BERT4Rec model failed to load - check model files\")\n    # Initialize fallback service\n</code></pre></p> </li> <li> <p>API Response Format Mismatch <pre><code>// Add response validation\nif (!data.success || !data.data) {\n    console.warn('Invalid API response format:', data);\n    throw new Error('Invalid response format');\n}\n</code></pre></p> </li> <li> <p>Performance Issues <pre><code># Add caching for expensive ML operations\n@lru_cache(maxsize=1000)\ndef get_cached_recommendations(user_id: str, cache_key: str):\n    return self.bert4rec_reranker.predict(user_id)\n</code></pre></p> </li> <li> <p>Frontend Data Source Confusion <pre><code>// Add clear logging\nconsole.log(`Using ${DATA_SOURCE_CONFIG.popular ? 'REAL' : 'MOCK'} data for popular movies`);\n</code></pre></p> </li> </ol> <p>This guide provides the complete integration path from your ML models to the user interface. Follow each phase sequentially, testing thoroughly before moving to the next integration point.</p>"},{"location":"data-pipeline/","title":"\ud83d\udd04 Data Pipeline Overview","text":"<p>Complete guide to Movie Genie's data processing and ML pipeline powered by DVC (Data Version Control).</p>"},{"location":"data-pipeline/#pipeline-overview","title":"\ud83c\udfaf Pipeline Overview","text":"<p>Movie Genie's data pipeline transforms raw MovieLens data into trained ML models through a series of reproducible stages:</p> <pre><code>Raw Data \u2192 Processing \u2192 Feature Engineering \u2192 Model Training \u2192 Deployment\n</code></pre>"},{"location":"data-pipeline/#table-of-contents","title":"\ud83d\udccb Table of Contents","text":""},{"location":"data-pipeline/#dvc-workflows","title":"\ud83d\udce6 DVC Workflows","text":"<p>Perfect for: Understanding data versioning and pipeline automation - DVC setup and configuration - Pipeline stage definitions - Dependency management and caching - Remote storage and collaboration</p>"},{"location":"data-pipeline/#data-processing","title":"\ud83e\uddf9 Data Processing","text":"<p>Perfect for: Understanding data transformation and cleaning - MovieLens dataset structure - Data cleaning and validation - User sequence generation - Database preparation</p>"},{"location":"data-pipeline/#feature-engineering","title":"\u2699\ufe0f Feature Engineering","text":"<p>Perfect for: Creating ML-ready features - Content feature extraction - User behavior encoding - Sequence preprocessing - Feature scaling and normalization</p>"},{"location":"data-pipeline/#complete-pipeline-flow","title":"\ud83d\udd04 Complete Pipeline Flow","text":""},{"location":"data-pipeline/#stage-1-data-ingestion","title":"Stage 1: Data Ingestion","text":"<pre><code># Download and extract MovieLens data\ndata/raw/ml-100k/\n\u251c\u2500\u2500 u.data      # 100k ratings\n\u251c\u2500\u2500 u.item      # Movie information\n\u251c\u2500\u2500 u.user      # User demographics\n\u2514\u2500\u2500 u.genre     # Genre definitions\n</code></pre>"},{"location":"data-pipeline/#stage-2-data-processing","title":"Stage 2: Data Processing","text":"<p><pre><code>dvc repro data_processing\n</code></pre> - Clean and validate raw data - Merge movie and rating information - Create user interaction sequences - Generate train/validation splits</p>"},{"location":"data-pipeline/#stage-3-feature-engineering","title":"Stage 3: Feature Engineering","text":"<p><pre><code>dvc repro feature_engineering\n</code></pre> - Extract content features from movie descriptions - Create user behavior embeddings - Generate item similarity matrices - Prepare model-specific input formats</p>"},{"location":"data-pipeline/#stage-4-model-training","title":"Stage 4: Model Training","text":"<p><pre><code>dvc repro train_bert4rec train_two_tower setup_semantic_search\n</code></pre> - Train sequential recommendation model (BERT4Rec) - Train collaborative filtering model (Two-Tower) - Setup semantic search with pre-trained embeddings</p>"},{"location":"data-pipeline/#stage-5-database-setup","title":"Stage 5: Database Setup","text":"<p><pre><code>dvc repro setup_database\n</code></pre> - Create SQLite database schema - Populate with processed data - Create indexes for fast queries - Validate data integrity</p>"},{"location":"data-pipeline/#stage-6-model-deployment","title":"Stage 6: Model Deployment","text":"<p><pre><code>dvc repro backend_server\n</code></pre> - Load trained models into Flask application - Start API server with ML endpoints - Serve frontend interface</p>"},{"location":"data-pipeline/#data-statistics","title":"\ud83d\udcca Data Statistics","text":""},{"location":"data-pipeline/#movielens-100k-dataset","title":"MovieLens 100K Dataset","text":"Metric Value Description Users 943 Unique users with ratings Movies 1,682 Unique movies in catalog Ratings 100,000 User-movie rating interactions Genres 19 Movie genre categories Rating Scale 1-5 Integer ratings from users Sparsity 93.7% Percentage of missing user-movie pairs"},{"location":"data-pipeline/#processed-data-output","title":"Processed Data Output","text":"Dataset Records Features Description Movies 1,682 25 Movie metadata with content features Users 943 10 User demographics and behavior stats Ratings 100,000 8 Timestamped user-movie interactions Sequences 943 Variable User interaction sequences for training Content Features 1,682 512 Semantic embeddings for movies"},{"location":"data-pipeline/#pipeline-configuration","title":"\ud83d\udee0\ufe0f Pipeline Configuration","text":""},{"location":"data-pipeline/#dvc-pipeline-definition-dvcyaml","title":"DVC Pipeline Definition (<code>dvc.yaml</code>)","text":"<pre><code>stages:\n  data_processing:\n    cmd: python scripts/process_movielens.py --input data/raw/ml-100k/ --output data/processed/\n    deps:\n      - data/raw/ml-100k/\n      - scripts/process_movielens.py\n    outs:\n      - data/processed/movies.parquet\n      - data/processed/ratings.parquet\n      - data/processed/users.parquet\n\n  feature_engineering:\n    cmd: python movie_genie/data/content_features.py --input data/processed/ --output data/processed/content_features.parquet\n    deps:\n      - data/processed/movies.parquet\n      - movie_genie/data/content_features.py\n    outs:\n      - data/processed/content_features.parquet\n\n  sequential_processing:\n    cmd: python movie_genie/data/sequential_processing.py --input data/processed/ --output data/processed/sequences_with_metadata.parquet\n    deps:\n      - data/processed/ratings.parquet\n      - data/processed/movies.parquet\n      - movie_genie/data/sequential_processing.py\n    outs:\n      - data/processed/sequences_with_metadata.parquet\n</code></pre>"},{"location":"data-pipeline/#parameter-configuration-paramsyaml","title":"Parameter Configuration (<code>params.yaml</code>)","text":"<pre><code>data_processing:\n  min_ratings_per_user: 20\n  min_ratings_per_movie: 5\n  test_split_ratio: 0.2\n  random_seed: 42\n\nfeature_engineering:\n  embedding_dim: 512\n  max_sequence_length: 50\n  content_features:\n    - title\n    - genres\n    - release_year\n\nmodel_training:\n  bert4rec:\n    hidden_size: 128\n    num_layers: 4\n    num_heads: 8\n    batch_size: 256\n    learning_rate: 0.001\n    epochs: 50\n\n  two_tower:\n    embedding_dim: 64\n    hidden_dims: [128, 64]\n    batch_size: 512\n    learning_rate: 0.001\n    epochs: 100\n</code></pre>"},{"location":"data-pipeline/#pipeline-management","title":"\ud83d\udd27 Pipeline Management","text":""},{"location":"data-pipeline/#running-the-pipeline","title":"Running the Pipeline","text":"<pre><code># Run entire pipeline\ndvc repro\n\n# Run specific stage\ndvc repro data_processing\n\n# Run with force (ignore cache)\ndvc repro --force\n\n# Run downstream stages\ndvc repro --downstream train_bert4rec\n</code></pre>"},{"location":"data-pipeline/#monitoring-pipeline-status","title":"Monitoring Pipeline Status","text":"<pre><code># Check what needs to be reproduced\ndvc status\n\n# Show pipeline graph\ndvc dag\n\n# Show detailed pipeline info\ndvc pipeline show --ascii\n</code></pre>"},{"location":"data-pipeline/#cache-management","title":"Cache Management","text":"<pre><code># Check cache status\ndvc cache dir\n\n# Clean unused cache\ndvc gc\n\n# Show cache statistics\ndvc cache size\n</code></pre>"},{"location":"data-pipeline/#data-quality-monitoring","title":"\ud83d\udcc8 Data Quality Monitoring","text":""},{"location":"data-pipeline/#validation-checks","title":"Validation Checks","text":"<pre><code># Data quality validation in pipeline\ndef validate_data_quality(df):\n    checks = {\n        'no_null_ids': df['movie_id'].notna().all(),\n        'ratings_in_range': df['rating'].between(1, 5).all(),\n        'valid_timestamps': df['timestamp'] &gt; 0,\n        'sufficient_interactions': len(df) &gt;= 10000\n    }\n    return all(checks.values()), checks\n</code></pre>"},{"location":"data-pipeline/#monitoring-metrics","title":"Monitoring Metrics","text":"Metric Threshold Description Data Completeness &gt; 95% Percentage of non-null values Rating Distribution 1-5 range Valid rating values User Activity 20+ ratings Minimum interactions per user Movie Popularity 5+ ratings Minimum ratings per movie"},{"location":"data-pipeline/#performance-optimization","title":"\ud83d\ude80 Performance Optimization","text":""},{"location":"data-pipeline/#pipeline-optimization","title":"Pipeline Optimization","text":"<pre><code># Use parallel processing\ndvc repro --force-downstream -j 4\n\n# Cache optimization\ndvc config cache.type symlink\ndvc config cache.protected true\n\n# Remote cache for team collaboration\ndvc remote add -d myremote s3://my-bucket/dvc-cache\n</code></pre>"},{"location":"data-pipeline/#data-processing-optimization","title":"Data Processing Optimization","text":"<pre><code># Use efficient data formats\ndf.to_parquet('output.parquet', compression='snappy')\n\n# Batch processing for large datasets\nfor chunk in pd.read_csv('large_file.csv', chunksize=10000):\n    process_chunk(chunk)\n\n# Memory-efficient operations\ndf = df.pipe(clean_data).pipe(add_features).pipe(validate)\n</code></pre>"},{"location":"data-pipeline/#debugging-pipeline-issues","title":"\ud83d\udd0d Debugging Pipeline Issues","text":""},{"location":"data-pipeline/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"data-pipeline/#stage-not-found-error","title":"\"Stage not found\" Error","text":"<pre><code># Check pipeline definition\ncat dvc.yaml\n\n# Verify stage name\ndvc dag | grep stage_name\n</code></pre>"},{"location":"data-pipeline/#dependencies-not-found-error","title":"\"Dependencies not found\" Error","text":"<pre><code># Check file paths\nls -la data/raw/ml-100k/\n\n# Verify dependencies\ndvc status --verbose\n</code></pre>"},{"location":"data-pipeline/#out-of-memory-error","title":"\"Out of memory\" Error","text":"<pre><code># Reduce batch size in params.yaml\nbatch_size: 128  # Instead of 512\n\n# Use chunked processing\nchunk_size: 1000\n</code></pre>"},{"location":"data-pipeline/#permission-denied-error","title":"\"Permission denied\" Error","text":"<pre><code># Fix file permissions\nchmod +x scripts/process_movielens.py\n\n# Check directory permissions\nls -la data/\n</code></pre>"},{"location":"data-pipeline/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"data-pipeline/#pipeline-best-practices","title":"Pipeline Best Practices","text":"<ul> <li>Modular Stages: Keep stages small and focused</li> <li>Clear Dependencies: Explicit input/output relationships</li> <li>Parameterization: Use <code>params.yaml</code> for configuration</li> <li>Validation: Add data quality checks at each stage</li> <li>Documentation: Comment complex processing logic</li> </ul>"},{"location":"data-pipeline/#scaling-considerations","title":"Scaling Considerations","text":"<ul> <li>Large Datasets: Use Dask or Spark for parallel processing</li> <li>Remote Compute: Run pipeline on cloud instances</li> <li>Distributed Storage: Use cloud storage for data artifacts</li> <li>Pipeline Orchestration: Consider Airflow for complex workflows</li> </ul> <p>This data pipeline provides the foundation for reproducible ML workflows. Each stage is designed to be modular, testable, and scalable for real-world applications. \ud83d\udd04</p>"},{"location":"getting-started/","title":"\ud83d\ude80 Getting Started with Movie Genie","text":"<p>Welcome! This section will get you up and running with Movie Genie quickly and efficiently.</p>"},{"location":"getting-started/#whats-in-this-section","title":"\ud83d\udcda What's in This Section","text":"<ul> <li> <p> Quick Start Guide</p> <p>Perfect for developers who want to see the system working ASAP</p> <ul> <li>Get the application running in 5 minutes</li> <li>Basic commands to test functionality</li> <li>Quick validation that everything works</li> </ul> <p> Quick Start</p> </li> <li> <p> Installation Guide</p> <p>Perfect for detailed setup and environment configuration</p> <ul> <li>Prerequisites and system requirements</li> <li>Step-by-step installation process</li> <li>Development environment setup</li> <li>Troubleshooting installation issues</li> </ul> <p> Installation</p> </li> <li> <p> Project Overview</p> <p>Perfect for understanding what Movie Genie does and how</p> <ul> <li>System architecture and design decisions</li> <li>Key features and capabilities</li> <li>Technology stack explanation</li> <li>Use cases and applications</li> </ul> <p> Project Overview</p> </li> <li> <p> Commands Reference</p> <p>Perfect for daily development and operations</p> <ul> <li>Complete list of all commands</li> <li>DVC pipeline commands</li> <li>Development server commands</li> <li>Database and data management commands</li> <li>Testing and validation commands</li> </ul> <p> Commands Reference</p> </li> </ul>"},{"location":"getting-started/#recommended-learning-path","title":"\ud83c\udfaf Recommended Learning Path","text":""},{"location":"getting-started/#for-complete-beginners","title":"For Complete Beginners:","text":"<ol> <li>Read Project Overview to understand what we're building</li> <li>Follow Installation Guide for detailed setup</li> <li>Use Commands Reference as your daily helper</li> </ol>"},{"location":"getting-started/#for-experienced-developers","title":"For Experienced Developers:","text":"<ol> <li>Jump to Quick Start Guide to get running immediately</li> <li>Refer to Commands Reference for specific operations</li> <li>Browse Project Overview for architecture details</li> </ol>"},{"location":"getting-started/#for-ml-engineers","title":"For ML Engineers:","text":"<ol> <li>Start with Project Overview for system design</li> <li>Follow Quick Start Guide to see ML models in action</li> <li>Move to Machine Learning docs for model details</li> </ol>"},{"location":"getting-started/#what-youll-learn","title":"\ud83d\udd0d What You'll Learn","text":"<p>After completing this section, you'll be able to:</p> <ul> <li>\u2705 Set up a complete ML recommendation system</li> <li>\u2705 Run DVC pipelines for data processing and model training</li> <li>\u2705 Start the full-stack application (backend + frontend)</li> <li>\u2705 Navigate the user interface and test recommendations</li> <li>\u2705 Understand the overall system architecture</li> <li>\u2705 Use key commands for development and maintenance</li> </ul>"},{"location":"getting-started/#prerequisites","title":"\ud83d\udee0\ufe0f Prerequisites","text":"<ul> <li>Python 3.8+ (for ML models and backend)</li> <li>Node.js 16+ (for frontend development)</li> <li>Git (for version control)</li> <li>8GB+ RAM (for ML model training)</li> <li>5GB+ disk space (for data and models)</li> </ul>"},{"location":"getting-started/#need-help","title":"\ud83c\udd98 Need Help?","text":"<ul> <li>Installation Issues: Check Installation Guide troubleshooting section</li> <li>Command Problems: See Commands Reference for exact syntax</li> <li>General Issues: Visit Troubleshooting section</li> <li>Architecture Questions: Read Project Overview</li> </ul> <p>Ready to build an AI-powered movie recommendation system? Let's get started! \ud83c\udfac</p>"},{"location":"getting-started/commands-reference/","title":"\ud83d\udccb Commands Reference","text":"<p>Complete reference of all commands you'll need for developing, running, and maintaining Movie Genie.</p>"},{"location":"getting-started/commands-reference/#quick-start-commands","title":"\ud83d\ude80 Quick Start Commands","text":""},{"location":"getting-started/commands-reference/#essential-commands","title":"Essential Commands","text":"<pre><code># 1. Install the project\npip install -e .\n\n# 2. Run the complete pipeline\ndvc repro\n\n# 3. Access the application\n# Open browser to: http://127.0.0.1:5001\n</code></pre>"},{"location":"getting-started/commands-reference/#dvc-pipeline-commands","title":"\ud83d\udce6 DVC Pipeline Commands","text":""},{"location":"getting-started/commands-reference/#run-complete-pipeline","title":"Run Complete Pipeline","text":"<pre><code># Run all stages from data processing to deployment\ndvc repro\n\n# Run specific stage\ndvc repro stage_name\n\n# Run stages up to a specific point\ndvc repro --downstream stage_name\n</code></pre>"},{"location":"getting-started/commands-reference/#check-pipeline-status","title":"Check Pipeline Status","text":"<pre><code># Check what needs to be reproduced\ndvc status\n\n# Show pipeline graph\ndvc dag\n\n# Show detailed pipeline information\ndvc pipeline show --ascii\n</code></pre>"},{"location":"getting-started/commands-reference/#manage-data-and-models","title":"Manage Data and Models","text":"<pre><code># Add data to DVC tracking\ndvc add data/raw/movies.csv\n\n# Download data from remote storage\ndvc pull\n\n# Upload data to remote storage\ndvc push\n\n# Check data status\ndvc data status\n</code></pre>"},{"location":"getting-started/commands-reference/#data-processing-commands","title":"\ud83d\udd04 Data Processing Commands","text":""},{"location":"getting-started/commands-reference/#database-operations","title":"Database Operations","text":"<pre><code># Remove existing database and test fresh setup\nrm -f movie_genie.db*\npython test_db.py\n\n# Initialize database with fresh data\npython scripts/setup_database.py\n\n# Backup database\ncp movie_genie/backend/movie_genie.db movie_genie_backup.db\n</code></pre>"},{"location":"getting-started/commands-reference/#data-scraping-and-collection","title":"Data Scraping and Collection","text":"<pre><code># Run IMDB reviews scraper\npython scripts/imdb_featured_reviews.py \\\n  --links-csv data/raw/ml-100k/links.csv \\\n  --limit 25 \\\n  --out data/raw/imdb-reviews/ml-100k_reviews.csv \\\n  --lang en \\\n  --min-delay 0.05 \\\n  --max-delay 0.1 \\\n  --checkpoint data/raw/imdb-reviews/ml-100k_checkpoint.json \\\n  --filter-by-movies\n\n# Process MovieLens data\npython scripts/process_movielens.py \\\n  --input data/raw/ml-100k/ \\\n  --output data/processed/\n</code></pre>"},{"location":"getting-started/commands-reference/#feature-engineering","title":"Feature Engineering","text":"<pre><code># Generate content features\npython movie_genie/data/content_features.py \\\n  --input data/raw/ \\\n  --output data/processed/content_features.parquet\n\n# Create user sequences\npython movie_genie/data/sequential_processing.py \\\n  --input data/processed/ \\\n  --output data/processed/sequences_with_metadata.parquet\n</code></pre>"},{"location":"getting-started/commands-reference/#ml-model-commands","title":"\ud83e\udde0 ML Model Commands","text":""},{"location":"getting-started/commands-reference/#model-training","title":"Model Training","text":"<pre><code># Train BERT4Rec model\npython movie_genie/ranking/train_bert4rec.py \\\n  --config configs/bert4rec_config.yaml \\\n  --data data/processed/sequences_with_metadata.parquet \\\n  --output models/bert4rec/\n\n# Train Two-Tower model\npython movie_genie/retrieval/train_two_tower.py \\\n  --config configs/two_tower_config.yaml \\\n  --data data/processed/ \\\n  --output models/two_tower/\n\n# Setup semantic search\npython movie_genie/search/setup_semantic_search.py \\\n  --config configs/semantic_search.yaml \\\n  --data data/processed/content_features.parquet\n</code></pre>"},{"location":"getting-started/commands-reference/#model-evaluation","title":"Model Evaluation","text":"<pre><code># Run integrated evaluation\npython movie_genie/evaluation/integrated_evaluation.py \\\n  --config configs/evaluation_config.yaml \\\n  --models models/ \\\n  --data data/processed/ \\\n  --output results/\n\n# Generate evaluation report\npython scripts/generate_evaluation_report.py \\\n  --results results/ \\\n  --output reports/model_comparison.html\n</code></pre>"},{"location":"getting-started/commands-reference/#model-testing","title":"Model Testing","text":"<pre><code># Test BERT4Rec predictions\npython -c \"\nfrom movie_genie.ranking.bert4rec_model import BERT4RecReranker\nreranker = BERT4RecReranker('models/bert4rec/')\nprint(reranker.predict(user_id=123, num_recommendations=10))\n\"\n\n# Test semantic search\npython -c \"\nfrom movie_genie.search.semantic_engine import SemanticSearchEngine\nengine = SemanticSearchEngine('configs/semantic_search.yaml')\nprint(engine.search('action movies with robots', k=10))\n\"\n</code></pre>"},{"location":"getting-started/commands-reference/#backend-frontend-commands","title":"\ud83c\udf10 Backend &amp; Frontend Commands","text":""},{"location":"getting-started/commands-reference/#backend-development","title":"Backend Development","text":"<pre><code># Start backend server (development)\ncd movie_genie/backend\npython app.py\n\n# Start backend with specific port\nFLASK_PORT=5001 python app.py\n\n# Start with production settings\nFLASK_ENV=production python app.py\n\n# Test API endpoints\ncurl http://127.0.0.1:5001/api/health\ncurl http://127.0.0.1:5001/api/users/info\ncurl \"http://127.0.0.1:5001/api/search/semantic?q=action%20movies\"\n</code></pre>"},{"location":"getting-started/commands-reference/#frontend-development","title":"Frontend Development","text":"<pre><code># Install frontend dependencies\ncd movie_genie/frontend\nnpm install\n\n# Start development server\nnpm run dev\n\n# Build for production\nnpm run build\n\n# Preview production build\nnpm run preview\n\n# Run type checking\nnpm run type-check\n\n# Run linting\nnpm run lint\n</code></pre>"},{"location":"getting-started/commands-reference/#full-stack-development","title":"Full-Stack Development","text":"<pre><code># Run both backend and frontend in development\n# Terminal 1: Backend\ncd movie_genie/backend &amp;&amp; python app.py\n\n# Terminal 2: Frontend\ncd movie_genie/frontend &amp;&amp; npm run dev\n\n# Or use DVC pipeline for integrated setup\ndvc repro backend_server\n</code></pre>"},{"location":"getting-started/commands-reference/#testing-commands","title":"\ud83e\uddea Testing Commands","text":""},{"location":"getting-started/commands-reference/#backend-testing","title":"Backend Testing","text":"<pre><code># Run all backend tests\npytest movie_genie/backend/tests/\n\n# Run specific test file\npytest movie_genie/backend/tests/test_api.py\n\n# Run with coverage\npytest --cov=movie_genie movie_genie/backend/tests/\n\n# Test specific API endpoint\npytest movie_genie/backend/tests/test_api.py::test_user_info_endpoint\n</code></pre>"},{"location":"getting-started/commands-reference/#frontend-testing","title":"Frontend Testing","text":"<pre><code># Run frontend tests\ncd movie_genie/frontend\nnpm test\n\n# Run tests in watch mode\nnpm run test:watch\n\n# Run tests with coverage\nnpm run test:coverage\n\n# Run end-to-end tests\nnpm run test:e2e\n</code></pre>"},{"location":"getting-started/commands-reference/#integration-testing","title":"Integration Testing","text":"<pre><code># Test full pipeline\npython scripts/test_full_pipeline.py\n\n# Test ML model integration\npython tests/test_ml_integration.py\n\n# Test API integration\npython tests/test_api_integration.py\n</code></pre>"},{"location":"getting-started/commands-reference/#deployment-commands","title":"\ud83d\udc33 Deployment Commands","text":""},{"location":"getting-started/commands-reference/#docker-deployment","title":"Docker Deployment","text":"<pre><code># Build Docker image\ndocker build -t movie-genie .\n\n# Run Docker container\ndocker run -p 5001:5001 movie-genie\n\n# Run with Docker Compose\ndocker-compose up -d\n\n# Check logs\ndocker logs movie-genie\ndocker-compose logs -f\n</code></pre>"},{"location":"getting-started/commands-reference/#production-deployment","title":"Production Deployment","text":"<pre><code># Install production dependencies\npip install -r requirements.txt --no-dev\n\n# Run with Gunicorn\ngunicorn -w 4 -b 0.0.0.0:5001 movie_genie.backend.app:app\n\n# Run with systemd service\nsudo systemctl start movie-genie\nsudo systemctl enable movie-genie\nsudo systemctl status movie-genie\n</code></pre>"},{"location":"getting-started/commands-reference/#development-utilities","title":"\ud83d\udd27 Development Utilities","text":""},{"location":"getting-started/commands-reference/#code-quality","title":"Code Quality","text":"<pre><code># Format Python code\nblack movie_genie/\nisort movie_genie/\n\n# Lint Python code\nflake8 movie_genie/\npylint movie_genie/\n\n# Type checking\nmypy movie_genie/\n\n# Format frontend code\ncd movie_genie/frontend\nnpm run format\nnpm run lint:fix\n</code></pre>"},{"location":"getting-started/commands-reference/#environment-management","title":"Environment Management","text":"<pre><code># Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install development dependencies\npip install -e \".[dev]\"\n\n# Update dependencies\npip-tools compile requirements.in\npip-sync requirements.txt\n\n# Check environment\npip list\npip check\n</code></pre>"},{"location":"getting-started/commands-reference/#data-management","title":"Data Management","text":"<pre><code># Clean generated files\nrm -rf models/ results/ metrics/\ndvc cache dir --unset\n\n# Reset to clean state\ndvc clean\ngit clean -fdx\n\n# Check data integrity\ndvc data status\ndvc check-ignore data/\n</code></pre>"},{"location":"getting-started/commands-reference/#debugging-commands","title":"\ud83d\udd0d Debugging Commands","text":""},{"location":"getting-started/commands-reference/#backend-debugging","title":"Backend Debugging","text":"<pre><code># Run backend with debug mode\nFLASK_ENV=development FLASK_DEBUG=1 python movie_genie/backend/app.py\n\n# Check database content\nsqlite3 movie_genie/backend/movie_genie.db\n.tables\nSELECT COUNT(*) FROM movies;\nSELECT COUNT(*) FROM ratings;\n\n# Monitor API requests\ntail -f movie_genie/backend/logs/app.log\n</code></pre>"},{"location":"getting-started/commands-reference/#frontend-debugging","title":"Frontend Debugging","text":"<pre><code># Start with verbose logging\ncd movie_genie/frontend\nVITE_LOG_LEVEL=debug npm run dev\n\n# Check bundle size\nnpm run build-analyze\n\n# Debug network requests\n# Open browser dev tools \u2192 Network tab\n</code></pre>"},{"location":"getting-started/commands-reference/#ml-model-debugging","title":"ML Model Debugging","text":"<pre><code># Check model files\nls -la models/bert4rec/\nls -la models/two_tower/\n\n# Verify model loading\npython -c \"\nimport torch\nmodel = torch.load('models/bert4rec/bert4rec_model.pth')\nprint(f'Model type: {type(model)}')\nprint(f'Model keys: {model.keys() if isinstance(model, dict) else \\\"Not a dict\\\"}')\"\n\n# Test data loading\npython -c \"\nimport pandas as pd\ndf = pd.read_parquet('data/processed/content_features.parquet')\nprint(f'Data shape: {df.shape}')\nprint(f'Columns: {df.columns.tolist()}')\"\n</code></pre>"},{"location":"getting-started/commands-reference/#monitoring-commands","title":"\ud83d\udcca Monitoring Commands","text":""},{"location":"getting-started/commands-reference/#system-health","title":"System Health","text":"<pre><code># Check API health\ncurl http://127.0.0.1:5001/api/health\n\n# Monitor system resources\nhtop\nnvidia-smi  # If using GPU\n\n# Check application logs\ntail -f movie_genie/backend/logs/app.log\njournalctl -u movie-genie -f\n</code></pre>"},{"location":"getting-started/commands-reference/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code># Profile Python code\npython -m cProfile -o profile.stats movie_genie/ranking/train_bert4rec.py\npython -c \"import pstats; pstats.Stats('profile.stats').sort_stats('cumulative').print_stats(10)\"\n\n# Monitor memory usage\npython -m memory_profiler movie_genie/ranking/train_bert4rec.py\n\n# Check disk usage\ndu -sh data/ models/ results/\ndf -h\n</code></pre>"},{"location":"getting-started/commands-reference/#emergency-commands","title":"\ud83c\udd98 Emergency Commands","text":""},{"location":"getting-started/commands-reference/#quick-recovery","title":"Quick Recovery","text":"<pre><code># Reset everything to working state\ngit stash\ngit checkout main\ndvc checkout\ndvc repro\n\n# Restore from backup\ncp movie_genie_backup.db movie_genie/backend/movie_genie.db\n\n# Force rebuild everything\ndvc clean --all\ndvc repro --force\n</code></pre>"},{"location":"getting-started/commands-reference/#clean-installation","title":"Clean Installation","text":"<pre><code># Remove all generated files\nrm -rf .venv/ models/ data/processed/ results/\nrm -f movie_genie/backend/movie_genie.db\n\n# Fresh installation\npython -m venv .venv\nsource .venv/bin/activate\npip install -e .\ndvc repro\n</code></pre> <p>Keep this reference handy during development. Most daily tasks can be accomplished with these commands! \ud83d\udcda</p>"},{"location":"getting-started/installation/","title":"\ud83d\udd27 Installation Guide","text":"<p>Complete step-by-step installation instructions for Movie Genie development environment.</p>"},{"location":"getting-started/installation/#prerequisites","title":"\ud83d\udccb Prerequisites","text":""},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":"<ul> <li>OS: macOS, Linux, or Windows (WSL recommended)</li> <li>Python: 3.8 or higher</li> <li>Node.js: 16.0 or higher</li> <li>Git: Latest version</li> <li>Memory: 8GB+ RAM (for ML model training)</li> <li>Storage: 5GB+ free disk space</li> </ul>"},{"location":"getting-started/installation/#check-your-system","title":"Check Your System","text":"<pre><code># Check Python version\npython --version  # Should be 3.8+\n\n# Check Node.js version\nnode --version    # Should be 16+\n\n# Check Git\ngit --version\n\n# Check available memory\nfree -h  # Linux/macOS\n</code></pre>"},{"location":"getting-started/installation/#installation-steps","title":"\ud83d\ude80 Installation Steps","text":""},{"location":"getting-started/installation/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<pre><code># Clone the project\ngit clone &lt;repository-url&gt;\ncd movie-genie\n\n# Verify the directory structure\nls -la\n</code></pre> <p>You should see: <pre><code>movie_genie/\n\u251c\u2500\u2500 configs/\n\u251c\u2500\u2500 data/\n\u251c\u2500\u2500 docs/\n\u251c\u2500\u2500 movie_genie/\n\u251c\u2500\u2500 scripts/\n\u251c\u2500\u2500 dvc.yaml\n\u251c\u2500\u2500 params.yaml\n\u2514\u2500\u2500 pyproject.toml\n</code></pre></p>"},{"location":"getting-started/installation/#step-2-create-virtual-environment","title":"Step 2: Create Virtual Environment","text":"<pre><code># Create virtual environment\npython -m venv .venv\n\n# Activate virtual environment\nsource .venv/bin/activate  # macOS/Linux\n# OR\n.venv\\Scripts\\activate     # Windows\n</code></pre>"},{"location":"getting-started/installation/#step-3-install-python-dependencies","title":"Step 3: Install Python Dependencies","text":"<pre><code># Install project with development dependencies\npip install -e \".[dev]\"\n\n# Verify installation\npip list | grep movie-genie\n</code></pre>"},{"location":"getting-started/installation/#step-4-install-frontend-dependencies","title":"Step 4: Install Frontend Dependencies","text":"<pre><code># Navigate to frontend directory\ncd movie_genie/frontend\n\n# Install Node.js dependencies\nnpm install\n\n# Verify installation\nnpm list --depth=0\n\n# Return to project root\ncd ../..\n</code></pre>"},{"location":"getting-started/installation/#step-5-initialize-dvc","title":"Step 5: Initialize DVC","text":"<pre><code># Initialize DVC (if not already done)\ndvc init --no-scm  # Use if not using git\n# OR\ndvc init          # Use if using git\n\n# Check DVC status\ndvc status\n</code></pre>"},{"location":"getting-started/installation/#development-environment-setup","title":"\ud83d\udd27 Development Environment Setup","text":""},{"location":"getting-started/installation/#configure-environment-variables","title":"Configure Environment Variables","text":""},{"location":"getting-started/installation/#backend-environment","title":"Backend Environment","text":"<pre><code># Create backend environment file\ncat &gt; movie_genie/backend/.env &lt;&lt; EOF\nFLASK_ENV=development\nFLASK_DEBUG=1\nFLASK_PORT=5001\nDATABASE_URL=sqlite:///movie_genie.db\nLOG_LEVEL=DEBUG\nEOF\n</code></pre>"},{"location":"getting-started/installation/#frontend-environment","title":"Frontend Environment","text":"<pre><code># Create frontend environment file\ncat &gt; movie_genie/frontend/.env.development &lt;&lt; EOF\nVITE_API_URL=http://127.0.0.1:5001/api\nVITE_USE_REAL_POPULAR=false\nVITE_USE_REAL_SEARCH=false\nVITE_USE_REAL_RECOMMENDATIONS=false\nVITE_USE_REAL_MOVIE_DETAILS=false\nEOF\n</code></pre>"},{"location":"getting-started/installation/#ide-configuration","title":"IDE Configuration","text":""},{"location":"getting-started/installation/#vs-code-setup","title":"VS Code Setup","text":"<pre><code># Install recommended extensions\ncode --install-extension ms-python.python\ncode --install-extension bradlc.vscode-tailwindcss\ncode --install-extension esbenp.prettier-vscode\ncode --install-extension ms-vscode.vscode-typescript-next\n\n# Open project\ncode .\n</code></pre>"},{"location":"getting-started/installation/#pycharm-setup","title":"PyCharm Setup","text":"<ol> <li>Open the project directory</li> <li>Configure Python interpreter to use <code>.venv/bin/python</code></li> <li>Mark <code>movie_genie/</code> as source root</li> <li>Enable DVC integration if available</li> </ol>"},{"location":"getting-started/installation/#data-setup","title":"\ud83d\udce6 Data Setup","text":""},{"location":"getting-started/installation/#download-initial-data","title":"Download Initial Data","text":"<pre><code># If using remote DVC storage\ndvc pull\n\n# OR manually download MovieLens data\nmkdir -p data/raw/ml-100k\ncurl -O http://files.grouplens.org/datasets/movielens/ml-100k.zip\nunzip ml-100k.zip -d data/raw/\n</code></pre>"},{"location":"getting-started/installation/#initialize-database","title":"Initialize Database","text":"<pre><code># Run initial data processing\ndvc repro data_processing\n\n# Verify database creation\nls -la movie_genie/backend/movie_genie.db\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"\ud83e\uddea Verify Installation","text":""},{"location":"getting-started/installation/#test-backend","title":"Test Backend","text":"<pre><code># Start backend server\ncd movie_genie/backend\npython app.py\n\n# In another terminal, test API\ncurl http://127.0.0.1:5001/api/health\n</code></pre> <p>Expected response: <pre><code>{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2024-01-01T12:00:00\",\n  \"version\": \"1.0.0\"\n}\n</code></pre></p>"},{"location":"getting-started/installation/#test-frontend","title":"Test Frontend","text":"<pre><code># Start frontend development server\ncd movie_genie/frontend\nnpm run dev\n\n# Open browser to http://localhost:5173\n</code></pre>"},{"location":"getting-started/installation/#test-full-pipeline","title":"Test Full Pipeline","text":"<pre><code># Run complete pipeline\ndvc repro\n\n# Check all stages completed\ndvc status\n</code></pre>"},{"location":"getting-started/installation/#tool-installation","title":"\ud83d\udee0\ufe0f Tool Installation","text":""},{"location":"getting-started/installation/#optional-development-tools","title":"Optional Development Tools","text":""},{"location":"getting-started/installation/#code-formatting","title":"Code Formatting","text":"<pre><code># Python formatters\npip install black isort flake8 mypy\n\n# Frontend formatters are included in package.json\n</code></pre>"},{"location":"getting-started/installation/#database-tools","title":"Database Tools","text":"<pre><code># SQLite browser (optional)\n# macOS\nbrew install --cask db-browser-for-sqlite\n\n# Ubuntu/Debian\nsudo apt install sqlitebrowser\n\n# Windows\n# Download from https://sqlitebrowser.org/\n</code></pre>"},{"location":"getting-started/installation/#monitoring-tools","title":"Monitoring Tools","text":"<pre><code># System monitoring\npip install htop psutil\n\n# GPU monitoring (if using CUDA)\nnvidia-smi\n</code></pre>"},{"location":"getting-started/installation/#configuration","title":"\ud83d\udd27 Configuration","text":""},{"location":"getting-started/installation/#dvc-configuration","title":"DVC Configuration","text":"<pre><code># Configure DVC cache (optional)\ndvc config cache.type symlink\ndvc config cache.protected true\n\n# Add remote storage (optional)\ndvc remote add -d myremote s3://my-bucket/dvc-storage\n</code></pre>"},{"location":"getting-started/installation/#git-configuration","title":"Git Configuration","text":"<pre><code># Configure Git for DVC\ngit config core.autocrlf input  # Handle line endings\n</code></pre>"},{"location":"getting-started/installation/#python-path-configuration","title":"Python Path Configuration","text":"<pre><code># Add to your shell profile (~/.bashrc, ~/.zshrc)\nexport PYTHONPATH=\"${PYTHONPATH}:$(pwd)\"\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting-installation","title":"\ud83c\udd98 Troubleshooting Installation","text":""},{"location":"getting-started/installation/#common-issues","title":"Common Issues","text":""},{"location":"getting-started/installation/#python-version-conflicts","title":"Python Version Conflicts","text":"<pre><code># Use pyenv to manage Python versions\ncurl https://pyenv.run | bash\npyenv install 3.9.0\npyenv local 3.9.0\n</code></pre>"},{"location":"getting-started/installation/#permission-errors","title":"Permission Errors","text":"<pre><code># Fix pip permissions\npip install --user -e .\n\n# OR use virtual environment (recommended)\npython -m venv .venv\nsource .venv/bin/activate\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#nodejs-issues","title":"Node.js Issues","text":"<pre><code># Clear npm cache\nnpm cache clean --force\n\n# Delete node_modules and reinstall\nrm -rf movie_genie/frontend/node_modules\ncd movie_genie/frontend\nnpm install\n</code></pre>"},{"location":"getting-started/installation/#dvc-issues","title":"DVC Issues","text":"<pre><code># Reset DVC cache\ndvc cache dir --unset\ndvc cache dir .dvc/cache\n\n# Reinitialize DVC\nrm -rf .dvc\ndvc init\n</code></pre>"},{"location":"getting-started/installation/#database-permissions","title":"Database Permissions","text":"<pre><code># Fix SQLite permissions\nchmod 664 movie_genie/backend/movie_genie.db\nchmod 775 movie_genie/backend/\n</code></pre>"},{"location":"getting-started/installation/#performance-issues","title":"Performance Issues","text":""},{"location":"getting-started/installation/#slow-model-training","title":"Slow Model Training","text":"<pre><code># Check if using GPU\npython -c \"import torch; print(torch.cuda.is_available())\"\n\n# Reduce model size in configs/\n# Edit configs/bert4rec_config.yaml:\n# hidden_size: 64  # Reduce from 128\n# num_layers: 2    # Reduce from 4\n</code></pre>"},{"location":"getting-started/installation/#memory-issues","title":"Memory Issues","text":"<pre><code># Monitor memory usage\nhtop\n\n# Reduce batch sizes in configs/\n# Edit configs/two_tower_config.yaml:\n# batch_size: 128  # Reduce from 512\n</code></pre>"},{"location":"getting-started/installation/#installation-checklist","title":"\u2705 Installation Checklist","text":"<ul> <li> Python 3.8+ installed and activated in virtual environment</li> <li> Node.js 16+ installed</li> <li> Git configured</li> <li> Project dependencies installed (<code>pip install -e .</code>)</li> <li> Frontend dependencies installed (<code>npm install</code>)</li> <li> Environment variables configured</li> <li> DVC initialized</li> <li> Database created and accessible</li> <li> Backend API responding (<code>curl http://127.0.0.1:5001/api/health</code>)</li> <li> Frontend development server running (<code>npm run dev</code>)</li> <li> Full pipeline executable (<code>dvc repro</code>)</li> </ul>"},{"location":"getting-started/installation/#next-steps","title":"\ud83d\ude80 Next Steps","text":"<ol> <li>Quick Start: Follow Quick Start Guide to see the system in action</li> <li>Architecture: Read Project Overview to understand the system</li> <li>Development: Start with Commands Reference for daily operations</li> <li>ML Models: Explore ML Documentation for model details</li> </ol> <p>Installation complete! You're ready to explore modern ML-powered recommendation systems. \ud83c\udfac</p>"},{"location":"getting-started/project-overview/","title":"\ud83c\udfaf Project Overview","text":"<p>Understanding Movie Genie: An AI-powered movie recommendation system that demonstrates modern ML engineering and full-stack development best practices.</p>"},{"location":"getting-started/project-overview/#what-is-movie-genie","title":"\ud83c\udfac What is Movie Genie?","text":"<p>Movie Genie is a complete movie recommendation system that showcases:</p> <ul> <li>\ud83e\udde0 Advanced ML Models: Sequential (BERT4Rec), collaborative (Two-Tower), and content-based (Semantic Search) approaches</li> <li>\ud83c\udf10 Modern Full-Stack: React TypeScript frontend with Flask Python backend</li> <li>\ud83d\udd04 MLOps Pipeline: DVC-managed reproducible data and model workflows</li> <li>\ud83d\udcca Real Data: MovieLens dataset with 100k ratings and rich movie metadata</li> <li>\ud83d\ude80 Production Ready: Docker deployment, monitoring, and scalability considerations</li> </ul> <p>This project serves both as a functional recommendation system and a comprehensive learning reference for building modern ML applications.</p>"},{"location":"getting-started/project-overview/#system-architecture","title":"\ud83c\udfd7\ufe0f System Architecture","text":""},{"location":"getting-started/project-overview/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Frontend      \u2502    \u2502    Backend      \u2502    \u2502   ML Models     \u2502\n\u2502   (React TS)    \u2502\u25c4\u2500\u2500\u25ba\u2502   (Flask)       \u2502\u25c4\u2500\u2500\u25ba\u2502   (PyTorch)     \u2502\n\u2502                 \u2502    \u2502                 \u2502    \u2502                 \u2502\n\u2502 \u2022 User Interface\u2502    \u2502 \u2022 REST API      \u2502    \u2502 \u2022 BERT4Rec      \u2502\n\u2502 \u2022 Search &amp; Grid \u2502    \u2502 \u2022 Data Services \u2502    \u2502 \u2022 Two-Tower     \u2502\n\u2502 \u2022 Movie Details \u2502    \u2502 \u2022 ML Integration\u2502    \u2502 \u2022 Semantic      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502                       \u2502\n         \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502   Database      \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502   (SQLite)      \u2502\n                        \u2502                 \u2502\n                        \u2502 \u2022 Movies        \u2502\n                        \u2502 \u2022 Ratings       \u2502\n                        \u2502 \u2022 Users         \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"getting-started/project-overview/#data-flow-architecture","title":"Data Flow Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Raw Data  \u2502\u2500\u2500\u2500\u25ba\u2502 Processing  \u2502\u2500\u2500\u2500\u25ba\u2502   Models    \u2502\u2500\u2500\u2500\u25ba\u2502 Application \u2502\n\u2502             \u2502    \u2502   (DVC)     \u2502    \u2502 (Training)  \u2502    \u2502  (Serving)  \u2502\n\u2502 \u2022 MovieLens \u2502    \u2502             \u2502    \u2502             \u2502    \u2502             \u2502\n\u2502 \u2022 IMDB      \u2502    \u2502 \u2022 Cleaning  \u2502    \u2502 \u2022 BERT4Rec  \u2502    \u2502 \u2022 Frontend  \u2502\n\u2502 \u2022 Features  \u2502    \u2502 \u2022 Features  \u2502    \u2502 \u2022 Two-Tower \u2502    \u2502 \u2022 Backend   \u2502\n\u2502             \u2502    \u2502 \u2022 Sequences \u2502    \u2502 \u2022 Semantic  \u2502    \u2502 \u2022 API       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"getting-started/project-overview/#core-features","title":"\ud83c\udfaf Core Features","text":""},{"location":"getting-started/project-overview/#intelligent-recommendations","title":"\ud83e\udde0 Intelligent Recommendations","text":"<ul> <li>Personalized: Learns from user viewing history using BERT4Rec</li> <li>Collaborative: Finds similar users and items with Two-Tower model</li> <li>Content-Based: Semantic search using natural language descriptions</li> <li>Hybrid: Combines multiple approaches for better results</li> </ul>"},{"location":"getting-started/project-overview/#advanced-search","title":"\ud83d\udd0d Advanced Search","text":"<ul> <li>Semantic Search: \"Find action movies with robots\"</li> <li>Traditional Search: Search by title, genre, or keywords</li> <li>Filtered Results: Smart filtering and ranking</li> <li>Visual Grid: Beautiful, responsive movie grid layout</li> </ul>"},{"location":"getting-started/project-overview/#modern-interface","title":"\ud83c\udfa8 Modern Interface","text":"<ul> <li>User Selection: Choose from 610 different user profiles</li> <li>Responsive Design: Works on desktop, tablet, and mobile</li> <li>Real-time Search: Instant results as you type</li> <li>Movie Details: Rich information panels with similar movies</li> </ul>"},{"location":"getting-started/project-overview/#developer-experience","title":"\u26a1 Developer Experience","text":"<ul> <li>Hot Reload: Frontend development with instant updates</li> <li>API Testing: Built-in endpoints for testing and debugging</li> <li>Reproducible: DVC ensures consistent results across environments</li> <li>Configurable: Easy parameter tuning through YAML configs</li> </ul>"},{"location":"getting-started/project-overview/#machine-learning-models","title":"\ud83e\udde0 Machine Learning Models","text":""},{"location":"getting-started/project-overview/#bert4rec-sequential-recommendation","title":"BERT4Rec - Sequential Recommendation","text":"<pre><code># What it does\nuser_sequence = [movie1, movie2, movie3, ...]\nnext_movie = bert4rec.predict(user_sequence)\n\n# Best for\n- Users with viewing history (5+ movies)\n- Sequential/temporal recommendations\n- \"Continue watching\" suggestions\n</code></pre>"},{"location":"getting-started/project-overview/#two-tower-collaborative-filtering","title":"Two-Tower - Collaborative Filtering","text":"<pre><code># What it does\nuser_embedding = user_encoder(user_features)\nitem_embedding = item_encoder(item_features)\nsimilarity = cosine_similarity(user_embedding, item_embedding)\n\n# Best for\n- Large-scale recommendations\n- Finding similar users/items\n- Fast real-time inference\n</code></pre>"},{"location":"getting-started/project-overview/#semantic-search-content-based","title":"Semantic Search - Content-Based","text":"<pre><code># What it does\nquery_embedding = encoder(\"action movies with time travel\")\nmovie_embeddings = encoder(movie_descriptions)\nresults = similarity_search(query_embedding, movie_embeddings)\n\n# Best for\n- Natural language queries\n- Content discovery\n- Zero-shot recommendations\n</code></pre>"},{"location":"getting-started/project-overview/#data-pipeline-dvc","title":"\ud83d\udd04 Data Pipeline (DVC)","text":""},{"location":"getting-started/project-overview/#pipeline-stages","title":"Pipeline Stages","text":"<pre><code>stages:\n  data_processing:\n    cmd: python scripts/process_movielens.py\n    deps: [data/raw/ml-100k/]\n    outs: [data/processed/]\n\n  feature_engineering:\n    cmd: python movie_genie/data/content_features.py\n    deps: [data/processed/]\n    outs: [data/processed/content_features.parquet]\n\n  train_bert4rec:\n    cmd: python movie_genie/ranking/train_bert4rec.py\n    deps: [data/processed/sequences_with_metadata.parquet]\n    outs: [models/bert4rec/]\n\n  train_two_tower:\n    cmd: python movie_genie/retrieval/train_two_tower.py\n    deps: [data/processed/]\n    outs: [models/two_tower/]\n\n  setup_semantic_search:\n    cmd: python movie_genie/search/setup_semantic_search.py\n    deps: [data/processed/content_features.parquet]\n    outs: [models/semantic_search/]\n\n  setup_database:\n    cmd: python scripts/setup_database.py\n    deps: [data/processed/]\n    outs: [movie_genie/backend/movie_genie.db]\n\n  backend_server:\n    cmd: cd movie_genie/backend &amp;&amp; python app.py\n    deps: [models/, movie_genie/backend/movie_genie.db]\n</code></pre>"},{"location":"getting-started/project-overview/#why-dvc","title":"Why DVC?","text":"<ul> <li>Reproducibility: Same results every time</li> <li>Version Control: Track data and model changes</li> <li>Collaboration: Share pipelines across team</li> <li>Scalability: Run on different compute environments</li> </ul>"},{"location":"getting-started/project-overview/#full-stack-integration","title":"\ud83c\udf10 Full-Stack Integration","text":""},{"location":"getting-started/project-overview/#frontend-react-typescript","title":"Frontend (React + TypeScript)","text":"<pre><code>// Key Components\n- UserSelectionModal: User authentication\n- MovieSearch: Search interface\n- SearchResultsGrid: Results display\n- MovieThumbnail: Individual movie cards\n- RecommendationCarousel: Personalized suggestions\n\n// Data Layer\n- MovieDataService: API abstraction\n- Real/Mock data switching\n- Error handling and fallbacks\n</code></pre>"},{"location":"getting-started/project-overview/#backend-flask-python","title":"Backend (Flask + Python)","text":"<pre><code># API Structure\n/api/health           # System health check\n/api/users/info       # User information\n/api/movies/popular   # Popular movies\n/api/movies/&lt;id&gt;      # Movie details\n/api/search/semantic  # Semantic search\n/api/recommendations  # Personalized recommendations\n\n# Service Layer\n- MovieService: Movie data management\n- RecommendationService: ML model integration\n- SearchService: Search functionality\n- UserService: User management\n</code></pre>"},{"location":"getting-started/project-overview/#technology-stack","title":"\ud83d\udcca Technology Stack","text":""},{"location":"getting-started/project-overview/#core-technologies","title":"Core Technologies","text":"Component Technology Why Chosen Frontend React + TypeScript Modern, type-safe UI development Backend Flask + Python Lightweight, ML-friendly API server Database SQLite Simple, embedded, perfect for demos ML Framework PyTorch Flexible, research-friendly deep learning Data Pipeline DVC Git-like versioning for data and models Deployment Docker Containerized, reproducible deployment"},{"location":"getting-started/project-overview/#ml-specific-tools","title":"ML-Specific Tools","text":"Tool Purpose Usage Transformers BERT4Rec implementation Sequential recommendation model Sentence-BERT Semantic search Text embedding and similarity Pandas Data processing ETL and feature engineering Scikit-learn Traditional ML Evaluation metrics and utilities"},{"location":"getting-started/project-overview/#learning-objectives","title":"\ud83c\udfaf Learning Objectives","text":""},{"location":"getting-started/project-overview/#machine-learning-engineering","title":"Machine Learning Engineering","text":"<ul> <li>\u2705 Model Architecture: Understand transformer-based recommendations</li> <li>\u2705 Training Pipelines: Implement reproducible ML workflows</li> <li>\u2705 Model Evaluation: Compare different recommendation approaches</li> <li>\u2705 Production Deployment: Serve ML models in web applications</li> </ul>"},{"location":"getting-started/project-overview/#full-stack-development","title":"Full-Stack Development","text":"<ul> <li>\u2705 API Design: RESTful services for ML applications</li> <li>\u2705 Frontend Integration: Connect ML outputs to user interfaces</li> <li>\u2705 State Management: Handle complex application state</li> <li>\u2705 Performance: Optimize for real-time user experience</li> </ul>"},{"location":"getting-started/project-overview/#mlops-devops","title":"MLOps &amp; DevOps","text":"<ul> <li>\u2705 Data Versioning: Track datasets and model artifacts</li> <li>\u2705 Pipeline Automation: Reproducible data and training workflows</li> <li>\u2705 Environment Management: Consistent development and production setups</li> <li>\u2705 Monitoring: Track system health and model performance</li> </ul>"},{"location":"getting-started/project-overview/#system-design","title":"System Design","text":"<ul> <li>\u2705 Scalability: Design for growth and performance</li> <li>\u2705 Maintainability: Clean, documented, testable code</li> <li>\u2705 Reliability: Error handling and graceful degradation</li> <li>\u2705 User Experience: Intuitive, responsive interfaces</li> </ul>"},{"location":"getting-started/project-overview/#use-cases-applications","title":"\ud83d\udd0d Use Cases &amp; Applications","text":""},{"location":"getting-started/project-overview/#educational","title":"Educational","text":"<ul> <li>Learning ML: Hands-on experience with modern recommendation systems</li> <li>Full-Stack Skills: Complete web application development</li> <li>MLOps Practices: Industry-standard workflows and tools</li> <li>System Design: Architecture patterns and best practices</li> </ul>"},{"location":"getting-started/project-overview/#professional","title":"Professional","text":"<ul> <li>Portfolio Project: Demonstrate ML and full-stack capabilities</li> <li>Reference Implementation: Template for recommendation systems</li> <li>Interview Preparation: Discuss real project experience</li> <li>Team Training: Onboard developers to ML practices</li> </ul>"},{"location":"getting-started/project-overview/#research-experimentation","title":"Research &amp; Experimentation","text":"<ul> <li>Model Comparison: Test different recommendation approaches</li> <li>A/B Testing: Compare model performance on real users</li> <li>Feature Engineering: Experiment with new data features</li> <li>Algorithm Development: Implement new recommendation algorithms</li> </ul>"},{"location":"getting-started/project-overview/#deployment-scenarios","title":"\ud83d\ude80 Deployment Scenarios","text":""},{"location":"getting-started/project-overview/#development","title":"Development","text":"<pre><code># Local development with hot reload\ndvc repro\n# Frontend: npm run dev (localhost:5173)\n# Backend: python app.py (localhost:5001)\n</code></pre>"},{"location":"getting-started/project-overview/#production","title":"Production","text":"<pre><code># Single container deployment\ndocker build -t movie-genie .\ndocker run -p 5001:5001 movie-genie\n\n# Or with Docker Compose\ndocker-compose up -d\n</code></pre>"},{"location":"getting-started/project-overview/#cloud-deployment","title":"Cloud Deployment","text":"<ul> <li>AWS: ECS with RDS for database</li> <li>GCP: Cloud Run with Cloud SQL</li> <li>Azure: Container Instances with Azure SQL</li> <li>Heroku: Simple PaaS deployment</li> </ul>"},{"location":"getting-started/project-overview/#performance-characteristics","title":"\ud83d\udcc8 Performance Characteristics","text":""},{"location":"getting-started/project-overview/#model-performance","title":"Model Performance","text":"Model Training Time Inference Speed Memory Usage Accuracy BERT4Rec ~30 minutes ~50ms ~500MB High (sequential) Two-Tower ~10 minutes ~5ms ~200MB Good (collaborative) Semantic Pre-trained ~20ms ~100MB Good (content)"},{"location":"getting-started/project-overview/#system-performance","title":"System Performance","text":"<ul> <li>API Response Time: &lt; 100ms for most endpoints</li> <li>Database Queries: &lt; 10ms for typical operations</li> <li>Frontend Load Time: &lt; 2 seconds initial load</li> <li>Concurrent Users: 50+ with single server</li> </ul>"},{"location":"getting-started/project-overview/#future-enhancements","title":"\ud83d\udd2e Future Enhancements","text":""},{"location":"getting-started/project-overview/#short-term","title":"Short Term","text":"<ul> <li> Real-time Learning: Update models with user interactions</li> <li> A/B Testing: Compare model performance on live traffic</li> <li> Caching Layer: Redis for faster API responses</li> <li> Monitoring: Grafana dashboard for system metrics</li> </ul>"},{"location":"getting-started/project-overview/#medium-term","title":"Medium Term","text":"<ul> <li> Multi-Model Ensemble: Combine all models intelligently</li> <li> User Profiles: Rich user preference modeling</li> <li> Social Features: Friend recommendations and sharing</li> <li> Mobile App: React Native mobile interface</li> </ul>"},{"location":"getting-started/project-overview/#long-term","title":"Long Term","text":"<ul> <li> Multi-tenant: Support multiple content catalogs</li> <li> Real-time Streaming: Live recommendation updates</li> <li> Advanced ML: Graph neural networks, reinforcement learning</li> <li> Enterprise Features: SSO, analytics, content management</li> </ul> <p>This overview provides the foundation for understanding Movie Genie's architecture, capabilities, and learning potential. Ready to dive deeper into specific components? \ud83c\udfac</p>"},{"location":"getting-started/quick-start/","title":"\u26a1 Quick Start Guide","text":"<p>Get Movie Genie up and running in 5 minutes! This guide gets you from zero to a working AI-powered movie recommendation system.</p>"},{"location":"getting-started/quick-start/#5-minute-setup","title":"\ud83d\ude80 5-Minute Setup","text":""},{"location":"getting-started/quick-start/#step-1-clone-and-install-2-minutes","title":"Step 1: Clone and Install (2 minutes)","text":"<pre><code># Clone the repository\ngit clone &lt;repository-url&gt;\ncd movie-genie\n\n# Install the project\npip install -e .\n</code></pre>"},{"location":"getting-started/quick-start/#step-2-run-the-pipeline-2-minutes","title":"Step 2: Run the Pipeline (2 minutes)","text":"<pre><code># Run the complete DVC pipeline\ndvc repro\n</code></pre> <p>This command will: - \u2705 Process the MovieLens dataset - \u2705 Train all ML models (BERT4Rec, Two-Tower, Semantic Search) - \u2705 Set up the database - \u2705 Start the backend server</p>"},{"location":"getting-started/quick-start/#step-3-access-the-application-1-minute","title":"Step 3: Access the Application (1 minute)","text":"<pre><code># Open your browser to:\nhttp://127.0.0.1:5001\n</code></pre> <p>\ud83c\udf89 You're done! The application is now running with: - Frontend: React interface served by Flask - Backend: Flask API with ML models - Database: SQLite with MovieLens data - ML Models: Trained and ready for recommendations</p>"},{"location":"getting-started/quick-start/#what-youll-see","title":"\ud83c\udfaf What You'll See","text":""},{"location":"getting-started/quick-start/#1-user-selection","title":"1. User Selection","text":"<ul> <li>Enter a user ID (1-610) to simulate different users</li> <li>Each user has unique viewing history and preferences</li> </ul>"},{"location":"getting-started/quick-start/#2-homepage","title":"2. Homepage","text":"<ul> <li>Popular Movies: Most-watched films from the dataset</li> <li>Personalized Recommendations: ML-powered suggestions</li> <li>Genre Collections: Movies organized by category</li> </ul>"},{"location":"getting-started/quick-start/#3-search-discovery","title":"3. Search &amp; Discovery","text":"<ul> <li>Semantic Search: Find movies using natural language</li> <li>Grid Results: Browse search results in an organized layout</li> <li>Movie Details: Click any movie for detailed information</li> </ul>"},{"location":"getting-started/quick-start/#test-the-features","title":"\ud83e\uddea Test the Features","text":""},{"location":"getting-started/quick-start/#test-ml-recommendations","title":"Test ML Recommendations","text":"<pre><code># Try different user IDs to see personalized results\nUser ID 123: Sci-fi and action movie fan\nUser ID 456: Romance and comedy preferences\nUser ID 789: Horror and thriller enthusiast\n</code></pre>"},{"location":"getting-started/quick-start/#test-semantic-search","title":"Test Semantic Search","text":"<pre><code># Try these search queries:\n\"funny movies for family night\"\n\"sci-fi movies with time travel\"\n\"action movies with robots\"\n\"romantic comedies from the 90s\"\n</code></pre>"},{"location":"getting-started/quick-start/#test-api-endpoints","title":"Test API Endpoints","text":"<pre><code># Check API health\ncurl http://127.0.0.1:5001/api/health\n\n# Get user info\ncurl http://127.0.0.1:5001/api/users/info\n\n# Search movies\ncurl \"http://127.0.0.1:5001/api/search/semantic?q=action%20movies\"\n</code></pre>"},{"location":"getting-started/quick-start/#common-quick-commands","title":"\ud83d\udd27 Common Quick Commands","text":""},{"location":"getting-started/quick-start/#restart-everything","title":"Restart Everything","text":"<pre><code># If something goes wrong, restart the pipeline\ndvc repro --force\n</code></pre>"},{"location":"getting-started/quick-start/#check-whats-running","title":"Check What's Running","text":"<pre><code># Check if backend is running\ncurl http://127.0.0.1:5001/api/health\n\n# Check database\nsqlite3 movie_genie/backend/movie_genie.db \"SELECT COUNT(*) FROM movies;\"\n</code></pre>"},{"location":"getting-started/quick-start/#view-logs","title":"View Logs","text":"<pre><code># Backend logs (if running in terminal)\n# Check the terminal where you ran `dvc repro`\n\n# Or check DVC logs\ndvc status\n</code></pre>"},{"location":"getting-started/quick-start/#quick-troubleshooting","title":"\ud83c\udd98 Quick Troubleshooting","text":""},{"location":"getting-started/quick-start/#issue-port-already-in-use","title":"Issue: \"Port already in use\"","text":"<pre><code># Find and kill the process using port 5001\nlsof -ti:5001 | xargs kill -9\ndvc repro\n</code></pre>"},{"location":"getting-started/quick-start/#issue-no-module-named-movie_genie","title":"Issue: \"No module named 'movie_genie'\"","text":"<pre><code># Reinstall the project\npip install -e .\n</code></pre>"},{"location":"getting-started/quick-start/#issue-database-not-found","title":"Issue: \"Database not found\"","text":"<pre><code># Re-run database setup\ndvc repro data_processing setup_database\n</code></pre>"},{"location":"getting-started/quick-start/#issue-models-not-loading","title":"Issue: \"Models not loading\"","text":"<pre><code># Check if models were trained\nls -la models/\n# If empty, retrain models\ndvc repro train_bert4rec train_two_tower setup_semantic_search\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"\ud83c\udfaf Next Steps","text":"<p>Once you have the basic system running:</p> <ol> <li>Explore the Code: Check out Project Overview for architecture details</li> <li>Understand ML Models: Read ML Models Documentation</li> <li>Customize: Modify configurations in <code>configs/</code> directory</li> <li>Develop: Follow Installation Guide for development setup</li> </ol>"},{"location":"getting-started/quick-start/#development-mode","title":"\ud83d\ude80 Development Mode","text":"<p>If you want to develop the frontend separately:</p> <pre><code># Terminal 1: Backend only\ncd movie_genie/backend\npython app.py\n\n# Terminal 2: Frontend development server\ncd movie_genie/frontend\nnpm install\nnpm run dev\n</code></pre> <p>Frontend will be available at <code>http://localhost:5173</code> with hot reload.</p> <p>That's it! You now have a complete AI-powered movie recommendation system running locally. Time to explore what modern ML can do! \ud83c\udfac</p>"},{"location":"machine-learning/","title":"\ud83e\udde0 Machine Learning Models","text":"<p>Section Overview</p> <p>This section covers all machine learning models used in Movie Genie, from theoretical foundations to practical implementation.</p> <p>Movie Genie implements three state-of-the-art recommendation and search models, each optimized for different use cases and data scenarios.</p>"},{"location":"machine-learning/#model-overview","title":"\ud83c\udfaf Model Overview","text":"Model Type Best For Input Data Output BERT4Rec Sequential Users with interaction history User sequence + item features Next-item predictions Two-Tower Collaborative Large-scale recommendations User-item interactions User/item embeddings Semantic Search Content-Based Text-based discovery Movie descriptions + queries Similarity rankings"},{"location":"machine-learning/#detailed-documentation","title":"\ud83d\udcda Detailed Documentation","text":""},{"location":"machine-learning/#bert4rec-model","title":"\ud83e\udde0 BERT4Rec Model","text":"<p>Sequential Recommendation Model - Transformer-based architecture for next-item prediction - Handles user interaction sequences and item features - Perfect for \"users who liked X will like Y\" scenarios - Supports cold-start users with content features</p>"},{"location":"machine-learning/#two-tower-model","title":"\ud83c\udfd7\ufe0f Two-Tower Model","text":"<p>Collaborative Filtering Model - Dual-encoder architecture for user and item embeddings - Scalable to millions of users and items - Excellent for finding similar users and items - Fast inference with pre-computed embeddings</p>"},{"location":"machine-learning/#semantic-search","title":"\ud83d\udd0d Semantic Search","text":"<p>Content-Based Search Model - Embedding-based similarity search - Natural language query understanding - Handles complex, descriptive search queries - Zero-shot learning on new movie content</p>"},{"location":"machine-learning/#model-evaluation","title":"\ud83d\udcc8 Model Evaluation","text":"<p>Performance Analysis &amp; Comparison - Comprehensive evaluation metrics - A/B testing framework - Model comparison guidelines - Performance optimization strategies</p>"},{"location":"machine-learning/#when-to-use-which-model","title":"\ud83c\udfaf When to Use Which Model","text":""},{"location":"machine-learning/#bert4rec","title":"BERT4Rec \ud83e\udde0","text":"<p>Use When: - \u2705 User has significant interaction history (5+ movies) - \u2705 You want sequential/temporal recommendations - \u2705 User preferences change over time - \u2705 You have rich item content features</p> <p>Example Use Cases: - \"More like your recent watches\" - \"Continue watching\" recommendations - Trending predictions based on viewing patterns</p>"},{"location":"machine-learning/#two-tower","title":"Two-Tower \ud83c\udfd7\ufe0f","text":"<p>Use When: - \u2705 You have large-scale user-item interaction data - \u2705 You need fast, real-time recommendations - \u2705 You want to find similar users or items - \u2705 Cold-start scenarios with minimal history</p> <p>Example Use Cases: - Homepage personalized recommendations - \"Users like you also watched\" - Large-scale batch recommendations</p>"},{"location":"machine-learning/#semantic-search_1","title":"Semantic Search \ud83d\udd0d","text":"<p>Use When: - \u2705 Users search with natural language queries - \u2705 You want content-based discovery - \u2705 Handling zero-shot scenarios - \u2705 Complex, descriptive search needs</p> <p>Example Use Cases: - \"Sci-fi movies with time travel\" - \"Funny movies for family night\" - Genre and mood-based discovery</p>"},{"location":"machine-learning/#model-architecture-comparison","title":"\ud83d\udd27 Model Architecture Comparison","text":""},{"location":"machine-learning/#bert4rec-architecture","title":"BERT4Rec Architecture","text":"<pre><code>User Sequence \u2192 BERT Encoder \u2192 Item Features \u2192 Attention \u2192 Next Item Probabilities\n[movie1, movie2, ...] \u2192 Transformer \u2192 Content Features \u2192 Output Layer \u2192 Recommendations\n</code></pre>"},{"location":"machine-learning/#two-tower-architecture","title":"Two-Tower Architecture","text":"<pre><code>User Features \u2192 User Encoder \u2192 User Embedding\n                                    \u2193\n                                Cosine Similarity \u2192 Ranking\n                                    \u2191\nItem Features \u2192 Item Encoder \u2192 Item Embedding\n</code></pre>"},{"location":"machine-learning/#semantic-search-architecture","title":"Semantic Search Architecture","text":"<pre><code>Text Query \u2192 SentenceTransformer \u2192 Query Embedding\n                                        \u2193\n                                   Similarity Search\n                                        \u2191\nMovie Descriptions \u2192 SentenceTransformer \u2192 Movie Embeddings\n</code></pre>"},{"location":"machine-learning/#performance-characteristics","title":"\ud83d\udcca Performance Characteristics","text":"Metric BERT4Rec Two-Tower Semantic Search Training Time High (hours) Medium (minutes) Low (pre-trained) Inference Speed Medium Fast Fast Memory Usage High Medium Low Cold-Start Good Excellent Excellent Personalization Excellent Good None Scalability Medium High High"},{"location":"machine-learning/#implementation-strategy","title":"\ud83d\udee0\ufe0f Implementation Strategy","text":""},{"location":"machine-learning/#development-phase","title":"Development Phase","text":"<ol> <li>Start with Two-Tower: Fastest to implement and validate</li> <li>Add Semantic Search: Enhance discovery capabilities</li> <li>Implement BERT4Rec: Advanced sequential modeling</li> </ol>"},{"location":"machine-learning/#production-phase","title":"Production Phase","text":"<ol> <li>A/B Test: Compare models on real user behavior</li> <li>Ensemble: Combine models for different use cases</li> <li>Optimize: Fine-tune based on performance metrics</li> </ol>"},{"location":"machine-learning/#model-integration-flow","title":"\ud83d\udd04 Model Integration Flow","text":"<pre><code>graph TD\n    A[User Request] --&gt; B{Request Type}\n    B --&gt;|Search Query| C[Semantic Search]\n    B --&gt;|Homepage| D[Two-Tower]\n    B --&gt;|Sequential| E[BERT4Rec]\n    C --&gt; F[Content Recommendations]\n    D --&gt; G[Collaborative Recommendations]\n    E --&gt; H[Sequential Recommendations]\n    F --&gt; I[Final Ranking]\n    G --&gt; I\n    H --&gt; I\n    I --&gt; J[User Interface]</code></pre>"},{"location":"machine-learning/#evaluation-metrics","title":"\ud83d\udcc8 Evaluation Metrics","text":""},{"location":"machine-learning/#offline-metrics","title":"Offline Metrics","text":"<ul> <li>NDCG@K: Ranking quality</li> <li>Recall@K: Coverage of relevant items</li> <li>MAP: Mean Average Precision</li> <li>AUC: Area Under ROC Curve</li> </ul>"},{"location":"machine-learning/#online-metrics","title":"Online Metrics","text":"<ul> <li>Click-Through Rate (CTR): User engagement</li> <li>Conversion Rate: Action completion</li> <li>Session Length: User retention</li> <li>Diversity: Recommendation variety</li> </ul>"},{"location":"machine-learning/#getting-started","title":"\ud83d\ude80 Getting Started","text":"<ol> <li>Understand the Theory: Read individual model documentation</li> <li>See Models in Action: Run the full application</li> <li>Experiment: Modify model parameters and observe results</li> <li>Evaluate: Use the evaluation framework to compare performance</li> <li>Optimize: Tune models for your specific use case</li> </ol> <p>Each model serves a specific purpose in the recommendation ecosystem. Understanding their strengths and limitations will help you build more effective recommendation systems.</p>"},{"location":"machine-learning/bert4rec/","title":"BERT4Rec Architecture: Mathematical Foundations and Sequential Understanding","text":"<p>A comprehensive guide to bidirectional transformer-based sequential recommendation for movie discovery</p>"},{"location":"machine-learning/bert4rec/#understanding-the-sequential-recommendation-challenge","title":"Understanding the Sequential Recommendation Challenge","text":"<p>Let me start by helping you understand why we need BERT4Rec when we already have a working two-tower model. Think about how you actually choose movies to watch. Your decision isn't just based on what you generally like - it's heavily influenced by what you've been watching recently, what mood you're in, and how your tastes are evolving over time.</p> <p>Consider this example: You've been on a Christopher Nolan binge, watching \"Inception,\" \"Interstellar,\" and \"The Dark Knight\" over the past few weeks. Then you watch a romantic comedy with friends. A traditional collaborative filtering system might think your preferences have shifted toward romantic comedies. But a human would understand that you're still interested in complex, thought-provoking films - the romantic comedy was just a temporary diversion.</p> <p>Your two-tower model captures what you generally like based on your overall interaction history. It learns that you enjoy science fiction, complex narratives, and high production values. But it treats each rating as an independent signal. It doesn't understand the sequential logic of how your preferences unfold over time or how context influences what you want to watch next.</p> <p>This limitation becomes particularly important for movie recommendation because film consumption involves deliberate exploration patterns. Users go through phases - maybe a month of exploring film noir, followed by a documentary phase, then returning to action movies. These temporal patterns contain crucial information about user intent that static models cannot capture.</p>"},{"location":"machine-learning/bert4rec/#the-mathematical-foundation-of-sequential-modeling","title":"The Mathematical Foundation of Sequential Modeling","text":"<p>Let's formalize this problem mathematically. Instead of treating user preferences as a static function, we need to model them as sequences that evolve over time.</p> <p>Traditional collaborative filtering models user-item compatibility as: \\(\\(\\hat{r}_{ui} = f(u, i, \\Theta)\\)\\)</p> <p>where user \\(u\\) and item \\(i\\) are treated as independent entities. Sequential recommendation extends this to consider the user's interaction history as a sequence:</p> \\[\\mathbf{s}_u = [i_1, i_2, \\ldots, i_t]\\] <p>where \\(\\mathbf{s}_u\\) represents user \\(u\\)'s chronologically ordered interaction sequence. The sequential prediction task becomes:</p> \\[\\hat{r}_{u,i_{t+1}} = f(\\mathbf{s}_u, i_{t+1}, \\Theta)\\] <p>This formulation acknowledges that predicting what user \\(u\\) will like next depends on their entire interaction sequence, not just their static preferences.</p> <p>The challenge lies in learning function \\(f\\) that can capture complex temporal dependencies, handle variable-length sequences, and understand how user preferences evolve over time. This is where BERT4Rec's transformer architecture provides a breakthrough solution.</p>"},{"location":"machine-learning/bert4rec/#why-bidirectional-context-revolutionizes-sequential-understanding","title":"Why Bidirectional Context Revolutionizes Sequential Understanding","text":"<p>Most sequential models process user interactions from left to right, predicting what comes next based on what came before. This approach seems intuitive since time moves forward, but it misses crucial information about user preferences.</p> <p>BERT4Rec takes a radically different approach inspired by BERT's success in natural language processing. Instead of only looking backward in time, it uses bidirectional attention to understand user preferences by considering the complete context around each interaction.</p> <p>Let me illustrate why this matters with a concrete example:</p> <p>User Sequence: The Matrix \u2192 Love Actually \u2192 The Notebook \u2192 Blade Runner \u2192 Her</p> <p>A left-to-right model processing this sequence might interpret the romantic movies as a shift away from science fiction. But a bidirectional model can see both the earlier \"Matrix\" and later \"Blade Runner\" and \"Her,\" recognizing that the user's interest in thoughtful science fiction persists across the romantic movie phase.</p> <p>Mathematically, instead of computing: \\(\\(p(i_t | i_1, i_2, \\ldots, i_{t-1})\\)\\)</p> <p>BERT4Rec computes: \\(\\(p(i_t | i_1, i_2, \\ldots, i_{t-1}, i_{t+1}, \\ldots, i_T)\\)\\)</p> <p>This bidirectional conditioning enables much richer understanding of user preference patterns by leveraging the complete sequence context during training.</p>"},{"location":"machine-learning/bert4rec/#the-transformer-architecture-attention-as-preference-understanding","title":"The Transformer Architecture: Attention as Preference Understanding","text":"<p>The heart of BERT4Rec lies in its use of transformer architecture, specifically the multi-head attention mechanism. To understand how this works, let's think about what your mind does when deciding what to watch next.</p> <p>You don't give equal weight to every movie you've ever seen. Instead, you focus on recent viewings that indicate your current interests, memorable films that shaped your preferences, and movies that relate thematically to your current mood. Some past interactions matter more than others for predicting future preferences, and the relevance of different interactions changes based on context.</p> <p>The attention mechanism automates this selective focusing process. For each position in a user's interaction sequence, attention computes three types of representations:</p> <p>Queries (Q): What information am I looking for to understand this user's preferences? Keys (K): What information is available from other movies in this user's history? Values (V): What is the actual preference information at each position?</p> <p>The mathematical computation involves:</p> \\[\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\\] <p>The \\(QK^T\\) operation computes similarity scores between the query at each position and keys from all other positions. The softmax function converts these scores into attention weights that sum to one, creating a probability distribution over sequence positions.</p> <p>Let's walk through what this means in practice. Suppose we're trying to understand a user's current preferences at the point where they watched \"Blade Runner.\" The attention mechanism might assign high weights to: - Recent science fiction films (temporal relevance) - Movies with similar visual aesthetics (content similarity) - Films with philosophical themes (thematic consistency)</p> <p>The final representation combines information from all positions, weighted by these computed attention scores. This creates contextualized understanding that captures both the user's stable preferences and their current trajectory.</p>"},{"location":"machine-learning/bert4rec/#multi-head-attention-capturing-different-aspects-of-preference","title":"Multi-Head Attention: Capturing Different Aspects of Preference","text":"<p>BERT4Rec uses multi-head attention, which runs several attention computations in parallel. Think of each attention head as focusing on different aspects of user preferences:</p> <ul> <li>Head 1: Recent interactions and temporal patterns</li> <li>Head 2: Genre preferences and content similarity  </li> <li>Head 3: Thematic coherence and narrative complexity</li> <li>Head 4: Production quality and directorial style</li> </ul> <p>Mathematically, each head \\(h\\) computes its own attention:</p> \\[\\text{head}_h = \\text{Attention}(QW_h^Q, KW_h^K, VW_h^V)\\] <p>where \\(W_h^Q\\), \\(W_h^K\\), and \\(W_h^V\\) are learned projection matrices specific to head \\(h\\). The outputs from all heads get concatenated and projected:</p> \\[\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\ldots, \\text{head}_H)W^O\\] <p>This multi-head approach enables the model to attend to different types of patterns simultaneously, creating richer understanding of user preferences than single-head attention could achieve.</p>"},{"location":"machine-learning/bert4rec/#the-masking-strategy-learning-through-contextual-prediction","title":"The Masking Strategy: Learning Through Contextual Prediction","text":"<p>BERT4Rec's training process uses a sophisticated masking strategy that teaches the model to understand user preferences through contextual prediction. Instead of simply predicting the next item in a sequence, the model learns to predict masked items based on bidirectional context.</p> <p>During training, we randomly mask certain movies in user interaction sequences and train the model to predict what the masked items should be. This creates a learning task that directly mirrors what we want the model to do: understand user preferences well enough to predict which movies would naturally fit into specific contexts.</p> <p>The masking process becomes particularly sophisticated for movie recommendation. We preferentially mask movies that users rated positively, since these represent the clearest preference signals. The model learns to identify patterns like:</p> <p>Masked Sequence: The Matrix \u2192 [MASK] \u2192 Blade Runner \u2192 Her Learning Task: Predict that \"Ghost in the Shell\" or \"Ex Machina\" would fit the masked position</p> <p>The mathematical objective involves maximizing the likelihood of observed items at masked positions:</p> \\[\\mathcal{L} = -\\sum_{i \\in \\text{masked}} \\log p(i | \\text{context})\\] <p>where the probability \\(p(i | \\text{context})\\) is computed using the bidirectional transformer representations.</p>"},{"location":"machine-learning/bert4rec/#content-feature-integration-bridging-collaborative-and-content-understanding","title":"Content Feature Integration: Bridging Collaborative and Content Understanding","text":"<p>Your BERT4Rec implementation integrates the rich content features you developed during TMDB processing. This integration happens at the item representation level, where each movie gets represented by combining learned embeddings with explicit content features.</p> <p>For each movie \\(i\\), the input representation becomes:</p> \\[\\mathbf{h}_i^{(0)} = \\mathbf{W}_{\\text{item}} \\cdot \\text{one\\_hot}(i) + \\mathbf{W}_{\\text{content}} \\cdot \\mathbf{c}_i + \\mathbf{W}_{\\text{pos}} \\cdot \\text{pos}_i\\] <p>where: - \\(\\mathbf{W}_{\\text{item}} \\cdot \\text{one\\_hot}(i)\\) represents learned collaborative embeddings - \\(\\mathbf{W}_{\\text{content}} \\cdot \\mathbf{c}_i\\) projects your TMDB and text features - \\(\\mathbf{W}_{\\text{pos}} \\cdot \\text{pos}_i\\) encodes the sequence position</p> <p>This integration strategy provides several crucial advantages. The model can understand preferences along multiple dimensions simultaneously: collaborative patterns learned from user behavior and content patterns derived from movie characteristics. When a user shows interest in Christopher Nolan films, the content features help the model understand that the relevant patterns involve complex narratives, high production values, and specific visual styles.</p> <p>The attention mechanism can then identify thematic connections, stylistic similarities, and content-based relationships that inform preference predictions. This enables recommendations of new releases that lack interaction history, discovery of niche films through content similarity, and understanding of why certain users gravitate toward specific types of content.</p>"},{"location":"machine-learning/bert4rec/#transformer-layers-building-hierarchical-understanding","title":"Transformer Layers: Building Hierarchical Understanding","text":"<p>BERT4Rec stacks multiple transformer layers to build increasingly sophisticated representations of user preferences. Each layer can refine and enhance the representations learned by previous layers.</p> <p>The computation at each layer \\(l\\) follows:</p> \\[\\mathbf{h}^{(l)} = \\text{LayerNorm}(\\mathbf{h}^{(l-1)} + \\text{MultiHeadAttention}(\\mathbf{h}^{(l-1)}))$$ $$\\mathbf{h}^{(l)} = \\text{LayerNorm}(\\mathbf{h}^{(l)} + \\text{FFN}(\\mathbf{h}^{(l)}))\\] <p>where FFN represents a position-wise feed-forward network. The residual connections (the addition operations) enable information to flow directly from early layers to later layers, preventing the vanishing gradient problem that can plague deep networks.</p> <p>Think of each layer as adding a level of understanding: - Layer 1: Basic item similarities and recent interaction patterns - Layer 2: Thematic relationships and genre preferences - Layer 3: Complex narrative preferences and stylistic patterns - Layer 4: Sophisticated preference logic and contextual understanding</p> <p>This hierarchical learning enables BERT4Rec to capture both simple patterns (like genre preferences) and complex relationships (like the connection between Christopher Nolan films and users who enjoy puzzle-like narratives).</p>"},{"location":"machine-learning/bert4rec/#training-dynamics-and-optimization-challenges","title":"Training Dynamics and Optimization Challenges","text":"<p>Training BERT4Rec involves several sophisticated optimization considerations that differ from simpler recommendation models. The bidirectional nature of the model creates a complex parameter space where the model must learn to balance multiple competing objectives.</p> <p>The optimization landscape becomes challenging because the model must develop accurate understanding of individual user preferences while learning generalizable patterns that apply across different users and contexts. The masking strategy creates additional complexity because the model cannot simply memorize sequence patterns but must develop robust understanding that generalizes to new contexts.</p> <p>The learning rate scheduling becomes particularly important for transformer training. The model typically uses a warmup period with gradually increasing learning rates, followed by decay:</p> \\[\\text{lr}(t) = \\frac{d_{\\text{model}}^{-0.5} \\cdot \\min(t^{-0.5}, t \\cdot \\text{warmup\\_steps}^{-1.5})}{\\sqrt{\\text{warmup\\_steps}}}\\] <p>This scheduling helps the transformer converge to good solutions by preventing early training instability while enabling fine-tuning of learned representations in later epochs.</p>"},{"location":"machine-learning/bert4rec/#integration-with-your-two-tower-architecture","title":"Integration with Your Two-Tower Architecture","text":"<p>Understanding how BERT4Rec integrates with your two-tower model requires thinking about the complementary strengths each component brings to the complete recommendation pipeline. This integration represents one of the most sophisticated aspects of modern recommendation system design.</p> <p>Your two-tower model excels at efficiently scanning large catalogs to identify potentially relevant candidates. It operates at the scale of your complete movie database using fast similarity computations between learned user and item embeddings. This retrieval stage filters your 80,000+ movie catalog down to manageable candidate sets of 100-200 items within computational constraints suitable for real-time serving.</p> <p>BERT4Rec operates on these candidate sets, focusing its computational intensity on the ranking task where sophisticated understanding provides the most value. Instead of processing 80,000 items, BERT4Rec analyzes perhaps 100 carefully selected candidates, using its attention mechanisms and sequential understanding to determine optimal ordering.</p> <p>The mathematical pipeline involves two distinct but complementary prediction tasks:</p> <p>Two-Tower Prediction: \\(\\text{score}_{\\text{retrieval}}(u, i) = \\mathbf{e}_u^T \\mathbf{e}_i\\) BERT4Rec Prediction: \\(\\text{score}_{\\text{ranking}}(u, i | \\mathbf{s}_u) = \\text{BERT4Rec}(\\mathbf{s}_u, i)\\)</p> <p>During recommendation generation, these models work sequentially: 1. Two-tower generates candidates based on embedding similarity 2. BERT4Rec ranks these candidates using sequential context and content features 3. The final recommendations represent the top-ranked items from this two-stage process</p> <p>This division of labor enables you to leverage the computational efficiency of two-tower retrieval while applying the sophisticated preference understanding of BERT4Rec where it matters most: distinguishing between good candidates and great candidates based on temporal user behavior patterns.</p>"},{"location":"machine-learning/bert4rec/#why-this-architecture-succeeds-for-movie-recommendation","title":"Why This Architecture Succeeds for Movie Recommendation","text":"<p>Movie recommendation presents several unique characteristics that make BERT4Rec particularly well-suited compared to other sequential modeling approaches. Understanding these characteristics helps you appreciate why this architecture represents an optimal choice for your movie recommendation system.</p> <p>Movie consumption involves longer, more deliberate interaction sessions compared to domains like e-commerce browsing or music streaming. Users typically spend considerable time choosing what to watch, and their choices reflect thoughtful preferences rather than impulsive decisions. This deliberate nature means that sequential patterns in movie viewing carry strong predictive signals about user preferences.</p> <p>The temporal patterns in movie viewing align well with BERT4Rec's bidirectional modeling approach. Users often explore themes, directors, or genres across multiple viewings, creating coherent preference episodes that might span weeks or months. Your Netflix thumbs rating system provides particularly clear training signals that eliminate the ambiguity present in implicit feedback systems.</p> <p>The rich content features you developed from TMDB and EmbeddingGemma processing provide sophisticated item representations that enhance BERT4Rec's ability to understand preference patterns. Movies possess rich metadata including genre information, cast details, plot summaries, and production characteristics that enable content-based understanding beyond simple collaborative patterns.</p> <p>These characteristics combine to create an ideal environment for BERT4Rec's bidirectional attention mechanisms to learn meaningful patterns about user preference evolution, thematic exploration, and content-based similarity that drive effective movie recommendations.</p> <p>The integration of collaborative filtering signals from interaction sequences with rich content understanding creates a recommendation system that can handle both the discovery of new content and the refinement of preferences based on temporal user behavior patterns. This combination addresses the core challenges of movie recommendation: helping users discover films they'll enjoy while accounting for the evolving nature of taste and context that influences viewing decisions.</p>"},{"location":"machine-learning/evaluation/","title":"Model Evaluation","text":"<p>You're absolutely right to call this out. Let me explain the integrated evaluation from a conceptual foundation upward, because evaluating a two-stage recommendation system presents fundamentally different challenges than evaluating a single model.</p>"},{"location":"machine-learning/evaluation/#understanding-what-were-actually-trying-to-measure","title":"Understanding What We're Actually Trying to Measure","text":"<p>When you evaluate a single machine learning model, you typically ask straightforward questions: How accurately does it predict labels? How well does it generalize to unseen data? But when you evaluate an integrated recommendation system, you're asking much more complex questions that don't have simple answers.</p> <p>The fundamental challenge lies in understanding that your integrated system isn't just performing one task - it's performing two different but interdependent tasks that must work together harmoniously. Your two-tower model performs candidate retrieval, asking \"which movies from our entire catalog might this user find interesting?\" Your BERT4Rec model performs candidate ranking, asking \"given these potentially interesting movies, which specific ordering will maximize user satisfaction?\"</p> <p>Think about what this means for evaluation. You could have a two-tower model that achieves excellent retrieval performance and a BERT4Rec model that demonstrates superior ranking capabilities, but if they don't complement each other effectively, your users will receive poor recommendations. Conversely, you might have individual models that seem mediocre in isolation but work together beautifully to create outstanding user experiences.</p> <p>This interdependency creates evaluation challenges that don't exist for single-model systems. How do you separate retrieval problems from ranking problems when analyzing poor recommendations? How do you measure whether the sophisticated sequential modeling in BERT4Rec actually improves recommendations enough to justify its computational complexity? How do you determine optimal candidate set sizes that balance retrieval coverage with ranking effectiveness?</p>"},{"location":"machine-learning/evaluation/#the-cascade-effect-challenge","title":"The Cascade Effect Challenge","text":"<p>Let me help you understand why integrated evaluation becomes so complex by walking through what I call the \"cascade effect\" in two-stage recommendation systems. Every decision made by your two-tower model directly constrains what your BERT4Rec model can accomplish.</p> <p>Imagine your two-tower model generates candidates for a user who loves Christopher Nolan films. If the two-tower model fails to include \"Inception\" in its top 100 candidates, then no amount of sophisticated sequential modeling by BERT4Rec can recommend \"Inception\" to that user. The ranking stage cannot fix fundamental retrieval failures.</p> <p>This cascade relationship means that evaluation metrics can be misleading if you examine them independently. Suppose your BERT4Rec model achieves impressive ranking performance when evaluated on artificial candidate sets that include relevant items. But if your two-tower model rarely generates candidate sets that contain those relevant items, the real-world performance of your integrated system will disappoint users despite the ranking model's apparent sophistication.</p> <p>The cascade effect also works in reverse. Your two-tower model might generate excellent candidate sets that include many movies the user would enjoy, but if BERT4Rec consistently ranks them poorly due to sequential modeling failures, users will see irrelevant recommendations at the top of their lists. The retrieval stage's success gets undermined by ranking stage failures.</p> <p>Understanding this cascade relationship becomes crucial for interpreting evaluation results. When your integrated system performs poorly, you need diagnostic approaches that help you identify whether the problem originates in candidate generation, candidate ranking, or the interaction between these stages.</p>"},{"location":"machine-learning/evaluation/#designing-evaluation-that-captures-system-behavior","title":"Designing Evaluation That Captures System Behavior","text":"<p>The integrated evaluation process must capture both individual component performance and emergent system behavior that arises from their interaction. This requires thinking carefully about what questions you want the evaluation to answer and designing metrics that provide actionable insights.</p> <p>The evaluation process begins by establishing ground truth about user preferences from your held-out test data. For each test user, you identify movies they actually rated positively in your temporal test split. These represent the \"correct answers\" that your integrated system should ideally recommend.</p> <p>The evaluation then simulates the complete recommendation pipeline for each test user. Your two-tower model generates candidate sets of varying sizes, and BERT4Rec ranks these candidates using the user's interaction history up to the temporal split point. This simulation mirrors exactly what happens during real recommendation serving.</p> <p>The key insight involves measuring performance at multiple levels of the system simultaneously. You measure retrieval performance by examining whether relevant items appear anywhere in the candidate sets generated by the two-tower model. You measure ranking performance by examining whether BERT4Rec places relevant items at the top of the reranked lists. You measure integrated performance by examining the final recommendations that users would actually see.</p> <p>Let me walk you through how this multi-level measurement works in practice. Consider a test user who loved \"Interstellar\" during the test period. The evaluation traces this example through your system:</p> <p>First, the two-tower model generates 100 candidates for this user. The evaluation records whether \"Interstellar\" appears anywhere in these 100 candidates. If it doesn't appear, you've identified a retrieval failure. If it appears at position 87, you know the two-tower model recognized some relevance but didn't prioritize it highly.</p> <p>Next, BERT4Rec ranks these 100 candidates using the user's sequence history. The evaluation records whether \"Interstellar\" moves up or down in the rankings. If BERT4Rec moves it from position 87 to position 3, this indicates that sequential modeling provided valuable signals that pure collaborative filtering missed.</p> <p>Finally, the evaluation examines the top 10 final recommendations that the user would see. Whether \"Interstellar\" appears in these top 10 positions determines whether your integrated system would successfully recommend this relevant movie to the user.</p>"},{"location":"machine-learning/evaluation/#understanding-the-metrics-that-matter","title":"Understanding the Metrics That Matter","text":"<p>The integrated evaluation produces several types of metrics that each illuminate different aspects of system performance. Understanding what each metric tells you helps you diagnose problems and guide improvements.</p> <p>Coverage metrics measure how much of your movie catalog the system actually recommends across all users. Low coverage suggests that your system focuses too heavily on popular mainstream content, potentially creating filter bubbles where users only see obvious choices. High coverage indicates that your system can surface diverse content, enabling discovery of niche films that might delight specific users.</p> <p>But coverage metrics must be interpreted carefully in the context of your two-stage architecture. If your two-tower model generates diverse candidate sets but BERT4Rec consistently ranks the same popular movies at the top, you might observe high candidate coverage but low final recommendation coverage. This pattern would suggest that your ranking stage needs improvement rather than your retrieval stage.</p> <p>Recall metrics measure what fraction of movies that users actually enjoyed appear somewhere in your recommendations. Recall at different cutoff points reveals how candidate set size affects system performance. You might discover that increasing candidate sets from 50 to 100 movies significantly improves recall, but expanding from 100 to 200 provides minimal benefits. This insight helps you optimize the computational trade-offs in your system.</p> <p>The evaluation also measures ranking correlation between your two-tower and BERT4Rec orderings. High correlation suggests that sequential modeling reinforces collaborative filtering patterns, potentially indicating redundancy. Low correlation suggests that BERT4Rec discovers different preference signals than your two-tower model, potentially indicating complementary value.</p>"},{"location":"machine-learning/evaluation/#analyzing-ranking-changes-to-understand-sequential-value","title":"Analyzing Ranking Changes to Understand Sequential Value","text":"<p>One of the most insightful aspects of integrated evaluation involves analyzing how BERT4Rec reorders the candidates from your two-tower model. This analysis reveals whether sequential modeling provides meaningful improvements over pure collaborative filtering or simply adds computational complexity without corresponding benefits.</p> <p>The evaluation tracks every movie that appears in both the two-tower ranking and the BERT4Rec ranking, computing how much each movie's position changes. Movies that move significantly upward in the BERT4Rec ranking represent cases where sequential context provided valuable signals that collaborative filtering missed.</p> <p>Consider a concrete example that illustrates this analysis. Your two-tower model might rank \"Ghost in the Shell\" at position 45 for a user based on general science fiction preferences. But BERT4Rec, seeing that the user recently watched \"Blade Runner\" and \"Ex Machina,\" might move \"Ghost in the Shell\" to position 8 based on the clear sequential pattern of cyberpunk exploration.</p> <p>The evaluation quantifies these ranking changes across all users and movies, providing statistics like average rank improvement, percentage of movies that moved up versus down, and correlation between the original and reranked orderings. These statistics help you understand whether BERT4Rec consistently provides value or only helps in specific circumstances.</p> <p>The analysis becomes particularly revealing when you examine which types of movies benefit most from sequential reranking. You might discover that BERT4Rec significantly improves rankings for movies in niche genres where collaborative filtering provides weak signals, but provides minimal improvements for mainstream blockbusters where collaborative patterns are strong.</p>"},{"location":"machine-learning/evaluation/#interpreting-system-level-performance-patterns","title":"Interpreting System-Level Performance Patterns","text":"<p>The integrated evaluation reveals system-level patterns that help you understand how your architecture performs across different types of users and scenarios. These patterns guide both immediate improvements and longer-term architectural decisions.</p> <p>User analysis reveals how system performance varies based on interaction history characteristics. Users with longer, more consistent viewing histories might benefit significantly from BERT4Rec's sequential modeling, while users with sparse or erratic viewing patterns might receive minimal improvements from the ranking stage. Understanding these patterns helps you identify when to apply sophisticated modeling versus when simpler approaches suffice.</p> <p>The evaluation also reveals temporal patterns in how ranking changes affect recommendation quality. You might discover that BERT4Rec provides substantial improvements for users who are currently in exploration phases, trying new genres or themes, but provides minimal improvements for users who are in exploitation phases, repeatedly watching similar content.</p> <p>Content analysis shows which types of movies benefit most from your integrated approach. New releases might see significant ranking improvements when BERT4Rec uses content features to identify thematic connections with user sequences. Niche art films might benefit from sequential understanding that recognizes sophisticated user taste development over time.</p>"},{"location":"machine-learning/evaluation/#diagnostic-capabilities-for-system-improvement","title":"Diagnostic Capabilities for System Improvement","text":"<p>The integrated evaluation provides diagnostic capabilities that help you identify specific areas for improvement rather than just overall performance scores. This diagnostic power becomes essential for iterative system development.</p> <p>When the evaluation reveals poor performance for specific users, you can trace through the recommendation pipeline to identify failure points. Maybe the two-tower model generates reasonable candidates, but BERT4Rec ranks them poorly due to insufficient sequence length. Maybe BERT4Rec would rank effectively, but the two-tower model fails to include relevant items in the candidate set.</p> <p>The evaluation can reveal systematic biases in your system performance. Perhaps your integrated approach works well for users who watch mainstream Hollywood films but fails for users who prefer international cinema. Perhaps the system excels at recommending within established genres but struggles with cross-genre recommendations.</p> <p>These diagnostic insights guide targeted improvements rather than general architecture changes. You might discover that improving your two-tower model's content feature integration would have larger impact than sophisticated BERT4Rec architecture modifications. Or you might find that BERT4Rec's attention mechanisms need refinement while your retrieval stage performs adequately.</p> <p>This comprehensive understanding of integrated evaluation helps you move beyond simple performance metrics toward deep insight into how your recommendation system behaves, why it succeeds or fails in specific circumstances, and where to focus development efforts for maximum impact on user satisfaction.</p>"},{"location":"machine-learning/evaluation/#integrated-recommendation-system-evaluation-mathematical-foundations-and-implementation","title":"Integrated Recommendation System Evaluation: Mathematical Foundations and Implementation","text":"<p>Understanding how to evaluate your two-stage recommendation system requires building mathematical frameworks that capture the complex interactions between retrieval and ranking. Let me walk you through the theoretical foundations alongside the concrete implementation details that make this evaluation both rigorous and actionable.</p>"},{"location":"machine-learning/evaluation/#mathematical-foundation-of-cascade-effects","title":"Mathematical Foundation of Cascade Effects","text":"<p>The fundamental challenge in evaluating integrated systems stems from what we can formalize as the cascade dependency problem. Your system's final performance depends on a composition of functions that cannot be evaluated independently.</p> <p>Let's define this mathematically. Your two-tower model performs a retrieval function:</p> \\[\\mathcal{R}(u) = \\text{TopK}(\\{(i, s_{ui}^{(2T)}) \\mid i \\in \\mathcal{I}\\}, k)\\] <p>where \\(s_{ui}^{(2T)}\\) represents the two-tower compatibility score between user \\(u\\) and item \\(i\\), and \\(\\mathcal{I}\\) represents your complete item catalog. This function returns the top-k candidates based on two-tower scoring.</p> <p>Your BERT4Rec model then performs a ranking function over these candidates:</p> \\[\\mathcal{B}(u, \\mathcal{C}_u) = \\text{Rank}(\\{(i, s_{ui}^{(B4R)}) \\mid i \\in \\mathcal{C}_u\\})\\] <p>where \\(\\mathcal{C}_u = \\mathcal{R}(u)\\) represents the candidate set from the two-tower model, and \\(s_{ui}^{(B4R)}\\) represents the BERT4Rec ranking score.</p> <p>The final recommendation function becomes:</p> \\[\\text{Recommend}(u, n) = \\text{TopN}(\\mathcal{B}(u, \\mathcal{R}(u)), n)\\] <p>This mathematical composition creates the cascade dependency. The domain of function \\(\\mathcal{B}\\) is entirely determined by the output of function \\(\\mathcal{R}\\). If \\(\\mathcal{R}(u)\\) fails to include relevant items in \\(\\mathcal{C}_u\\), then \\(\\mathcal{B}\\) cannot recover from this failure regardless of its sophistication.</p> <p>Here's how we implement this cascade evaluation in code:</p> <pre><code>def evaluate_cascade_effect(self, user_idx: int, ground_truth_items: List[int], \n                           k_values: List[int] = [50, 100, 200]) -&gt; Dict[str, Any]:\n    \"\"\"\n    Evaluate how cascade effects propagate through the two-stage system.\n\n    This function traces a specific user's recommendations through both stages,\n    measuring how retrieval failures affect ranking performance and vice versa.\n    The mathematical analysis quantifies the cascade dependency between stages.\n\n    Args:\n        user_idx: Index of user for cascade analysis\n        ground_truth_items: Movies the user actually liked in test data\n        k_values: Different candidate set sizes to analyze\n\n    Returns:\n        Detailed analysis of cascade effects and stage interactions\n    \"\"\"\n    cascade_analysis = {\n        'user_idx': user_idx,\n        'ground_truth_count': len(ground_truth_items),\n        'cascade_metrics': {}\n    }\n\n    for k in k_values:\n        # Stage 1: Two-tower candidate generation\n        # Measure retrieval effectiveness at different candidate set sizes\n        candidates, retrieval_scores = self.generate_two_tower_candidates(user_idx, k)\n\n        # Calculate retrieval metrics: how many relevant items reached ranking stage?\n        retrieved_relevant = set(candidates).intersection(set(ground_truth_items))\n        retrieval_recall = len(retrieved_relevant) / len(ground_truth_items) if ground_truth_items else 0\n\n        # Stage 2: BERT4Rec ranking of retrieved candidates\n        # Only items that survived retrieval can be ranked effectively\n        user_sequence = self.bert4rec_data_loader.user_sequences.get(user_idx, [])\n        ranked_candidates = self.rank_candidates_with_bert4rec(user_idx, candidates, user_sequence)\n\n        # Calculate ranking metrics: how well did BERT4Rec order the retrieved candidates?\n        top_10_recommendations = [idx for idx, score in ranked_candidates[:10]]\n        final_relevant = set(top_10_recommendations).intersection(set(ground_truth_items))\n        final_recall = len(final_relevant) / len(ground_truth_items) if ground_truth_items else 0\n\n        # Cascade effect analysis: measure impact of retrieval on ranking\n        # This is the key mathematical insight - ranking is bounded by retrieval\n        max_possible_final_recall = len(retrieved_relevant) / len(ground_truth_items) if ground_truth_items else 0\n        ranking_efficiency = final_recall / max_possible_final_recall if max_possible_final_recall &gt; 0 else 0\n\n        # Compute stage-specific performance bounds\n        cascade_metrics = {\n            'candidate_set_size': k,\n            'retrieval_recall': retrieval_recall,          # P(relevant item in candidates)\n            'max_possible_final_recall': max_possible_final_recall,  # Upper bound for ranking\n            'final_recall': final_recall,                  # P(relevant item in top-10)\n            'ranking_efficiency': ranking_efficiency,      # How well ranking used available candidates\n            'cascade_loss': max_possible_final_recall - final_recall,  # Performance lost to ranking\n            'retrieval_loss': 1.0 - max_possible_final_recall,        # Performance lost to retrieval\n        }\n\n        cascade_analysis['cascade_metrics'][f'k_{k}'] = cascade_metrics\n\n    return cascade_analysis\n</code></pre> <p>This implementation demonstrates the mathematical relationship between stages. The <code>max_possible_final_recall</code> represents the theoretical upper bound on ranking performance given the retrieval results. The <code>cascade_loss</code> quantifies how much performance the ranking stage sacrificed, while <code>retrieval_loss</code> quantifies the fundamental constraints imposed by the retrieval stage.</p>"},{"location":"machine-learning/evaluation/#mathematical-framework-for-multi-level-performance-measurement","title":"Mathematical Framework for Multi-Level Performance Measurement","text":"<p>To understand system behavior comprehensively, we need mathematical frameworks that measure performance at multiple levels simultaneously. Let's formalize the key metrics that capture different aspects of system effectiveness.</p> <p>The fundamental insight involves recognizing that traditional single-model metrics like accuracy or F1-score don't capture the multi-objective nature of recommendation systems. We need metrics that measure both individual component performance and emergent system behavior.</p> <p>Define the set of relevant items for user \\(u\\) as:</p> \\[\\mathcal{G}_u = \\{i \\in \\mathcal{I} \\mid r_{ui} \\geq \\tau\\}\\] <p>where \\(\\tau\\) represents our relevance threshold (e.g., thumbs up rating of 1.0).</p> <p>Our retrieval recall at candidate set size \\(k\\) becomes:</p> \\[\\text{Recall}_{\\text{retrieval}}@k = \\frac{|\\mathcal{R}(u) \\cap \\mathcal{G}_u|}{|\\mathcal{G}_u|}\\] <p>Our final recommendation recall at cutoff \\(n\\) becomes:</p> \\[\\text{Recall}_{\\text{final}}@n = \\frac{|\\text{TopN}(\\mathcal{B}(u, \\mathcal{R}(u)), n) \\cap \\mathcal{G}_u|}{|\\mathcal{G}_u|}\\] <p>The ranking effectiveness can be measured through the gain ratio:</p> \\[\\text{Ranking Gain} = \\frac{\\text{Recall}_{\\text{final}}@n}{\\text{Recall}_{\\text{retrieval}}@k}\\] <p>This ratio indicates how effectively the ranking stage utilizes the candidates provided by retrieval. A ratio close to 1.0 suggests that BERT4Rec successfully places relevant items at the top of candidate lists.</p> <p>Here's the implementation of this multi-level measurement framework:</p> <pre><code>def compute_multi_level_metrics(self, test_users: List[int], \n                               candidate_k: int = 100, final_n: int = 10) -&gt; Dict[str, float]:\n    \"\"\"\n    Compute performance metrics at multiple levels of the integrated system.\n\n    This implementation measures retrieval effectiveness, ranking effectiveness,\n    and integrated system performance using the mathematical frameworks defined above.\n    The metrics provide actionable insights into where improvements would be most valuable.\n\n    Args:\n        test_users: List of user indices for evaluation\n        candidate_k: Candidate set size for two-tower retrieval\n        final_n: Final recommendation list size\n\n    Returns:\n        Dictionary containing multi-level performance metrics\n    \"\"\"\n    # Initialize metric accumulators for mathematical aggregation\n    retrieval_recalls = []\n    final_recalls = []\n    ranking_gains = []\n    coverage_items = set()\n\n    for user_idx in test_users:\n        # Get ground truth for this user from temporal test split\n        ground_truth = self._get_user_ground_truth(user_idx)\n\n        if not ground_truth:\n            continue  # Skip users without test interactions\n\n        # Stage 1: Two-tower candidate generation and retrieval metrics\n        candidates, _ = self.generate_two_tower_candidates(user_idx, candidate_k)\n        retrieved_relevant = set(candidates).intersection(set(ground_truth))\n\n        # Retrieval recall: R_retrieval@k = |C_u \u2229 G_u| / |G_u|\n        retrieval_recall = len(retrieved_relevant) / len(ground_truth)\n        retrieval_recalls.append(retrieval_recall)\n\n        # Stage 2: BERT4Rec ranking and final metrics\n        user_sequence = self.bert4rec_data_loader.user_sequences.get(user_idx, [])\n        ranked_results = self.rank_candidates_with_bert4rec(user_idx, candidates, user_sequence)\n\n        final_recommendations = [idx for idx, score in ranked_results[:final_n]]\n        final_relevant = set(final_recommendations).intersection(set(ground_truth))\n\n        # Final recall: R_final@n = |Top-N \u2229 G_u| / |G_u|\n        final_recall = len(final_relevant) / len(ground_truth)\n        final_recalls.append(final_recall)\n\n        # Ranking effectiveness: how well did BERT4Rec utilize available candidates?\n        # Ranking gain = (R_final@n) / (R_retrieval@k) when R_retrieval@k &gt; 0\n        if retrieval_recall &gt; 0:\n            ranking_gain = final_recall / retrieval_recall\n            ranking_gains.append(ranking_gain)\n\n        # Coverage analysis: track diversity of recommended items\n        coverage_items.update(final_recommendations)\n\n    # Aggregate metrics across all test users using mathematical averages\n    metrics = {\n        'avg_retrieval_recall': np.mean(retrieval_recalls),\n        'avg_final_recall': np.mean(final_recalls), \n        'avg_ranking_gain': np.mean(ranking_gains) if ranking_gains else 0.0,\n        'catalog_coverage': len(coverage_items) / self.two_tower_data_loader.num_movies,\n        'num_evaluated_users': len(test_users)\n    }\n\n    # Compute statistical significance measures for metric reliability\n    metrics['retrieval_recall_std'] = np.std(retrieval_recalls)\n    metrics['final_recall_std'] = np.std(final_recalls)\n\n    # Mathematical bounds analysis: what's theoretically possible?\n    # The integrated system recall is bounded above by retrieval recall\n    metrics['theoretical_upper_bound'] = metrics['avg_retrieval_recall']\n    metrics['ranking_efficiency'] = metrics['avg_final_recall'] / metrics['avg_retrieval_recall'] if metrics['avg_retrieval_recall'] &gt; 0 else 0\n\n    return metrics\n\ndef _get_user_ground_truth(self, user_idx: int) -&gt; List[int]:\n    \"\"\"Extract ground truth relevant items for user from temporal test split.\"\"\"\n    # This would implement temporal splitting logic to get items the user\n    # actually rated positively in the test period\n    # Implementation depends on your specific temporal splitting strategy\n    pass\n</code></pre> <p>This implementation captures the mathematical relationships between different performance levels. The <code>theoretical_upper_bound</code> demonstrates how retrieval performance constrains final system performance, while <code>ranking_efficiency</code> measures how well BERT4Rec utilizes the opportunities provided by the two-tower stage.</p>"},{"location":"machine-learning/evaluation/#mathematical-analysis-of-ranking-changes","title":"Mathematical Analysis of Ranking Changes","text":"<p>Understanding how BERT4Rec reorders candidates requires sophisticated mathematical analysis that goes beyond simple before-and-after comparisons. We need metrics that capture the magnitude, direction, and significance of ranking changes across different types of content and users.</p> <p>Let's define the ranking change analysis mathematically. For user \\(u\\) and item \\(i\\), let \\(r_i^{(2T)}\\) represent the rank of item \\(i\\) in the two-tower ordering, and \\(r_i^{(B4R)}\\) represent its rank in the BERT4Rec ordering. The rank change becomes:</p> \\[\\Delta r_i = r_i^{(2T)} - r_i^{(B4R)}\\] <p>Positive values indicate that BERT4Rec moved the item up in rankings, while negative values indicate downward movement. We can aggregate these changes across users and items to understand system-wide patterns.</p> <p>The rank correlation between the two orderings can be measured using Spearman's correlation coefficient:</p> \\[\\rho = 1 - \\frac{6 \\sum_{i=1}^n (r_i^{(2T)} - r_i^{(B4R)})^2}{n(n^2 - 1)}\\] <p>where \\(n\\) represents the number of items in the candidate set. Low correlation indicates that BERT4Rec discovers different preference signals than collaborative filtering, potentially adding value through sequential understanding.</p> <p>Here's the mathematical implementation of ranking change analysis:</p> <pre><code>def analyze_ranking_changes(self, user_idx: int, candidate_k: int = 100) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform comprehensive mathematical analysis of how BERT4Rec reorders candidates.\n\n    This analysis quantifies the magnitude and direction of ranking changes,\n    providing insights into when and why sequential modeling improves recommendations.\n    The mathematical framework enables systematic understanding of model interactions.\n\n    Args:\n        user_idx: User for ranking change analysis\n        candidate_k: Size of candidate set to analyze\n\n    Returns:\n        Detailed mathematical analysis of ranking changes and their implications\n    \"\"\"\n    # Generate two-tower candidate ordering\n    candidates, two_tower_scores = self.generate_two_tower_candidates(user_idx, candidate_k)\n\n    # Generate BERT4Rec reordering of the same candidates\n    user_sequence = self.bert4rec_data_loader.user_sequences.get(user_idx, [])\n    bert4rec_results = self.rank_candidates_with_bert4rec(user_idx, candidates, user_sequence)\n    bert4rec_ordering = [idx for idx, score in bert4rec_results]\n\n    # Mathematical analysis of ranking changes\n    ranking_changes = []\n    position_improvements = 0\n    position_declines = 0\n\n    for bert4rec_rank, movie_idx in enumerate(bert4rec_ordering):\n        # Find this movie's position in the original two-tower ordering\n        if movie_idx in candidates:\n            two_tower_rank = candidates.index(movie_idx)\n\n            # Calculate rank change: \u0394r_i = r_i^(2T) - r_i^(B4R)\n            # Positive values mean BERT4Rec moved item up (better ranking)\n            rank_change = two_tower_rank - bert4rec_rank\n\n            ranking_changes.append({\n                'movie_idx': movie_idx,\n                'two_tower_rank': two_tower_rank,\n                'bert4rec_rank': bert4rec_rank,\n                'rank_change': rank_change,\n                'improvement': rank_change &gt; 0\n            })\n\n            if rank_change &gt; 0:\n                position_improvements += 1\n            elif rank_change &lt; 0:\n                position_declines += 1\n\n    # Compute aggregate mathematical statistics\n    rank_change_values = [change['rank_change'] for change in ranking_changes]\n\n    analysis = {\n        'total_analyzed_items': len(ranking_changes),\n        'mean_rank_change': np.mean(rank_change_values) if rank_change_values else 0,\n        'std_rank_change': np.std(rank_change_values) if rank_change_values else 0,\n        'median_rank_change': np.median(rank_change_values) if rank_change_values else 0,\n        'max_improvement': max(rank_change_values) if rank_change_values else 0,\n        'max_decline': min(rank_change_values) if rank_change_values else 0,\n        'items_improved': position_improvements,\n        'items_declined': position_declines,\n        'improvement_rate': position_improvements / len(ranking_changes) if ranking_changes else 0\n    }\n\n    # Spearman rank correlation: \u03c1 = 1 - (6\u03a3d\u00b2)/(n(n\u00b2-1))\n    # This measures how much the two orderings agree\n    if len(ranking_changes) &gt; 1:\n        analysis['spearman_correlation'] = self._compute_spearman_correlation(\n            candidates, bert4rec_ordering\n        )\n\n    # Statistical significance testing for ranking changes\n    # Use Wilcoxon signed-rank test to determine if changes are significant\n    if len(rank_change_values) &gt; 10:\n        from scipy import stats\n        statistic, p_value = stats.wilcoxon(rank_change_values)\n        analysis['wilcoxon_statistic'] = statistic\n        analysis['wilcoxon_p_value'] = p_value\n        analysis['changes_significant'] = p_value &lt; 0.05\n\n    return analysis\n\ndef _compute_spearman_correlation(self, original_order: List[int], \n                                reranked_order: List[int]) -&gt; float:\n    \"\"\"\n    Compute Spearman rank correlation coefficient between two orderings.\n\n    The mathematical formula: \u03c1 = 1 - (6\u03a3d\u00b2)/(n(n\u00b2-1))\n    where d represents rank differences for each item.\n    \"\"\"\n    common_items = set(original_order).intersection(set(reranked_order))\n\n    if len(common_items) &lt; 2:\n        return 0.0\n\n    # Get ranks for common items in both orderings\n    rank_diffs_squared = []\n\n    for item in common_items:\n        original_rank = original_order.index(item)\n        reranked_rank = reranked_order.index(item) \n        rank_diff = original_rank - reranked_rank\n        rank_diffs_squared.append(rank_diff ** 2)\n\n    n = len(common_items)\n    sum_diff_squared = sum(rank_diffs_squared)\n\n    # Spearman correlation formula: \u03c1 = 1 - (6\u03a3d\u00b2)/(n(n\u00b2-1))\n    correlation = 1 - (6 * sum_diff_squared) / (n * (n**2 - 1))\n\n    return correlation\n</code></pre> <p>This mathematical analysis provides quantitative insights into how sequential modeling affects recommendation ordering. The Spearman correlation reveals whether BERT4Rec discovers genuinely different preference signals, while the statistical significance testing determines whether observed changes are meaningful rather than random.</p>"},{"location":"machine-learning/evaluation/#implementation-of-diagnostic-analysis-framework","title":"Implementation of Diagnostic Analysis Framework","text":"<p>The diagnostic framework provides the mathematical tools needed to identify specific failure modes and improvement opportunities in your integrated system. This analysis goes beyond aggregate performance metrics to understand why your system succeeds or fails in particular circumstances.</p> <p>The diagnostic approach involves segmenting your evaluation results along multiple dimensions and computing performance statistics for each segment. This segmentation reveals patterns that guide targeted improvements rather than general architectural changes.</p> <pre><code>def perform_diagnostic_analysis(self, evaluation_results: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"\n    Comprehensive diagnostic analysis of integrated system performance patterns.\n\n    This framework segments performance results along multiple dimensions to identify\n    specific failure modes, success patterns, and improvement opportunities.\n    The mathematical analysis provides actionable insights for system optimization.\n\n    Args:\n        evaluation_results: Complete evaluation results from system testing\n\n    Returns:\n        Detailed diagnostic analysis with improvement recommendations\n    \"\"\"\n    diagnostics = {\n        'user_segment_analysis': {},\n        'content_segment_analysis': {},\n        'failure_mode_analysis': {},\n        'improvement_opportunities': {}\n    }\n\n    # User segmentation analysis: how does performance vary by user characteristics?\n    diagnostics['user_segment_analysis'] = self._analyze_user_segments(evaluation_results)\n\n    # Content segmentation analysis: which types of movies benefit from integration?\n    diagnostics['content_segment_analysis'] = self._analyze_content_segments(evaluation_results)\n\n    # Failure mode identification: systematic analysis of poor performance cases\n    diagnostics['failure_mode_analysis'] = self._identify_failure_modes(evaluation_results)\n\n    # Improvement opportunity quantification: where would changes have most impact?\n    diagnostics['improvement_opportunities'] = self._quantify_improvement_opportunities(evaluation_results)\n\n    return diagnostics\n\ndef _analyze_user_segments(self, evaluation_results: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"\n    Segment users by interaction history characteristics and analyze performance.\n\n    Mathematical segmentation based on sequence length, rating patterns, and\n    temporal activity to understand how system performance varies across user types.\n    \"\"\"\n    user_segments = {\n        'active_users': [],      # Users with long interaction histories  \n        'casual_users': [],      # Users with sparse interaction histories\n        'explorer_users': [],    # Users with diverse genre preferences\n        'specialist_users': []   # Users with narrow genre focus\n    }\n\n    segment_performance = {}\n\n    for user_result in evaluation_results.get('individual_results', []):\n        user_idx = user_result['user_idx']\n\n        # Get user characteristics for segmentation\n        user_sequence = self.bert4rec_data_loader.user_sequences.get(user_idx, [])\n        sequence_length = len(user_sequence)\n\n        # Mathematical segmentation criteria\n        if sequence_length &gt;= 50:\n            segment = 'active_users'\n        elif sequence_length &gt;= 10:\n            segment = 'casual_users'  \n        elif self._compute_genre_diversity(user_sequence) &gt; 0.7:\n            segment = 'explorer_users'\n        else:\n            segment = 'specialist_users'\n\n        user_segments[segment].append(user_result)\n\n    # Compute performance statistics for each segment\n    for segment_name, segment_users in user_segments.items():\n        if segment_users:\n            segment_performance[segment_name] = self._compute_segment_metrics(segment_users)\n\n    return segment_performance\n\ndef _compute_genre_diversity(self, user_sequence: List[Dict]) -&gt; float:\n    \"\"\"\n    Calculate genre diversity score using Shannon entropy.\n\n    Mathematical formula: H = -\u03a3(p_i * log(p_i))\n    where p_i represents the proportion of interactions in genre i.\n    \"\"\"\n    if not user_sequence:\n        return 0.0\n\n    # Count interactions by genre (this would require genre metadata)\n    genre_counts = {}\n    total_interactions = len(user_sequence)\n\n    for interaction in user_sequence:\n        movie_idx = interaction['movie_idx']\n        # Get genre information for this movie (implementation depends on data structure)\n        genres = self._get_movie_genres(movie_idx)\n\n        for genre in genres:\n            genre_counts[genre] = genre_counts.get(genre, 0) + 1\n\n    # Compute Shannon entropy: H = -\u03a3(p_i * log(p_i))\n    entropy = 0.0\n    for count in genre_counts.values():\n        p_i = count / total_interactions\n        if p_i &gt; 0:\n            entropy -= p_i * np.log2(p_i)\n\n    # Normalize by maximum possible entropy (log of number of genres)\n    max_entropy = np.log2(len(genre_counts)) if genre_counts else 1\n    normalized_entropy = entropy / max_entropy if max_entropy &gt; 0 else 0\n\n    return normalized_entropy\n\ndef _identify_failure_modes(self, evaluation_results: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"\n    Systematic identification of failure patterns in the integrated system.\n\n    Mathematical analysis of cases where performance falls below expectations,\n    with statistical classification of failure types and their frequencies.\n    \"\"\"\n    failure_modes = {\n        'retrieval_failures': [],    # Two-tower failed to find relevant items\n        'ranking_failures': [],     # BERT4Rec failed to rank well despite good candidates\n        'cascade_failures': [],     # Poor interaction between stages\n        'cold_start_failures': []   # New users or items with insufficient data\n    }\n\n    failure_threshold = 0.1  # Define poor performance as recall &lt; 0.1\n\n    for user_result in evaluation_results.get('individual_results', []):\n        user_idx = user_result['user_idx']\n\n        # Analyze each configuration to identify failure patterns\n        for config_key, config_result in user_result.get('results_by_config', {}).items():\n            if 'error' in config_result:\n                continue\n\n            # Extract performance metrics for failure analysis\n            final_recall = self._extract_recall_metric(config_result)\n            retrieval_recall = self._extract_retrieval_recall(config_result)\n\n            if final_recall &lt; failure_threshold:\n                # Classify the type of failure based on mathematical criteria\n                if retrieval_recall &lt; failure_threshold:\n                    failure_type = 'retrieval_failures'\n                elif retrieval_recall &gt; 0.5 and final_recall &lt; retrieval_recall * 0.3:\n                    failure_type = 'ranking_failures'  \n                elif retrieval_recall &gt; 0.3 and final_recall &lt; 0.1:\n                    failure_type = 'cascade_failures'\n                else:\n                    failure_type = 'cold_start_failures'\n\n                failure_modes[failure_type].append({\n                    'user_idx': user_idx,\n                    'config': config_key,\n                    'final_recall': final_recall,\n                    'retrieval_recall': retrieval_recall,\n                    'failure_severity': failure_threshold - final_recall\n                })\n\n    # Statistical analysis of failure patterns\n    failure_statistics = {}\n    for failure_type, failures in failure_modes.items():\n        if failures:\n            failure_statistics[failure_type] = {\n                'count': len(failures),\n                'avg_severity': np.mean([f['failure_severity'] for f in failures]),\n                'affected_user_rate': len(set(f['user_idx'] for f in failures)) / len(evaluation_results.get('individual_results', []))\n            }\n\n    return {\n        'failure_modes': failure_modes,\n        'failure_statistics': failure_statistics\n    }\n</code></pre> <p>This diagnostic framework provides mathematical tools for understanding system behavior at a granular level. The user segmentation analysis reveals how different types of users benefit from your integrated approach, while the failure mode analysis identifies specific patterns that need attention.</p> <p>The mathematical foundations underlying these diagnostic tools enable systematic optimization of your recommendation system. Instead of making general architectural changes, you can target specific improvements that address the most common failure modes or enhance performance for the most important user segments.</p> <p>This comprehensive evaluation framework transforms the complex task of assessing integrated recommendation systems into a systematic process that provides actionable insights for improving user experience and system performance.</p>"},{"location":"machine-learning/models-overview/","title":"\ud83d\udcca ML Models Overview","text":"<p>This page provides a comprehensive comparison of all machine learning models used in Movie Genie.</p>"},{"location":"machine-learning/models-overview/#model-comparison","title":"\ud83c\udfaf Model Comparison","text":"Model Type Best For Input Data Output BERT4Rec Sequential Users with interaction history User sequence + item features Next-item predictions Two-Tower Collaborative Large-scale recommendations User-item interactions User/item embeddings Semantic Search Content-Based Text-based discovery Movie descriptions + queries Similarity rankings"},{"location":"machine-learning/models-overview/#performance-characteristics","title":"\ud83d\udcc8 Performance Characteristics","text":"Metric BERT4Rec Two-Tower Semantic Search Training Time High (hours) Medium (minutes) Low (pre-trained) Inference Speed Medium Fast Fast Memory Usage High Medium Low Cold-Start Good Excellent Excellent Personalization Excellent Good None Scalability Medium High High"},{"location":"machine-learning/models-overview/#when-to-use-which-model","title":"\ud83c\udfaf When to Use Which Model","text":""},{"location":"machine-learning/models-overview/#bert4rec","title":"BERT4Rec \ud83e\udde0","text":"<p>Use When</p> <ul> <li>\u2705 User has significant interaction history (5+ movies)</li> <li>\u2705 You want sequential/temporal recommendations</li> <li>\u2705 User preferences change over time</li> <li>\u2705 You have rich item content features</li> </ul> <p>Example Use Cases</p> <ul> <li>\"More like your recent watches\"</li> <li>\"Continue watching\" recommendations</li> <li>Trending predictions based on viewing patterns</li> </ul>"},{"location":"machine-learning/models-overview/#two-tower","title":"Two-Tower \ud83c\udfd7\ufe0f","text":"<p>Use When</p> <ul> <li>\u2705 You have large-scale user-item interaction data</li> <li>\u2705 You need fast, real-time recommendations</li> <li>\u2705 You want to find similar users or items</li> <li>\u2705 Cold-start scenarios with minimal history</li> </ul> <p>Example Use Cases</p> <ul> <li>Homepage personalized recommendations</li> <li>\"Users like you also watched\"</li> <li>Large-scale batch recommendations</li> </ul>"},{"location":"machine-learning/models-overview/#semantic-search","title":"Semantic Search \ud83d\udd0d","text":"<p>Use When</p> <ul> <li>\u2705 Users search with natural language queries</li> <li>\u2705 You want content-based discovery</li> <li>\u2705 Handling zero-shot scenarios</li> <li>\u2705 Complex, descriptive search needs</li> </ul> <p>Example Use Cases</p> <ul> <li>\"Sci-fi movies with time travel\"</li> <li>\"Funny movies for family night\"</li> <li>Genre and mood-based discovery</li> </ul>"},{"location":"machine-learning/models-overview/#model-architecture-comparison","title":"\ud83d\udd27 Model Architecture Comparison","text":""},{"location":"machine-learning/models-overview/#bert4rec-architecture","title":"BERT4Rec Architecture","text":"<pre><code>graph LR\n    A[User Sequence] --&gt; B[BERT Encoder]\n    B --&gt; C[Item Features]\n    C --&gt; D[Attention]\n    D --&gt; E[Next Item Probabilities]</code></pre>"},{"location":"machine-learning/models-overview/#two-tower-architecture","title":"Two-Tower Architecture","text":"<pre><code>graph TB\n    A[User Features] --&gt; B[User Encoder]\n    C[Item Features] --&gt; D[Item Encoder]\n    B --&gt; E[User Embedding]\n    D --&gt; F[Item Embedding]\n    E --&gt; G[Cosine Similarity]\n    F --&gt; G\n    G --&gt; H[Ranking]</code></pre>"},{"location":"machine-learning/models-overview/#semantic-search-architecture","title":"Semantic Search Architecture","text":"<pre><code>graph LR\n    A[Text Query] --&gt; B[SentenceTransformer]\n    B --&gt; C[Query Embedding]\n    D[Movie Descriptions] --&gt; E[SentenceTransformer]\n    E --&gt; F[Movie Embeddings]\n    C --&gt; G[Similarity Search]\n    F --&gt; G\n    G --&gt; H[Ranked Results]</code></pre>"},{"location":"machine-learning/models-overview/#evaluation-metrics","title":"\ud83d\udcca Evaluation Metrics","text":""},{"location":"machine-learning/models-overview/#offline-metrics","title":"Offline Metrics","text":"<ul> <li>NDCG@K: Ranking quality</li> <li>Recall@K: Coverage of relevant items</li> <li>MAP: Mean Average Precision</li> <li>AUC: Area Under ROC Curve</li> </ul>"},{"location":"machine-learning/models-overview/#online-metrics","title":"Online Metrics","text":"<ul> <li>Click-Through Rate (CTR): User engagement</li> <li>Conversion Rate: Action completion</li> <li>Session Length: User retention</li> <li>Diversity: Recommendation variety</li> </ul>"},{"location":"machine-learning/models-overview/#implementation-strategy","title":"\ud83d\udee0\ufe0f Implementation Strategy","text":""},{"location":"machine-learning/models-overview/#development-phase","title":"Development Phase","text":"<ol> <li>Start with Two-Tower: Fastest to implement and validate</li> <li>Add Semantic Search: Enhance discovery capabilities</li> <li>Implement BERT4Rec: Advanced sequential modeling</li> </ol>"},{"location":"machine-learning/models-overview/#production-phase","title":"Production Phase","text":"<ol> <li>A/B Test: Compare models on real user behavior</li> <li>Ensemble: Combine models for different use cases</li> <li>Optimize: Fine-tune based on performance metrics</li> </ol>"},{"location":"machine-learning/models-overview/#model-integration-flow","title":"\ud83d\udd04 Model Integration Flow","text":"<pre><code>graph TD\n    A[User Request] --&gt; B{Request Type}\n    B --&gt;|Search Query| C[Semantic Search]\n    B --&gt;|Homepage| D[Two-Tower]\n    B --&gt;|Sequential| E[BERT4Rec]\n    C --&gt; F[Content Recommendations]\n    D --&gt; G[Collaborative Recommendations]\n    E --&gt; H[Sequential Recommendations]\n    F --&gt; I[Final Ranking]\n    G --&gt; I\n    H --&gt; I\n    I --&gt; J[User Interface]</code></pre>"},{"location":"machine-learning/models-overview/#detailed-model-documentation","title":"\ud83d\udcda Detailed Model Documentation","text":"<p>For comprehensive details on each model:</p> <ul> <li>BERT4Rec Model - Sequential recommendation implementation</li> <li>Two-Tower Model - Collaborative filtering architecture</li> <li>Semantic Search - Content-based search engine</li> <li>Model Evaluation - Performance analysis and comparison</li> </ul> <p>Each model serves a specific purpose in the recommendation ecosystem. Understanding their strengths and limitations helps you build more effective recommendation systems.</p>"},{"location":"machine-learning/semantic-search/","title":"Semantic Search Architecture: Mathematical Foundations and Implementation Guide","text":"<p>A comprehensive technical reference for natural language movie discovery systems</p>"},{"location":"machine-learning/semantic-search/#executive-summary","title":"Executive Summary","text":"<p>The semantic search system provides natural language query capabilities that enable users to discover movies through conversational expressions of their interests. This document details the mathematical foundations, architectural decisions, and implementation strategies for a semantic search engine designed for the Movie Genie recommendation system, leveraging existing EmbeddingGemma text representations for consistent query-document matching.</p> <p>Our implementation addresses the fundamental challenge of bridging human language and mathematical similarity computation. The system maps user queries like \"dark sci-fi movies about artificial intelligence\" into the same 768-dimensional semantic space as movie content representations, enabling precise relevance matching that understands thematic concepts beyond keyword matching.</p> <p>The resulting architecture achieves sub-second query processing latency while maintaining semantic understanding quality through configuration-driven design that enables systematic experimentation with different embedding models and preprocessing strategies.</p>"},{"location":"machine-learning/semantic-search/#problem-definition-and-mathematical-formulation","title":"Problem Definition and Mathematical Formulation","text":""},{"location":"machine-learning/semantic-search/#the-semantic-search-challenge","title":"The Semantic Search Challenge","text":"<p>Traditional movie discovery relies on explicit filtering through genre categories, release dates, or cast information. Users must translate their nuanced preferences into rigid categorical constraints. However, human movie preferences involve complex thematic concepts, mood associations, and stylistic elements that resist simple categorization.</p> <p>Consider the query \"movies about questioning reality with philosophical depth.\" This expression combines thematic content (reality questioning), narrative sophistication (philosophical depth), and implicit quality expectations that cannot be captured through conventional metadata filtering. The semantic search challenge involves understanding such complex queries and matching them against movie content that satisfies the expressed intent.</p> <p>Let \\(\\mathcal{Q}\\) represent the space of possible natural language queries and \\(\\mathcal{D}\\) represent the space of movie documents with rich content descriptions. The semantic search problem requires learning a relevance function:</p> \\[\\text{relevance}: \\mathcal{Q} \\times \\mathcal{D} \\rightarrow \\mathbb{R}\\] <p>that assigns high scores to query-document pairs where the document satisfies the information need expressed in the query, even when they use different vocabulary to describe similar concepts.</p>"},{"location":"machine-learning/semantic-search/#embedding-space-formulation","title":"Embedding Space Formulation","text":"<p>Semantic search solves the vocabulary mismatch problem by mapping both queries and documents into a shared embedding space where semantic similarity corresponds to geometric proximity. This approach transforms the relevance computation into a similarity calculation in learned representation space.</p> <p>Let \\(\\phi_q: \\mathcal{Q} \\rightarrow \\mathbb{R}^d\\) represent a query encoding function and \\(\\phi_d: \\mathcal{D} \\rightarrow \\mathbb{R}^d\\) represent a document encoding function. The semantic relevance becomes:</p> \\[\\text{relevance}(q, d) = \\text{sim}(\\phi_q(q), \\phi_d(d))\\] <p>where \\(\\text{sim}(\\cdot, \\cdot)\\) represents a similarity metric, typically cosine similarity for normalized embeddings:</p> \\[\\text{sim}(\\mathbf{u}, \\mathbf{v}) = \\frac{\\mathbf{u}^T \\mathbf{v}}{|\\mathbf{u}| |\\mathbf{v}|}\\] <p>The key insight involves ensuring that \\(\\phi_q\\) and \\(\\phi_d\\) map semantically related queries and documents to nearby points in the embedding space, enabling effective similarity-based retrieval.</p>"},{"location":"machine-learning/semantic-search/#architecture-design-and-implementation-strategy","title":"Architecture Design and Implementation Strategy","text":""},{"location":"machine-learning/semantic-search/#system-components-overview","title":"System Components Overview","text":"<p>The semantic search architecture consists of three primary components that work together to transform natural language queries into ranked movie results:</p> <ol> <li>Query Encoder: Maps natural language queries to 768-dimensional semantic vectors</li> <li>Movie Embedding Loader: Organizes existing EmbeddingGemma movie representations for fast similarity computation</li> <li>Semantic Search Engine: Orchestrates the complete pipeline from query processing to result ranking</li> </ol> <p>This modular design enables independent development and testing of each component while maintaining clean interfaces between system layers.</p>"},{"location":"machine-learning/semantic-search/#query-encoding-architecture","title":"Query Encoding Architecture","text":"<p>The query encoder addresses the critical challenge of mapping arbitrary user text into the same semantic space as movie embeddings. Our implementation leverages EmbeddingGemma for consistency with existing movie representations, ensuring semantic alignment between query and document encodings.</p> <pre><code>class QueryEncoder:\n    def __init__(self, config_path: str = \"configs/semantic_search.yaml\"):\n        self.config = self._load_config(config_path)\n        self.model_name = self.config['model_name']  # google/embeddinggemma-300M\n\n        # Initialize text embedder using existing pipeline infrastructure\n        self.embedder = TextEmbedder(self.model_name)\n        self.encoding_dimension = 768  # EmbeddingGemma output dimension\n\n        # Query cache for performance optimization\n        self.query_cache = {}\n</code></pre> <p>The mathematical operation performed by the query encoder involves several preprocessing steps followed by embedding generation:</p> \\[\\mathbf{e}_q = \\text{EmbeddingGemma}(\\text{preprocess}(q))\\] <p>where preprocessing includes text normalization, abbreviation expansion, and whitespace handling to improve encoding consistency.</p>"},{"location":"machine-learning/semantic-search/#text-preprocessing-pipeline","title":"Text Preprocessing Pipeline","text":"<p>Query preprocessing normalizes the variability in human input while preserving semantic content. The preprocessing pipeline applies several transformations:</p> <p>Text Normalization: Converts queries to lowercase and normalizes whitespace to create consistent input format for the embedding model.</p> <p>Abbreviation Expansion: Maps domain-specific abbreviations to full terms using configurable mappings: - \"sci-fi\" \u2192 \"science fiction\" - \"rom-com\" \u2192 \"romantic comedy\" - \"ai\" \u2192 \"artificial intelligence\"</p> <p>This expansion bridges vocabulary gaps between user queries and movie descriptions, improving semantic matching accuracy.</p> <p>Cache Integration: Frequently used queries get cached to eliminate redundant encoding computation, reducing response latency for common searches.</p> <p>The complete preprocessing function implements:</p> <pre><code>def _preprocess_query(self, query: str) -&gt; str:\n    processed = query.strip().lower()\n    processed = ' '.join(processed.split())  # Normalize whitespace\n    processed = self._expand_abbreviations(processed)\n    return processed\n</code></pre>"},{"location":"machine-learning/semantic-search/#movie-embedding-integration","title":"Movie Embedding Integration","text":"<p>The movie embedding loader extracts and organizes the existing EmbeddingGemma text embeddings computed during content feature engineering. This integration ensures semantic consistency between movie representations used for search and those used for recommendation.</p> <p>The loader handles practical data quality challenges: - Missing embeddings for some movies - Different embedding storage formats in parquet files - Memory-efficient loading of large embedding matrices</p> <p>The mathematical foundation involves organizing movie embeddings into a matrix \\(\\mathbf{M} \\in \\mathbb{R}^{n \\times 768}\\) where each row represents one movie's semantic embedding. This matrix gets pre-normalized for cosine similarity computation:</p> \\[\\mathbf{M}_{\\text{norm}} = \\frac{\\mathbf{M}}{||\\mathbf{M}||_2}\\] <p>enabling efficient similarity calculation through matrix multiplication.</p>"},{"location":"machine-learning/semantic-search/#similarity-computation-and-ranking","title":"Similarity Computation and Ranking","text":"<p>The core search operation computes semantic similarity between the encoded query vector and all movie embedding vectors:</p> \\[\\mathbf{scores} = \\mathbf{M}_{\\text{norm}} \\mathbf{e}_q\\] <p>This matrix-vector multiplication produces similarity scores for all movies simultaneously, with computational complexity \\(O(nd)\\) where \\(n\\) represents the number of movies and \\(d\\) represents the embedding dimension.</p> <p>The ranking process selects the top-\\(k\\) movies with highest similarity scores:</p> \\[\\text{results} = \\text{TopK}(\\mathbf{scores}, k)\\] <p>Results include both similarity scores and movie metadata for presentation to users.</p>"},{"location":"machine-learning/semantic-search/#mathematical-properties-and-theoretical-foundations","title":"Mathematical Properties and Theoretical Foundations","text":""},{"location":"machine-learning/semantic-search/#semantic-space-geometry","title":"Semantic Space Geometry","text":"<p>The learned embedding space exhibits geometric properties that enable semantic reasoning. Movies exploring similar themes cluster together in the 768-dimensional space, while the query encoding process maps related queries near relevant movie clusters.</p> <p>The cosine similarity metric provides several theoretical advantages for semantic search:</p> <ol> <li>Scale Invariance: Similarity depends on direction rather than magnitude, focusing on semantic content rather than text length</li> <li>Bounded Scores: Cosine similarity ranges from -1 to 1, providing interpretable relevance measures</li> <li>Efficient Computation: Normalized embeddings enable similarity calculation through simple dot products</li> </ol> <p>The geometric interpretation involves understanding that small angles between embedding vectors correspond to high semantic similarity, while large angles indicate semantic divergence.</p>"},{"location":"machine-learning/semantic-search/#query-document-alignment","title":"Query-Document Alignment","text":"<p>The effectiveness of semantic search depends critically on the alignment between query and document representations. Using EmbeddingGemma for both encoding tasks ensures this alignment by leveraging the same learned semantic understanding.</p> <p>Consider the mathematical relationship between query concepts and movie themes. A query about \"artificial intelligence\" should map to a region of embedding space that contains movies like \"Ex Machina,\" \"Her,\" and \"Blade Runner\" even though these movies might describe AI themes using different vocabulary (\"consciousness,\" \"synthetic beings,\" \"replicants\").</p> <p>The alignment property can be expressed mathematically as:</p> \\[\\text{sim}(\\phi_q(\\text{\"AI movies\"}), \\phi_d(\\text{movie about synthetic consciousness})) &gt; \\tau\\] <p>where \\(\\tau\\) represents a threshold for semantic relatedness.</p>"},{"location":"machine-learning/semantic-search/#dimensionality-and-representation-capacity","title":"Dimensionality and Representation Capacity","text":"<p>The 768-dimensional embedding space provides sufficient capacity to capture the nuanced semantic relationships relevant to movie recommendation. Each dimension can be interpreted as capturing some aspect of semantic meaning, though the specific meaning of individual dimensions remains opaque.</p> <p>The high dimensionality enables the representation of complex conceptual combinations. A query combining multiple constraints (\"dark atmospheric sci-fi with philosophical themes\") maps to a specific region of the embedding space that balances all specified attributes.</p>"},{"location":"machine-learning/semantic-search/#configuration-driven-design-philosophy","title":"Configuration-Driven Design Philosophy","text":""},{"location":"machine-learning/semantic-search/#separation-of-algorithm-and-parameters","title":"Separation of Algorithm and Parameters","text":"<p>The semantic search implementation separates algorithmic logic from parameter choices through comprehensive configuration management. This design enables systematic experimentation with different models, preprocessing strategies, and similarity thresholds without requiring code modifications.</p> <p>The configuration structure covers essential system parameters:</p> <pre><code># Model and encoding parameters\nmodel_name: \"google/embeddinggemma-300M\"\nnormalize_vectors: true\ncache_size: 1000\n\n# Data paths consistent with existing pipeline\nmovies_path: \"data/processed/content_features.parquet\"\n\n# Search behavior parameters\ndefault_results: 20\nmax_results: 100\n\n# Text preprocessing options\nabbreviations:\n  \"sci-fi\": \"science fiction\"\n  \"rom-com\": \"romantic comedy\"\n  \"ai\": \"artificial intelligence\"\n</code></pre> <p>This configuration approach demonstrates several software engineering principles:</p> <p>Single Source of Truth: All behavioral parameters exist in one location, eliminating inconsistencies between different parts of the system.</p> <p>Environment Consistency: The same configuration file works across development, testing, and production environments, reducing deployment complexity.</p> <p>Experimentation Support: Parameter modifications require only configuration changes, not code rebuilds or redeployment.</p>"},{"location":"machine-learning/semantic-search/#progressive-complexity-management","title":"Progressive Complexity Management","text":"<p>The simplified configuration structure follows the principle of progressive complexity: implement essential functionality with minimal configuration, then add parameters as specific requirements emerge.</p> <p>This approach contrasts with premature optimization where systems include extensive configuration options for features that may never be needed. The current configuration covers 100% of implemented functionality while remaining understandable and maintainable.</p> <p>Future extensions can add configuration sections for advanced indexing methods, detailed evaluation metrics, or performance optimization parameters when specific use cases require these capabilities.</p>"},{"location":"machine-learning/semantic-search/#integration-with-existing-pipeline-architecture","title":"Integration with Existing Pipeline Architecture","text":""},{"location":"machine-learning/semantic-search/#dvc-pipeline-extension","title":"DVC Pipeline Extension","text":"<p>The semantic search system integrates seamlessly with the existing DVC pipeline by consuming processed movie data and producing search capabilities as a new system component:</p> <pre><code>stages:\n  # Existing content feature processing\n  content_features:\n    cmd: python scripts/extract_tmdb_features.py\n    outs:\n      - data/processed/content_features.parquet\n\n  # Semantic search integration (future)\n  semantic_search_index:\n    cmd: python scripts/build_search_index.py\n    deps:\n      - data/processed/content_features.parquet\n      - configs/semantic_search.yaml\n    outs:\n      - models/semantic_search/search_index.pkl\n    metrics:\n      - metrics/search_performance.json\n</code></pre> <p>This integration maintains pipeline reproducibility while adding new discovery capabilities to the movie recommendation system.</p>"},{"location":"machine-learning/semantic-search/#feature-engineering-reuse","title":"Feature Engineering Reuse","text":"<p>The semantic search system leverages the comprehensive feature engineering developed during earlier pipeline stages. The EmbeddingGemma text embeddings computed for movie content features serve dual purposes:</p> <ol> <li>Content-based similarity for recommendation systems</li> <li>Semantic matching for natural language search queries</li> </ol> <p>This reuse demonstrates the value of careful feature engineering that creates versatile representations suitable for multiple downstream applications. The same movie embeddings that enable content-based recommendation also enable semantic search without additional processing overhead.</p>"},{"location":"machine-learning/semantic-search/#data-consistency-and-quality","title":"Data Consistency and Quality","text":"<p>The semantic search implementation handles practical data quality challenges that arise in production ML systems:</p> <p>Missing Embeddings: Some movies lack text embeddings due to insufficient content metadata. The system handles these gracefully by excluding them from search results rather than failing entirely.</p> <p>Format Variations: Parquet serialization might store embeddings in different formats (lists, arrays, strings). The loading process handles multiple formats robustly.</p> <p>Memory Management: Large embedding matrices require careful memory management for efficient loading and similarity computation.</p>"},{"location":"machine-learning/semantic-search/#performance-characteristics-and-optimization","title":"Performance Characteristics and Optimization","text":""},{"location":"machine-learning/semantic-search/#computational-complexity-analysis","title":"Computational Complexity Analysis","text":"<p>The semantic search system exhibits predictable computational complexity characteristics that scale with catalog size and query complexity:</p> <p>Query Encoding: \\(O(L \\cdot d)\\) where \\(L\\) represents query length in tokens and \\(d\\) represents embedding dimension. For typical queries, this operation completes in milliseconds.</p> <p>Similarity Computation: \\(O(n \\cdot d)\\) where \\(n\\) represents the number of movies in the catalog. For 10,000 movies and 768-dimensional embeddings, this requires approximately 7.7 million floating-point operations.</p> <p>Result Ranking: \\(O(n \\log k)\\) for selecting top-\\(k\\) results from \\(n\\) similarity scores using efficient sorting algorithms.</p> <p>The total search latency remains well below acceptable thresholds for interactive applications, typically completing within 100-200 milliseconds for catalogs containing tens of thousands of movies.</p>"},{"location":"machine-learning/semantic-search/#caching-and-memory-optimization","title":"Caching and Memory Optimization","text":"<p>The system employs several optimization strategies to minimize computational overhead:</p> <p>Query Caching: Frequently used queries get cached to eliminate redundant encoding computation. Cache size management prevents unbounded memory growth while maximizing cache hit rates.</p> <p>Embedding Precomputation: Movie embeddings get normalized once during system initialization rather than during each query, reducing per-query computation.</p> <p>Memory-Efficient Loading: Large embedding matrices are loaded incrementally and stored in efficient NumPy arrays to minimize memory footprint.</p>"},{"location":"machine-learning/semantic-search/#scalability-considerations","title":"Scalability Considerations","text":"<p>The current implementation scales effectively to catalogs containing hundreds of thousands of movies. For larger catalogs or higher query volumes, several optimization approaches become relevant:</p> <p>Approximate Similarity Search: Libraries like FAISS enable approximate nearest neighbor search with sub-linear computational complexity, trading slight accuracy for significant speed improvements.</p> <p>Distributed Computation: Similarity calculations can be distributed across multiple compute nodes for extremely large catalogs.</p> <p>Indexing Strategies: Advanced indexing methods can reduce search complexity through hierarchical clustering or learned indexes.</p>"},{"location":"machine-learning/semantic-search/#evaluation-framework-and-quality-metrics","title":"Evaluation Framework and Quality Metrics","text":""},{"location":"machine-learning/semantic-search/#search-quality-assessment","title":"Search Quality Assessment","text":"<p>Evaluating semantic search quality requires different metrics than traditional recommendation evaluation. Search evaluation focuses on relevance, precision, and user satisfaction rather than prediction accuracy or collaborative filtering effectiveness.</p> <p>Relevance Metrics: Measure whether search results actually match user intent expressed in natural language queries.</p> <p>Diversity Metrics: Evaluate whether results cover different aspects of complex queries rather than focusing narrowly on single interpretations.</p> <p>User Satisfaction: Assess whether users find search results helpful for movie discovery tasks.</p>"},{"location":"machine-learning/semantic-search/#systematic-evaluation-approach","title":"Systematic Evaluation Approach","text":"<p>A comprehensive evaluation framework includes multiple assessment dimensions:</p> <pre><code>class SearchEvaluator:\n    def evaluate_query_set(self, queries: List[str], k: int = 10):\n        \"\"\"Evaluate search quality across diverse query types.\"\"\"\n        results = {\n            'semantic_queries': self._evaluate_thematic_queries(),\n            'similarity_queries': self._evaluate_similarity_queries(),\n            'factual_queries': self._evaluate_factual_queries(),\n            'aggregate_metrics': self._compute_aggregate_metrics()\n        }\n        return results\n</code></pre> <p>This evaluation approach enables systematic assessment of search quality across different query types and use cases.</p>"},{"location":"machine-learning/semantic-search/#continuous-quality-monitoring","title":"Continuous Quality Monitoring","text":"<p>Production semantic search systems require ongoing quality monitoring to identify degradation or opportunities for improvement:</p> <p>Query Analysis: Understanding what users actually search for versus what the system expects.</p> <p>Result Click-Through Rates: Measuring whether users find search results sufficiently relevant to explore.</p> <p>Search Abandonment: Tracking cases where users reformulate queries multiple times, indicating poor initial results.</p>"},{"location":"machine-learning/semantic-search/#production-deployment-considerations","title":"Production Deployment Considerations","text":""},{"location":"machine-learning/semantic-search/#system-architecture-requirements","title":"System Architecture Requirements","text":"<p>Production semantic search deployment requires several infrastructure components:</p> <p>Search API: RESTful interface accepting natural language queries and returning ranked movie results with metadata.</p> <p>Embedding Serving: Efficient serving of large embedding matrices with appropriate caching strategies.</p> <p>Configuration Management: Dynamic configuration updates for experimentation without system restarts.</p> <p>Monitoring and Alerting: Real-time visibility into search performance, error rates, and quality metrics.</p>"},{"location":"machine-learning/semantic-search/#integration-with-existing-systems","title":"Integration with Existing Systems","text":"<p>The semantic search capabilities integrate with existing recommendation infrastructure through well-defined interfaces:</p> <p>Hybrid Search-Recommendation: Combining semantic search results with personalized ranking based on user interaction history.</p> <p>Content Discovery: Using semantic search to power content discovery features that help users explore the movie catalog.</p> <p>Query Suggestion: Leveraging search query patterns to suggest relevant searches to users.</p>"},{"location":"machine-learning/semantic-search/#deployment-and-maintenance","title":"Deployment and Maintenance","text":"<p>The configuration-driven design simplifies deployment and maintenance operations:</p> <p>Model Updates: New embedding models can be deployed through configuration changes rather than code modifications.</p> <p>Parameter Tuning: Search behavior adjustments require only configuration updates, enabling rapid experimentation.</p> <p>Performance Optimization: Query caching parameters and similarity thresholds can be adjusted based on production performance data.</p>"},{"location":"machine-learning/semantic-search/#future-enhancements-and-research-directions","title":"Future Enhancements and Research Directions","text":""},{"location":"machine-learning/semantic-search/#advanced-query-understanding","title":"Advanced Query Understanding","text":"<p>Current implementation handles queries as atomic text units. Future enhancements could include:</p> <p>Intent Classification: Distinguishing between different types of movie search intents (thematic, similarity-based, factual).</p> <p>Multi-Constraint Queries: Better handling of queries that combine multiple constraints (\"recent sci-fi movies with high ratings\").</p> <p>Conversational Context: Maintaining context across multiple related queries in a search session.</p>"},{"location":"machine-learning/semantic-search/#personalization-integration","title":"Personalization Integration","text":"<p>Semantic search results could be personalized based on user interaction history:</p> <p>User-Aware Ranking: Adjusting search result ordering based on individual user preferences learned through recommendation models.</p> <p>Contextual Search: Considering user's recent viewing history when interpreting ambiguous queries.</p> <p>Preference Learning: Adapting query understanding based on which search results users find most relevant.</p>"},{"location":"machine-learning/semantic-search/#performance-and-scale-optimization","title":"Performance and Scale Optimization","text":"<p>As the system scales to larger catalogs and higher query volumes, several optimization approaches become relevant:</p> <p>Advanced Indexing: Implementing approximate nearest neighbor search for sub-linear query processing.</p> <p>Distributed Serving: Scaling search computation across multiple nodes for extremely large catalogs.</p> <p>Learned Optimization: Using machine learning to optimize search parameters based on usage patterns.</p>"},{"location":"machine-learning/semantic-search/#conclusion","title":"Conclusion","text":"<p>The semantic search system provides a mathematically principled approach to natural language movie discovery that leverages existing content representations for consistent semantic understanding. The configuration-driven design enables systematic experimentation while maintaining production readiness.</p> <p>The integration with existing pipeline infrastructure demonstrates how careful architectural planning enables new capabilities without disrupting established workflows. The semantic search functionality complements existing recommendation capabilities by enabling active discovery through natural language queries.</p> <p>Future development can build upon this foundation to create increasingly sophisticated query understanding and personalized search experiences that help users discover movies that match their specific interests and preferences expressed through natural language.</p>"},{"location":"machine-learning/two_tower/","title":"Two-Tower Model Architecture: Mathematical Foundations and Implementation Guide","text":"<p>A comprehensive technical reference for neural collaborative filtering in movie recommendation systems</p>"},{"location":"machine-learning/two_tower/#executive-summary","title":"Executive Summary","text":"<p>The two-tower model represents a scalable solution to the fundamental computational challenge in modern recommendation systems: how to serve personalized recommendations from massive catalogs within strict latency constraints. This document details the mathematical foundations, architectural decisions, and implementation strategies for a two-tower model designed for the Movie Genie recommendation system, integrating rich content features with collaborative filtering signals through neural network architectures.</p> <p>Our implementation addresses the specific characteristics of the Netflix thumbs rating system (-1.0, 1.0, 2.0) and leverages the sophisticated content features developed through TMDB metadata processing and EmbeddingGemma semantic analysis. The resulting architecture achieves the computational efficiency required for real-time recommendation serving while maintaining the recommendation quality benefits of hybrid collaborative and content-based approaches.</p>"},{"location":"machine-learning/two_tower/#problem-definition-and-mathematical-formulation","title":"Problem Definition and Mathematical Formulation","text":""},{"location":"machine-learning/two_tower/#the-recommendation-scalability-challenge","title":"The Recommendation Scalability Challenge","text":"<p>Consider a recommendation system serving a catalog of \\(|I|\\) items to \\(|U|\\) users, where we wish to predict preference scores for all user-item pairs. The naive approach requires computing \\(|U| \\times |I|\\) compatibility scores per recommendation request. For realistic scales where \\(|U| = 100,000\\) and \\(|I| = 80,000\\), this translates to \\(8 \\times 10^9\\) computations per request, creating an intractable computational burden.</p> <p>Let \\(R \\in \\mathbb{R}^{|U| \\times |I|}\\) represent the user-item interaction matrix, where \\(R_{ui}\\) denotes user \\(u\\)'s rating for item \\(i\\). Traditional collaborative filtering approaches learn a direct prediction function:</p> \\[\\hat{r}_{ui} = f(u, i, \\Theta)\\] <p>where \\(\\Theta\\) represents model parameters. The computational complexity of this approach scales as \\(O(|U| \\times |I|)\\) for each recommendation request, making real-time serving impractical at scale.</p>"},{"location":"machine-learning/two_tower/#two-tower-mathematical-framework","title":"Two-Tower Mathematical Framework","text":"<p>The two-tower architecture reformulates the recommendation problem by learning separate embedding functions that map users and items into a shared \\(d\\)-dimensional space:</p> \\[\\mathbf{e}_u = f_{\\text{user}}(\\mathbf{x}_u; \\Theta_u) \\in \\mathbb{R}^d$$ $$\\mathbf{e}_i = f_{\\text{item}}(\\mathbf{x}_i; \\Theta_i) \\in \\mathbb{R}^d\\] <p>where \\(\\mathbf{x}_u\\) represents user features, \\(\\mathbf{x}_i\\) represents item features, and \\(\\Theta_u\\), \\(\\Theta_i\\) are the respective tower parameters. The compatibility score becomes:</p> \\[\\hat{r}_{ui} = \\mathbf{e}_u^T \\mathbf{e}_i = \\sum_{k=1}^{d} e_{uk} \\cdot e_{ik}\\] <p>This formulation enables crucial computational optimizations. Since item features change infrequently, item embeddings \\(\\mathbf{e}_i\\) can be pre-computed and cached. Recommendation generation requires computing only the user embedding \\(\\mathbf{e}_u\\), then performing \\(O(|I|)\\) dot products against cached item embeddings, reducing the computational complexity from \\(O(|U| \\times |I|)\\) to \\(O(|I|)\\) per request.</p>"},{"location":"machine-learning/two_tower/#collaborative-filtering-through-embedding-learning","title":"Collaborative Filtering Through Embedding Learning","text":"<p>The learning process discovers embedding spaces where geometric relationships encode preference patterns. Users with similar preferences develop similar embedding vectors, while items that appeal to similar user segments cluster in the embedding space. This emergent structure enables collaborative filtering: the model can recommend items liked by users with similar embeddings, even without explicit content similarity.</p> <p>The mathematical foundation relies on the assumption that user preferences follow low-dimensional patterns that can be captured through embedding representations. The model learns these patterns by observing interaction data and adjusting embeddings to minimize prediction errors across the training dataset.</p>"},{"location":"machine-learning/two_tower/#neural-network-architecture-design","title":"Neural Network Architecture Design","text":""},{"location":"machine-learning/two_tower/#user-tower-architecture","title":"User Tower Architecture","text":"<p>The user tower implements a neural network that transforms user characteristics into dense embeddings. For user \\(u\\), the forward pass follows:</p> \\[\\mathbf{h}_u^{(0)} = \\mathbf{W}_{\\text{emb}} \\cdot \\text{one\\_hot}(u) \\in \\mathbb{R}^{d_{\\text{emb}}}\\] <p>where \\(\\mathbf{W}_{\\text{emb}} \\in \\mathbb{R}^{|U| \\times d_{\\text{emb}}}\\) represents learned user embeddings. The network then applies a series of fully connected transformations:</p> \\[\\mathbf{h}_u^{(l+1)} = \\text{ReLU}(\\mathbf{W}^{(l)} \\mathbf{h}_u^{(l)} + \\mathbf{b}^{(l)})\\] <p>for layers \\(l = 0, 1, \\ldots, L-1\\). The final layer produces normalized embeddings:</p> \\[\\mathbf{e}_u = \\frac{\\mathbf{W}^{(L)} \\mathbf{h}_u^{(L-1)} + \\mathbf{b}^{(L)}}{\\|\\mathbf{W}^{(L)} \\mathbf{h}_u^{(L-1)} + \\mathbf{b}^{(L)}\\|_2}\\] <p>The normalization ensures that \\(\\|\\mathbf{e}_u\\|_2 = 1\\), making the dot product equivalent to cosine similarity and bounding similarity scores to the interval \\([-1, 1]\\).</p>"},{"location":"machine-learning/two_tower/#item-tower-architecture","title":"Item Tower Architecture","text":"<p>The item tower processes rich content features alongside learned item embeddings. For item \\(i\\) with content features \\(\\mathbf{c}_i \\in \\mathbb{R}^{d_{\\text{content}}}\\), the input representation combines multiple feature types:</p> \\[\\mathbf{h}_i^{(0)} = [\\mathbf{W}_{\\text{item}} \\cdot \\text{one\\_hot}(i); \\mathbf{c}_i] \\in \\mathbb{R}^{d_{\\text{item}} + d_{\\text{content}}}\\] <p>where \\([\\cdot; \\cdot]\\) denotes concatenation. The content features \\(\\mathbf{c}_i\\) include: - TMDB numerical features: \\(\\mathbf{c}_{\\text{num}} \\in \\mathbb{R}^7\\) (budget, revenue, runtime, etc.) - One-hot language features: \\(\\mathbf{c}_{\\text{lang}} \\in \\{0,1\\}^{16}\\) - Categorical features: \\(\\mathbf{c}_{\\text{cat}} \\in \\{0,1\\}^5\\) - EmbeddingGemma text features: \\(\\mathbf{c}_{\\text{text}} \\in \\mathbb{R}^{768}\\)</p> <p>The combined feature vector \\(\\mathbf{c}_i = [\\mathbf{c}_{\\text{num}}; \\mathbf{c}_{\\text{lang}}; \\mathbf{c}_{\\text{cat}}; \\mathbf{c}_{\\text{text}}] \\in \\mathbb{R}^{796}\\) provides rich content representation that enables both content-based similarity and collaborative filtering within the same mathematical framework.</p> <p>The item tower applies the same multi-layer architecture as the user tower, producing normalized embeddings \\(\\mathbf{e}_i\\) that live in the same \\(d\\)-dimensional space as user embeddings.</p>"},{"location":"machine-learning/two_tower/#training-objective-and-loss-function","title":"Training Objective and Loss Function","text":""},{"location":"machine-learning/two_tower/#contrastive-learning-framework","title":"Contrastive Learning Framework","text":"<p>The training process uses contrastive learning to teach the model to distinguish between positive and negative user-item interactions. Our Netflix thumbs rating system provides clear signals: - Thumbs down: \\(r_{ui} = -1.0\\) (explicit negative) - Thumbs up: \\(r_{ui} = 1.0\\) (positive) - Two thumbs up: \\(r_{ui} = 2.0\\) (strong positive)</p> <p>For each training example, we sample positive pairs \\((u, i^+)\\) where \\(r_{ui^+} \\geq 1.0\\) and negative pairs \\((u, i^-)\\) where \\(r_{ui^-} = -1.0\\) or through implicit negative sampling.</p>"},{"location":"machine-learning/two_tower/#ranking-loss-function","title":"Ranking Loss Function","text":"<p>The model learns through a ranking loss that encourages positive interactions to receive higher scores than negative interactions:</p> \\[\\mathcal{L} = \\frac{1}{|\\mathcal{B}|} \\sum_{(u, i^+, i^-) \\in \\mathcal{B}} \\max(0, \\gamma - (\\mathbf{e}_u^T \\mathbf{e}_{i^+} - \\mathbf{e}_u^T \\mathbf{e}_{i^-}))\\] <p>where \\(\\mathcal{B}\\) represents a training batch, \\(\\gamma &gt; 0\\) is a margin parameter, and \\((u, i^+, i^-)\\) are triplets consisting of a user, positive item, and negative item.</p> <p>This ranking loss implements the mathematical principle that drives collaborative filtering: users should have higher compatibility scores with items they prefer than with items they avoid. The margin \\(\\gamma\\) enforces a minimum separation between positive and negative scores, ensuring that the learned embeddings create clear preference boundaries.</p>"},{"location":"machine-learning/two_tower/#alternative-binary-cross-entropy-loss","title":"Alternative: Binary Cross-Entropy Loss","text":"<p>For scenarios with explicit ratings, we can formulate the problem as binary classification:</p> \\[\\mathcal{L}_{\\text{BCE}} = -\\frac{1}{|\\mathcal{B}|} \\sum_{(u,i,y) \\in \\mathcal{B}} [y \\log(\\sigma(\\mathbf{e}_u^T \\mathbf{e}_i)) + (1-y) \\log(1-\\sigma(\\mathbf{e}_u^T \\mathbf{e}_i))]\\] <p>where \\(\\sigma(\\cdot)\\) is the sigmoid function and \\(y \\in \\{0, 1\\}\\) indicates positive or negative interaction. This formulation provides probabilistic interpretation of compatibility scores and often exhibits stable training characteristics.</p>"},{"location":"machine-learning/two_tower/#implementation-architecture","title":"Implementation Architecture","text":""},{"location":"machine-learning/two_tower/#twotowermodel-class-structure","title":"TwoTowerModel Class Structure","text":"<p>Our implementation encapsulates the complete architecture in a PyTorch module that coordinates the user and item towers:</p> <pre><code>class TwoTowerModel(nn.Module):\n    def __init__(self, num_users: int, num_movies: int, content_feature_dim: int, \n                 embedding_dim: int = 128):\n        \"\"\"\n        Initialize the two-tower architecture with specified dimensions.\n\n        The content_feature_dim parameter reflects our Stage 4 feature engineering:\n        - 7 numerical features from TMDB metadata\n        - 16 language one-hot features  \n        - 5 categorical boolean features\n        - 768 text embedding features from EmbeddingGemma\n        Total: 796 content features per movie\n        \"\"\"\n        super(TwoTowerModel, self).__init__()\n\n        # User tower: processes user IDs into preference embeddings\n        self.user_tower = UserTower(\n            num_users=num_users,\n            output_dim=embedding_dim\n        )\n\n        # Item tower: processes movie content features into content embeddings\n        self.item_tower = ItemTower(\n            num_movies=num_movies,\n            content_feature_dim=content_feature_dim,  # 796 in our case\n            output_dim=embedding_dim\n        )\n\n    def forward(self, user_ids: torch.Tensor, movie_ids: torch.Tensor, \n                movie_features: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Compute compatibility scores between users and movies.\n\n        Mathematical operation: \u0155_ui = e_u^T * e_i\n        where both embeddings are L2-normalized for cosine similarity.\n        \"\"\"\n        # Generate normalized embeddings: ||e_u||_2 = 1, ||e_i||_2 = 1\n        user_embeddings = self.user_tower(user_ids)\n        movie_embeddings = self.item_tower(movie_ids, movie_features)\n\n        # Compute cosine similarity: e_u^T * e_i \u2208 [-1, 1]\n        scores = torch.sum(user_embeddings * movie_embeddings, dim=1)\n\n        return scores\n</code></pre> <p>The forward pass implements the core mathematical operation \\(\\hat{r}_{ui} = \\mathbf{e}_u^T \\mathbf{e}_i\\) that transforms the user-item compatibility problem into geometric similarity calculations in the learned embedding space.</p>"},{"location":"machine-learning/two_tower/#data-processing-pipeline","title":"Data Processing Pipeline","text":""},{"location":"machine-learning/two_tower/#feature-preparation","title":"Feature Preparation","text":"<p>The data loader transforms our processed parquet files into tensor format suitable for neural network training. The movie content features undergo careful preprocessing to handle the multi-modal nature of our feature set:</p> <pre><code>def _prepare_movie_features(self):\n    \"\"\"\n    Convert Stage 4 content features into tensor format.\n\n    Feature concatenation order:\n    1. Numerical features (7 dimensions): budget, revenue, runtime, etc.\n    2. Language features (16 dimensions): one-hot encoded language preferences  \n    3. Categorical features (5 dimensions): boolean indicators\n    4. Text embeddings (768 dimensions): EmbeddingGemma semantic representations\n\n    Total dimensionality: 7 + 16 + 5 + 768 = 796\n    \"\"\"\n    # Extract and concatenate all feature types\n    numerical_features = self.movies_df[numerical_cols].fillna(0).values\n    language_features = self.movies_df[lang_cols].fillna(0).values  \n    categorical_features = self.movies_df[categorical_cols].fillna(0).values\n\n    # Handle text embeddings with fallback for missing values\n    text_embeddings = np.stack([\n        emb if emb is not None else np.zeros(768) \n        for emb in self.movies_df['text_embedding'].values\n    ])\n\n    # Concatenate to create unified content representation\n    self.movie_features = np.concatenate([\n        numerical_features, language_features, \n        categorical_features, text_embeddings\n    ], axis=1)\n\n    self.movie_features = torch.FloatTensor(self.movie_features)\n</code></pre> <p>This preprocessing strategy preserves the semantic richness developed during our Stage 4 feature engineering while creating the numerical representations required for neural network training.</p>"},{"location":"machine-learning/two_tower/#training-example-generation","title":"Training Example Generation","text":"<p>The training data preparation process leverages the clear positive and negative signals in our Netflix thumbs rating system:</p> <pre><code>def _create_training_examples(self):\n    \"\"\"\n    Generate contrastive learning examples from thumbs ratings.\n\n    Positive examples: r_ui \u2208 {1.0, 2.0} (thumbs up, two thumbs up)\n    Negative examples: r_ui = -1.0 (thumbs down) + implicit negatives\n\n    The clear semantics eliminate ambiguity in determining preference labels.\n    \"\"\"\n    # Explicit positive examples with preference strength\n    positive_ratings = self.sequences_df[self.sequences_df['thumbs_rating'] &gt;= 1.0]\n    positive_examples = [\n        {'user_idx': self.user_to_idx[row['userId']], \n         'movie_idx': self.movie_to_idx[row['movieId']], \n         'rating': row['thumbs_rating']}\n        for _, row in positive_ratings.iterrows()\n    ]\n\n    # Explicit negative examples  \n    negative_ratings = self.sequences_df[self.sequences_df['thumbs_rating'] == -1.0]\n    negative_examples = [\n        {'user_idx': self.user_to_idx[row['userId']], \n         'movie_idx': self.movie_to_idx[row['movieId']], \n         'rating': -1.0}\n        for _, row in negative_ratings.iterrows()\n    ]\n\n    # Implicit negative sampling for balance\n    if len(negative_examples) &lt; len(positive_examples) * 0.3:\n        self._generate_implicit_negatives(positive_examples, negative_examples)\n</code></pre> <p>The Netflix thumbs rating system eliminates the threshold ambiguity that complicates traditional rating systems, providing clear training signals that improve model learning effectiveness.</p>"},{"location":"machine-learning/two_tower/#mathematical-properties-and-theoretical-foundations","title":"Mathematical Properties and Theoretical Foundations","text":""},{"location":"machine-learning/two_tower/#embedding-space-geometry","title":"Embedding Space Geometry","text":"<p>The learned embedding space exhibits geometric properties that reflect user preference patterns. Users with similar tastes cluster in regions of the embedding space, while items that appeal to similar user segments occupy nearby positions. The mathematical relationship between embedding similarity and preference compatibility enables collaborative filtering through geometric reasoning.</p> <p>The normalization constraint \\(\\|\\mathbf{e}_u\\|_2 = \\|\\mathbf{e}_i\\|_2 = 1\\) creates embeddings on the unit hypersphere \\(\\mathbb{S}^{d-1}\\). This geometric structure provides several theoretical advantages:</p> <ol> <li>Bounded similarity scores: \\(\\mathbf{e}_u^T \\mathbf{e}_i \\in [-1, 1]\\) provides interpretable compatibility measures</li> <li>Angular interpretation: The embedding angle \\(\\theta_{ui} = \\arccos(\\mathbf{e}_u^T \\mathbf{e}_i)\\) represents preference distance</li> <li>Stable optimization: The constrained parameter space reduces optimization instability</li> </ol>"},{"location":"machine-learning/two_tower/#collaborative-filtering-through-matrix-factorization","title":"Collaborative Filtering Through Matrix Factorization","text":"<p>The two-tower architecture generalizes traditional matrix factorization approaches. Consider the user-item interaction matrix \\(\\mathbf{R} \\in \\mathbb{R}^{|U| \\times |I|}\\). Matrix factorization seeks low-rank decomposition:</p> \\[\\mathbf{R} \\approx \\mathbf{U}\\mathbf{V}^T\\] <p>where \\(\\mathbf{U} \\in \\mathbb{R}^{|U| \\times d}\\) contains user factors and \\(\\mathbf{V} \\in \\mathbb{R}^{|I| \\times d}\\) contains item factors.</p> <p>The two-tower model extends this framework by learning non-linear transformations:</p> \\[\\mathbf{U} = f_{\\text{user}}(\\mathbf{X}_{\\text{user}}; \\Theta_u)$$ $$\\mathbf{V} = f_{\\text{item}}(\\mathbf{X}_{\\text{item}}; \\Theta_i)\\] <p>where \\(\\mathbf{X}_{\\text{user}}\\) and \\(\\mathbf{X}_{\\text{item}}\\) represent user and item features respectively. This generalization enables the incorporation of rich side information while maintaining the computational benefits of factorized representations.</p>"},{"location":"machine-learning/two_tower/#content-collaborative-hybridization","title":"Content-Collaborative Hybridization","text":"<p>Our implementation achieves hybridization between collaborative filtering and content-based recommendation through the item tower architecture. The mathematical formulation:</p> \\[\\mathbf{e}_i = f_{\\text{item}}([\\mathbf{w}_i; \\mathbf{c}_i]; \\Theta_i)\\] <p>combines learned item embeddings \\(\\mathbf{w}_i\\) with explicit content features \\(\\mathbf{c}_i\\). This approach enables the model to leverage both collaborative signals from user interaction patterns and content signals from item characteristics.</p> <p>The hybrid approach addresses key limitations of pure collaborative filtering approaches: - Cold start problem: New items can receive recommendations based on content similarity - Sparsity handling: Content features provide signals for items with few interactions - Explainability: Content features enable interpretation of recommendation rationales</p>"},{"location":"machine-learning/two_tower/#computational-complexity-and-scalability-analysis","title":"Computational Complexity and Scalability Analysis","text":""},{"location":"machine-learning/two_tower/#training-complexity","title":"Training Complexity","text":"<p>The training process exhibits computational complexity that scales with the dataset size and model architecture. For a training batch of size \\(B\\) containing user-item pairs:</p> <ul> <li>Forward pass: \\(O(B \\cdot d \\cdot H)\\) where \\(H\\) represents the total number of hidden units</li> <li>Backward pass: \\(O(B \\cdot d \\cdot H)\\) for gradient computation</li> <li>Parameter updates: \\(O(|\\Theta|)\\) where \\(|\\Theta|\\) is the total parameter count</li> </ul> <p>The per-epoch complexity scales as \\(O(N \\cdot d \\cdot H)\\) where \\(N\\) represents the number of training examples. This linear scaling enables training on large datasets with appropriate computational resources.</p>"},{"location":"machine-learning/two_tower/#inference-complexity","title":"Inference Complexity","text":"<p>The two-tower architecture provides crucial advantages during inference:</p> <ol> <li>Item embedding pre-computation: \\(O(|I| \\cdot d \\cdot H_{\\text{item}})\\) one-time cost</li> <li>User embedding computation: \\(O(d \\cdot H_{\\text{user}})\\) per recommendation request</li> <li>Similarity calculation: \\(O(|I| \\cdot d)\\) dot products against cached embeddings</li> </ol> <p>The total inference complexity becomes \\(O(d \\cdot H_{\\text{user}} + |I| \\cdot d)\\), which scales linearly with catalog size rather than quadratically as in naive approaches.</p>"},{"location":"machine-learning/two_tower/#memory-requirements","title":"Memory Requirements","text":"<p>The memory footprint includes several components:</p> <ul> <li>User embeddings: \\(O(|U| \\cdot d)\\) parameters</li> <li>Item embeddings: \\(O(|I| \\cdot d)\\) parameters  </li> <li>Network weights: \\(O(H^2)\\) for fully connected layers</li> <li>Cached item embeddings: \\(O(|I| \\cdot d)\\) for inference serving</li> </ul> <p>For our implementation with \\(|U| = 75,000\\), \\(|I| = 80,000\\), and \\(d = 128\\), the embedding parameters require approximately 25MB of memory, demonstrating the efficiency of the factorized representation.</p>"},{"location":"machine-learning/two_tower/#integration-with-existing-pipeline-architecture","title":"Integration with Existing Pipeline Architecture","text":""},{"location":"machine-learning/two_tower/#dvc-pipeline-extension","title":"DVC Pipeline Extension","text":"<p>The two-tower model integrates seamlessly with our existing DVC pipeline by consuming the processed datasets from Stage 4 and producing trained model artifacts for subsequent stages:</p> <pre><code>stages:\n  # Existing stages\n  content_features:\n    cmd: python scripts/extract_tmdb_features.py\n    outs:\n      - data/processed/movies_with_content_features.parquet\n\n  # New two-tower training stage\n  two_tower_training:\n    cmd: python scripts/train_two_tower.py\n    deps:\n      - data/processed/sequences_with_metadata.parquet\n      - data/processed/movies_with_content_features.parquet\n      - configs/two_tower_config.yaml\n    outs:\n      - models/two_tower_model.pth\n      - data/processed/movie_embeddings.parquet\n    metrics:\n      - metrics/two_tower_metrics.json\n</code></pre> <p>This pipeline structure maintains reproducibility while enabling iterative model development and hyperparameter experimentation.</p>"},{"location":"machine-learning/two_tower/#feature-engineering-integration","title":"Feature Engineering Integration","text":"<p>The two-tower model leverages the comprehensive feature engineering developed during Stage 4, demonstrating how careful data preparation pays dividends during model training. The rich content features enable the model to learn sophisticated item representations that combine explicit content characteristics with latent collaborative filtering factors.</p> <p>The integration strategy preserves the semantic richness of our multi-modal feature set: - TMDB numerical features provide explicit content characteristics - Language features capture cultural and linguistic preferences - Text embeddings from EmbeddingGemma contribute semantic understanding - Categorical features indicate production characteristics</p> <p>This feature diversity enables the model to capture multiple dimensions of user preference that pure collaborative filtering approaches might miss.</p>"},{"location":"machine-learning/two_tower/#evaluation-framework-and-success-metrics","title":"Evaluation Framework and Success Metrics","text":""},{"location":"machine-learning/two_tower/#retrieval-quality-metrics","title":"Retrieval Quality Metrics","text":"<p>The two-tower model serves as the first stage in a multi-stage recommendation pipeline, making retrieval quality the primary evaluation focus. Key metrics include:</p> <p>Recall at K: Measures the proportion of relevant items included in the top-K retrieved candidates:</p> \\[\\text{Recall@K} = \\frac{|\\{i \\in \\text{Top-K}(u) : r_{ui} \\geq \\tau\\}|}{|\\{i : r_{ui} \\geq \\tau\\}|}\\] <p>where \\(\\tau\\) represents the relevance threshold (e.g., \\(\\tau = 1.0\\) for thumbs up ratings).</p> <p>Coverage: Evaluates the diversity of retrieved candidates across the item catalog:</p> \\[\\text{Coverage} = \\frac{|\\bigcup_{u} \\text{Top-K}(u)|}{|I|}\\] <p>Higher coverage indicates that the model can recommend diverse content rather than focusing on popular items.</p>"},{"location":"machine-learning/two_tower/#computational-performance-metrics","title":"Computational Performance Metrics","text":"<p>Production deployment requires monitoring computational characteristics:</p> <ul> <li>Embedding generation latency: Time to compute user embeddings</li> <li>Similarity calculation throughput: Candidates evaluated per second  </li> <li>Memory utilization: RAM requirements for cached embeddings</li> <li>Model loading time: Initialization cost for serving systems</li> </ul> <p>These metrics ensure that the model meets the sub-200ms latency requirements for interactive recommendation serving.</p>"},{"location":"machine-learning/two_tower/#production-deployment-considerations","title":"Production Deployment Considerations","text":""},{"location":"machine-learning/two_tower/#embedding-caching-strategy","title":"Embedding Caching Strategy","text":"<p>The production architecture requires careful design of the embedding caching system to achieve target latency requirements. Movie embeddings can be pre-computed and stored in fast key-value stores, while user embeddings might be computed on demand or cached with appropriate expiration policies.</p>"},{"location":"machine-learning/two_tower/#model-update-pipeline","title":"Model Update Pipeline","text":"<p>The two-tower model enables flexible update strategies: - Full retraining: Periodic complete model updates using accumulated interaction data - Incremental updates: Online learning approaches for user embedding adaptation - A/B testing: Gradual rollout of model improvements with performance monitoring</p>"},{"location":"machine-learning/two_tower/#scalability-architecture","title":"Scalability Architecture","text":"<p>The two-tower design naturally supports horizontal scaling through distributed serving architectures. User embedding computation can be distributed across multiple workers, while cached item embeddings can be replicated across serving nodes for redundancy and load distribution.</p>"},{"location":"machine-learning/two_tower/#conclusion-and-future-directions","title":"Conclusion and Future Directions","text":"<p>The two-tower model provides a mathematically principled and computationally efficient foundation for scalable recommendation systems. Our implementation successfully integrates collaborative filtering principles with rich content features through neural network architectures that learn meaningful embedding representations of users and movies.</p> <p>The mathematical framework underlying the two-tower approach demonstrates how geometric reasoning in learned embedding spaces can encode complex preference patterns while maintaining the computational efficiency required for real-time serving. The clear semantics of our Netflix thumbs rating system eliminate many of the ambiguities that complicate traditional recommendation system development.</p> <p>Future enhancements might explore advanced architectures such as attention mechanisms for dynamic user preference modeling, multi-task learning objectives that optimize for multiple recommendation quality metrics simultaneously, or federated learning approaches that enable personalization while preserving user privacy.</p> <p>The solid foundation provided by this two-tower implementation positions the Movie Genie system for sophisticated extensions including sequential recommendation modeling, graph-based relationship reasoning, and natural language query understanding through the RAG system we have planned for later development stages.</p>"},{"location":"reference/project-structure/","title":"\ud83d\udcc1 Project Structure","text":"<p>Complete guide to Movie Genie's file organization, directory structure, and code architecture.</p>"},{"location":"reference/project-structure/#project-overview","title":"\ud83c\udfaf Project Overview","text":"<p>Movie Genie follows a modular, scalable structure that separates concerns while maintaining clear relationships between components.</p> <pre><code>movie-genie/\n\u251c\u2500\u2500 \ud83d\udcca Data &amp; Models\n\u251c\u2500\u2500 \ud83c\udfd7\ufe0f Application Code\n\u251c\u2500\u2500 \u2699\ufe0f Configuration\n\u251c\u2500\u2500 \ud83d\udcda Documentation\n\u251c\u2500\u2500 \ud83e\uddea Tests\n\u2514\u2500\u2500 \ud83d\ude80 Deployment\n</code></pre>"},{"location":"reference/project-structure/#complete-directory-structure","title":"\ud83d\udcc2 Complete Directory Structure","text":"<pre><code>movie-genie/\n\u251c\u2500\u2500 configs/                          # \u2699\ufe0f Configuration files\n\u2502   \u251c\u2500\u2500 bert4rec_config.yaml          # BERT4Rec model configuration\n\u2502   \u251c\u2500\u2500 two_tower_config.yaml         # Two-Tower model configuration\n\u2502   \u251c\u2500\u2500 semantic_search.yaml          # Semantic search configuration\n\u2502   \u2514\u2500\u2500 evaluation_config.yaml        # Model evaluation configuration\n\u2502\n\u251c\u2500\u2500 data/                             # \ud83d\udcca Data storage\n\u2502   \u251c\u2500\u2500 raw/                          # Raw input data\n\u2502   \u2502   \u2514\u2500\u2500 ml-100k/                  # MovieLens 100K dataset\n\u2502   \u2502       \u251c\u2500\u2500 u.data                # User ratings\n\u2502   \u2502       \u251c\u2500\u2500 u.item                # Movie information\n\u2502   \u2502       \u251c\u2500\u2500 u.user                # User demographics\n\u2502   \u2502       \u2514\u2500\u2500 u.genre               # Genre definitions\n\u2502   \u2514\u2500\u2500 processed/                    # Processed data files\n\u2502       \u251c\u2500\u2500 movies.parquet            # Clean movie data\n\u2502       \u251c\u2500\u2500 ratings.parquet           # Clean rating data\n\u2502       \u251c\u2500\u2500 users.parquet             # User demographics\n\u2502       \u251c\u2500\u2500 content_features.parquet  # Movie content features\n\u2502       \u2514\u2500\u2500 sequences_with_metadata.parquet # User sequences\n\u2502\n\u251c\u2500\u2500 docs/                             # \ud83d\udcda Documentation\n\u2502   \u251c\u2500\u2500 README.md                     # Main documentation hub\n\u2502   \u251c\u2500\u2500 getting-started/              # Getting started guides\n\u2502   \u2502   \u251c\u2500\u2500 README.md                 # Learning path overview\n\u2502   \u2502   \u251c\u2500\u2500 quick-start.md            # 5-minute setup guide\n\u2502   \u2502   \u251c\u2500\u2500 installation.md           # Detailed installation\n\u2502   \u2502   \u251c\u2500\u2500 project-overview.md       # Architecture overview\n\u2502   \u2502   \u2514\u2500\u2500 commands-reference.md     # Complete command reference\n\u2502   \u251c\u2500\u2500 machine-learning/             # ML documentation\n\u2502   \u2502   \u251c\u2500\u2500 README.md                 # ML models overview\n\u2502   \u2502   \u251c\u2500\u2500 bert4rec.md               # Sequential recommendation\n\u2502   \u2502   \u251c\u2500\u2500 two-tower.md              # Collaborative filtering\n\u2502   \u2502   \u251c\u2500\u2500 semantic-search.md        # Content-based search\n\u2502   \u2502   \u2514\u2500\u2500 evaluation.md             # Performance evaluation\n\u2502   \u251c\u2500\u2500 data-pipeline/                # Data processing docs\n\u2502   \u2502   \u251c\u2500\u2500 README.md                 # Pipeline overview\n\u2502   \u2502   \u251c\u2500\u2500 dvc-workflows.md          # DVC pipeline management\n\u2502   \u2502   \u251c\u2500\u2500 data-processing.md        # Data transformation\n\u2502   \u2502   \u2514\u2500\u2500 feature-engineering.md    # Feature creation\n\u2502   \u251c\u2500\u2500 backend-frontend/             # Full-stack architecture\n\u2502   \u2502   \u251c\u2500\u2500 README.md                 # Architecture overview\n\u2502   \u2502   \u251c\u2500\u2500 backend-integration.md    # Flask backend guide\n\u2502   \u2502   \u251c\u2500\u2500 ml-integration.md         # ML to frontend guide\n\u2502   \u2502   \u251c\u2500\u2500 api-reference.md          # Complete API docs\n\u2502   \u2502   \u2514\u2500\u2500 frontend-components.md    # React components\n\u2502   \u251c\u2500\u2500 deployment/                   # Deployment guides\n\u2502   \u251c\u2500\u2500 configuration/                # Configuration docs\n\u2502   \u251c\u2500\u2500 troubleshooting/              # Problem solving\n\u2502   \u2502   \u2514\u2500\u2500 README.md                 # Common issues guide\n\u2502   \u2514\u2500\u2500 reference/                    # Technical reference\n\u2502       \u251c\u2500\u2500 technology-stack.md       # All technologies used\n\u2502       \u251c\u2500\u2500 project-structure.md      # This file\n\u2502       \u251c\u2500\u2500 coding-standards.md       # Best practices\n\u2502       \u2514\u2500\u2500 changelog.md              # Project evolution\n\u2502\n\u251c\u2500\u2500 metrics/                          # \ud83d\udcc8 Model performance metrics\n\u2502   \u251c\u2500\u2500 bert4rec_metrics.json         # BERT4Rec evaluation results\n\u2502   \u251c\u2500\u2500 two_tower_metrics.json        # Two-Tower evaluation results\n\u2502   \u2514\u2500\u2500 comparison_report.json        # Model comparison\n\u2502\n\u251c\u2500\u2500 models/                           # \ud83e\udde0 Trained ML models\n\u2502   \u251c\u2500\u2500 bert4rec/                     # BERT4Rec model artifacts\n\u2502   \u2502   \u251c\u2500\u2500 bert4rec_model.pth        # Trained model weights\n\u2502   \u2502   \u251c\u2500\u2500 config.json               # Model configuration\n\u2502   \u2502   \u251c\u2500\u2500 tokenizer/                # Text tokenizer\n\u2502   \u2502   \u2514\u2500\u2500 training_log.json         # Training history\n\u2502   \u251c\u2500\u2500 two_tower/                    # Two-Tower model artifacts\n\u2502   \u2502   \u251c\u2500\u2500 user_encoder.pth          # User embedding model\n\u2502   \u2502   \u251c\u2500\u2500 item_encoder.pth          # Item embedding model\n\u2502   \u2502   \u251c\u2500\u2500 config.json               # Model configuration\n\u2502   \u2502   \u2514\u2500\u2500 embeddings/               # Pre-computed embeddings\n\u2502   \u2514\u2500\u2500 semantic_search/              # Semantic search models\n\u2502       \u251c\u2500\u2500 sentence_transformer/     # Pre-trained encoder\n\u2502       \u251c\u2500\u2500 movie_embeddings.npy      # Movie text embeddings\n\u2502       \u2514\u2500\u2500 index.faiss               # Fast similarity search index\n\u2502\n\u251c\u2500\u2500 movie_genie/                      # \ud83c\udfd7\ufe0f Main application code\n\u2502   \u251c\u2500\u2500 __init__.py                   # Package initialization\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 backend/                      # \ud83d\udd27 Flask backend application\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 app.py                    # Main Flask application\n\u2502   \u2502   \u251c\u2500\u2500 config.py                 # Backend configuration\n\u2502   \u2502   \u251c\u2500\u2500 movie_genie.db            # SQLite database\n\u2502   \u2502   \u251c\u2500\u2500 app/                      # Application modules\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 api/                  # API route handlers\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 movies.py         # Movie endpoints\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 search.py         # Search endpoints\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 recommendations.py # Recommendation endpoints\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 users.py          # User endpoints\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 services/             # Business logic layer\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 movie_service.py  # Movie data operations\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 search_service.py # Search functionality\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 recommendation_service.py # ML recommendations\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 user_service.py   # User operations\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 models/               # Database models\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 movie.py          # Movie data model\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 rating.py         # Rating data model\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 user.py           # User data model\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 utils/                # Utility functions\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 ml_loader.py      # ML model loading\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 validators.py     # Input validation\n\u2502   \u2502   \u251c\u2500\u2500 templates/                # Static files served by Flask\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 index.html            # React app entry point\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 favicon.ico           # Site icon\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 robots.txt            # Search engine instructions\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 placeholder.svg       # Placeholder image\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 assets/               # Built frontend assets\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 index-*.js        # Bundled JavaScript\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 index-*.css       # Bundled CSS\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 *.svg             # Optimized SVG assets\n\u2502   \u2502   \u251c\u2500\u2500 tests/                    # Backend tests\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_api.py           # API endpoint tests\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_services.py      # Service layer tests\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test_models.py        # Database model tests\n\u2502   \u2502   \u2514\u2500\u2500 logs/                     # Application logs\n\u2502   \u2502       \u251c\u2500\u2500 app.log               # Main application log\n\u2502   \u2502       \u2514\u2500\u2500 error.log             # Error-specific log\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 frontend/                     # \ud83c\udfa8 React frontend application\n\u2502   \u2502   \u251c\u2500\u2500 public/                   # Static assets\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 favicon.ico           # Site icon\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 placeholder.svg       # Default movie poster\n\u2502   \u2502   \u251c\u2500\u2500 src/                      # Source code\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 components/           # React components\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 UserSelectionModal.tsx # User ID selection\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 MovieSearch.tsx   # Search interface\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 SearchResultsGrid.tsx # Search results display\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 MovieThumbnail.tsx # Movie card component\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 RecommendationCarousel.tsx # Recommendations\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 MovieDetailsPanel.tsx # Movie details view\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 services/             # Data access layer\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 movieDataService.ts # Movie data operations\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 api.ts            # API client utilities\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 lib/                  # Shared utilities\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 api.ts            # API configuration\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 mockData.ts       # Mock data for development\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 types/                # TypeScript type definitions\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 movie.ts          # Movie-related types\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 styles/               # Global styles\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 index.css         # Main stylesheet\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 App.tsx               # Main application component\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 main.tsx              # Application entry point\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 vite-env.d.ts         # Vite type definitions\n\u2502   \u2502   \u251c\u2500\u2500 dist/                     # Built application (production)\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 index.html            # Built HTML\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 assets/               # Optimized assets\n\u2502   \u2502   \u251c\u2500\u2500 node_modules/             # Node.js dependencies\n\u2502   \u2502   \u251c\u2500\u2500 package.json              # Frontend dependencies\n\u2502   \u2502   \u251c\u2500\u2500 package-lock.json         # Dependency lock file\n\u2502   \u2502   \u251c\u2500\u2500 vite.config.ts            # Vite build configuration\n\u2502   \u2502   \u251c\u2500\u2500 tailwind.config.js        # Tailwind CSS configuration\n\u2502   \u2502   \u251c\u2500\u2500 tsconfig.json             # TypeScript configuration\n\u2502   \u2502   \u251c\u2500\u2500 tsconfig.node.json        # Node-specific TypeScript config\n\u2502   \u2502   \u251c\u2500\u2500 postcss.config.js         # PostCSS configuration\n\u2502   \u2502   \u251c\u2500\u2500 .env.development          # Development environment vars\n\u2502   \u2502   \u2514\u2500\u2500 .env.production           # Production environment vars\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 data/                         # \ud83d\udd04 Data processing modules\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 content_features.py       # Movie content feature extraction\n\u2502   \u2502   \u251c\u2500\u2500 sequential_processing.py  # User sequence generation\n\u2502   \u2502   \u2514\u2500\u2500 data_validation.py        # Data quality checks\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 ranking/                      # \ud83c\udfaf Sequential recommendation models\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 bert4rec_model.py         # BERT4Rec implementation\n\u2502   \u2502   \u251c\u2500\u2500 train_bert4rec.py         # BERT4Rec training script\n\u2502   \u2502   \u2514\u2500\u2500 utils.py                  # Ranking utilities\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 retrieval/                    # \ud83d\udd0d Collaborative filtering models\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 two_tower_model.py        # Two-Tower implementation\n\u2502   \u2502   \u251c\u2500\u2500 train_two_tower.py        # Two-Tower training script\n\u2502   \u2502   \u2514\u2500\u2500 embeddings.py             # Embedding utilities\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 search/                       # \ud83d\udd0e Semantic search modules\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 semantic_engine.py        # Semantic search engine\n\u2502   \u2502   \u251c\u2500\u2500 setup_semantic_search.py  # Search setup script\n\u2502   \u2502   \u2514\u2500\u2500 text_processing.py        # Text preprocessing\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 evaluation/                   # \ud83d\udcca Model evaluation modules\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 integrated_evaluation.py  # Cross-model evaluation\n\u2502       \u251c\u2500\u2500 metrics.py                # Evaluation metrics\n\u2502       \u2514\u2500\u2500 benchmark.py              # Performance benchmarking\n\u2502\n\u251c\u2500\u2500 results/                          # \ud83d\udcc8 Evaluation and experiment results\n\u2502   \u251c\u2500\u2500 model_comparison.json         # Model performance comparison\n\u2502   \u251c\u2500\u2500 ablation_studies/             # Feature importance studies\n\u2502   \u2514\u2500\u2500 experiment_logs/              # Detailed experiment logs\n\u2502\n\u251c\u2500\u2500 scripts/                          # \ud83d\udee0\ufe0f Utility and setup scripts\n\u2502   \u251c\u2500\u2500 setup_database.py             # Database initialization\n\u2502   \u251c\u2500\u2500 process_movielens.py          # MovieLens data processing\n\u2502   \u251c\u2500\u2500 imdb_featured_reviews.py      # IMDB review scraping\n\u2502   \u251c\u2500\u2500 generate_evaluation_report.py # Evaluation report generation\n\u2502   \u251c\u2500\u2500 test_full_pipeline.py         # End-to-end testing\n\u2502   \u2514\u2500\u2500 backup.sh                     # System backup script\n\u2502\n\u251c\u2500\u2500 tests/                            # \ud83e\uddea Project-wide tests\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 test_ml_integration.py        # ML model integration tests\n\u2502   \u251c\u2500\u2500 test_api_integration.py       # API integration tests\n\u2502   \u251c\u2500\u2500 test_data_pipeline.py         # Data pipeline tests\n\u2502   \u2514\u2500\u2500 fixtures/                     # Test data fixtures\n\u2502       \u251c\u2500\u2500 sample_movies.json        # Sample movie data\n\u2502       \u2514\u2500\u2500 sample_ratings.json       # Sample rating data\n\u2502\n\u251c\u2500\u2500 .dvc/                             # \ud83d\udd04 DVC configuration and cache\n\u2502   \u251c\u2500\u2500 config                        # DVC configuration\n\u2502   \u251c\u2500\u2500 cache/                        # DVC data cache\n\u2502   \u2514\u2500\u2500 .gitignore                    # DVC gitignore rules\n\u2502\n\u251c\u2500\u2500 .venv/                            # \ud83d\udc0d Python virtual environment\n\u2502   \u251c\u2500\u2500 bin/                          # Virtual environment binaries\n\u2502   \u251c\u2500\u2500 lib/                          # Python packages\n\u2502   \u2514\u2500\u2500 pyvenv.cfg                    # Virtual environment config\n\u2502\n\u251c\u2500\u2500 dvc.yaml                          # \ud83d\udccb DVC pipeline definition\n\u251c\u2500\u2500 dvc.lock                          # \ud83d\udd12 DVC pipeline lock file\n\u251c\u2500\u2500 params.yaml                       # \u2699\ufe0f Pipeline parameters\n\u251c\u2500\u2500 .dvcignore                        # DVC ignore rules\n\u251c\u2500\u2500 .gitignore                        # Git ignore rules\n\u251c\u2500\u2500 pyproject.toml                    # Python project configuration\n\u251c\u2500\u2500 requirements.txt                  # Python dependencies\n\u251c\u2500\u2500 README.md                         # Project overview\n\u251c\u2500\u2500 LICENSE                           # License information\n\u2514\u2500\u2500 Dockerfile                        # Docker container definition\n</code></pre>"},{"location":"reference/project-structure/#architecture-principles","title":"\ud83c\udfd7\ufe0f Architecture Principles","text":""},{"location":"reference/project-structure/#1-separation-of-concerns","title":"1. Separation of Concerns","text":"<p>Each directory has a clear, single responsibility: - <code>movie_genie/backend/</code>: HTTP API and business logic - <code>movie_genie/frontend/</code>: User interface and interactions - <code>movie_genie/ranking/</code>: Sequential recommendation models - <code>movie_genie/retrieval/</code>: Collaborative filtering models - <code>movie_genie/search/</code>: Content-based search</p>"},{"location":"reference/project-structure/#2-modular-design","title":"2. Modular Design","text":"<p>Components are loosely coupled and highly cohesive: - Service Layer: Business logic separated from API routes - Component Architecture: Reusable React components - Model Interfaces: Standardized ML model interfaces</p>"},{"location":"reference/project-structure/#3-configuration-management","title":"3. Configuration Management","text":"<p>All configuration is externalized: - <code>configs/</code>: Model hyperparameters and settings - <code>params.yaml</code>: Pipeline parameters - <code>.env</code> files: Environment-specific variables</p>"},{"location":"reference/project-structure/#4-data-flow-clarity","title":"4. Data Flow Clarity","text":"<p>Clear data flow from raw to production: <pre><code>data/raw/ \u2192 data/processed/ \u2192 models/ \u2192 movie_genie/backend/\n</code></pre></p>"},{"location":"reference/project-structure/#key-file-purposes","title":"\ud83d\udcca Key File Purposes","text":""},{"location":"reference/project-structure/#configuration-files","title":"Configuration Files","text":""},{"location":"reference/project-structure/#dvcyaml-pipeline-definition","title":"<code>dvc.yaml</code> - Pipeline Definition","text":"<pre><code># Defines the complete ML pipeline\nstages:\n  data_processing:\n    cmd: python scripts/process_movielens.py\n    deps: [data/raw/ml-100k/]\n    outs: [data/processed/]\n\n  train_bert4rec:\n    cmd: python movie_genie/ranking/train_bert4rec.py\n    deps: [data/processed/sequences_with_metadata.parquet]\n    outs: [models/bert4rec/]\n</code></pre>"},{"location":"reference/project-structure/#paramsyaml-global-parameters","title":"<code>params.yaml</code> - Global Parameters","text":"<pre><code># Shared parameters across all pipeline stages\ndata_processing:\n  min_ratings_per_user: 20\n  test_split_ratio: 0.2\n\nbert4rec:\n  hidden_size: 128\n  num_layers: 4\n  learning_rate: 0.001\n</code></pre>"},{"location":"reference/project-structure/#pyprojecttoml-python-project-config","title":"<code>pyproject.toml</code> - Python Project Config","text":"<pre><code># Python package configuration and dependencies\n[build-system]\nrequires = [\"setuptools\", \"wheel\"]\n\n[project]\nname = \"movie-genie\"\nversion = \"1.0.0\"\ndependencies = [\n    \"flask&gt;=2.3.0\",\n    \"torch&gt;=2.0.0\",\n    \"transformers&gt;=4.30.0\"\n]\n</code></pre>"},{"location":"reference/project-structure/#core-application-files","title":"Core Application Files","text":""},{"location":"reference/project-structure/#movie_geniebackendapppy-flask-application","title":"<code>movie_genie/backend/app.py</code> - Flask Application","text":"<pre><code># Main Flask application entry point\nfrom flask import Flask\nfrom flask_cors import CORS\n\napp = Flask(__name__)\nCORS(app)\n\n# Register API blueprints\nfrom app.api import movies_bp, search_bp, recommendations_bp\napp.register_blueprint(movies_bp, url_prefix='/api/movies')\napp.register_blueprint(search_bp, url_prefix='/api/search')\napp.register_blueprint(recommendations_bp, url_prefix='/api/recommendations')\n</code></pre>"},{"location":"reference/project-structure/#movie_geniefrontendsrcapptsx-react-application","title":"<code>movie_genie/frontend/src/App.tsx</code> - React Application","text":"<pre><code>// Main React application component\nimport React, { useState } from 'react';\nimport { UserSelectionModal, MovieSearch, SearchResultsGrid } from './components';\n\nexport default function App() {\n  const [currentUser, setCurrentUser] = useState&lt;UserInfo | null&gt;(null);\n\n  return (\n    &lt;div className=\"min-h-screen bg-gray-900\"&gt;\n      {!currentUser &amp;&amp; &lt;UserSelectionModal onUserSelect={setCurrentUser} /&gt;}\n      {currentUser &amp;&amp; (\n        &lt;&gt;\n          &lt;MovieSearch /&gt;\n          &lt;SearchResultsGrid /&gt;\n        &lt;/&gt;\n      )}\n    &lt;/div&gt;\n  );\n}\n</code></pre>"},{"location":"reference/project-structure/#data-flow-architecture","title":"\ud83d\udd04 Data Flow Architecture","text":""},{"location":"reference/project-structure/#1-data-processing-flow","title":"1. Data Processing Flow","text":"<pre><code>data/raw/ml-100k/\n\u251c\u2500\u2500 u.data (ratings) \u2500\u2500\u2500\u2500\u2510\n\u251c\u2500\u2500 u.item (movies) \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2192 scripts/process_movielens.py\n\u2514\u2500\u2500 u.user (users) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u2193\n                   data/processed/\n                   \u251c\u2500\u2500 movies.parquet\n                   \u251c\u2500\u2500 ratings.parquet\n                   \u2514\u2500\u2500 users.parquet\n</code></pre>"},{"location":"reference/project-structure/#2-model-training-flow","title":"2. Model Training Flow","text":"<pre><code>data/processed/ \u2500\u2500\u2192 movie_genie/ranking/train_bert4rec.py \u2500\u2500\u2192 models/bert4rec/\n                \u2514\u2192 movie_genie/retrieval/train_two_tower.py \u2500\u2500\u2192 models/two_tower/\n                \u2514\u2192 movie_genie/search/setup_semantic_search.py \u2500\u2500\u2192 models/semantic_search/\n</code></pre>"},{"location":"reference/project-structure/#3-application-flow","title":"3. Application Flow","text":"<pre><code>models/ \u2500\u2500\u2192 movie_genie/backend/app.py \u2500\u2500\u2192 API Endpoints\n                                          \u2502\n                                          \u2193\nFrontend \u2190\u2500\u2500\u2500 HTTP/JSON \u2190\u2500\u2500\u2500 Flask Application\n</code></pre>"},{"location":"reference/project-structure/#frontend-structure-deep-dive","title":"\ud83c\udfa8 Frontend Structure Deep Dive","text":""},{"location":"reference/project-structure/#component-hierarchy","title":"Component Hierarchy","text":"<pre><code>App.tsx\n\u251c\u2500\u2500 UserSelectionModal.tsx\n\u251c\u2500\u2500 MovieSearch.tsx\n\u251c\u2500\u2500 SearchResultsGrid.tsx\n\u2502   \u2514\u2500\u2500 MovieThumbnail.tsx (multiple)\n\u251c\u2500\u2500 RecommendationCarousel.tsx\n\u2502   \u2514\u2500\u2500 MovieThumbnail.tsx (multiple)\n\u2514\u2500\u2500 MovieDetailsPanel.tsx\n    \u2514\u2500\u2500 MovieThumbnail.tsx (similar movies)\n</code></pre>"},{"location":"reference/project-structure/#service-layer","title":"Service Layer","text":"<pre><code>services/\n\u251c\u2500\u2500 movieDataService.ts    # Main data access layer\n\u2502   \u251c\u2500\u2500 getPopularMovies()\n\u2502   \u251c\u2500\u2500 searchMovies()\n\u2502   \u251c\u2500\u2500 getRecommendations()\n\u2502   \u2514\u2500\u2500 getMovieDetails()\n\u2514\u2500\u2500 api.ts                 # Low-level API utilities\n    \u251c\u2500\u2500 fetchAPI()\n    \u2514\u2500\u2500 API_ENDPOINTS\n</code></pre>"},{"location":"reference/project-structure/#type-definitions","title":"Type Definitions","text":"<pre><code>// types/movie.ts\ninterface MovieData {\n  id: string;\n  title: string;\n  genres: string[];\n  poster_url: string | null;\n  rating: number;\n  // ... other fields\n}\n\ninterface SearchResults {\n  movies: MovieData[];\n  total: number;\n  query: string;\n  hasRealData: boolean;\n}\n</code></pre>"},{"location":"reference/project-structure/#backend-structure-deep-dive","title":"\ud83d\udd27 Backend Structure Deep Dive","text":""},{"location":"reference/project-structure/#api-layer","title":"API Layer","text":"<pre><code>app/api/\n\u251c\u2500\u2500 movies.py              # Movie-related endpoints\n\u2502   \u251c\u2500\u2500 GET /popular\n\u2502   \u251c\u2500\u2500 GET /{movie_id}\n\u2502   \u2514\u2500\u2500 GET /similar/{movie_id}\n\u251c\u2500\u2500 search.py              # Search endpoints\n\u2502   \u251c\u2500\u2500 GET /semantic\n\u2502   \u2514\u2500\u2500 GET /traditional\n\u251c\u2500\u2500 recommendations.py     # Recommendation endpoints\n\u2502   \u251c\u2500\u2500 GET /personalized\n\u2502   \u2514\u2500\u2500 GET /similar/{movie_id}\n\u2514\u2500\u2500 users.py               # User endpoints\n    \u2514\u2500\u2500 GET /info\n</code></pre>"},{"location":"reference/project-structure/#service-layer_1","title":"Service Layer","text":"<pre><code>app/services/\n\u251c\u2500\u2500 movie_service.py       # Movie business logic\n\u2502   \u251c\u2500\u2500 get_popular_movies()\n\u2502   \u251c\u2500\u2500 get_movie_by_id()\n\u2502   \u2514\u2500\u2500 get_similar_movies()\n\u251c\u2500\u2500 recommendation_service.py # ML recommendation logic\n\u2502   \u251c\u2500\u2500 get_personalized_recommendations()\n\u2502   \u2514\u2500\u2500 get_collaborative_recommendations()\n\u251c\u2500\u2500 search_service.py      # Search business logic\n\u2502   \u251c\u2500\u2500 semantic_search()\n\u2502   \u2514\u2500\u2500 traditional_search()\n\u2514\u2500\u2500 user_service.py        # User business logic\n    \u251c\u2500\u2500 get_user_info()\n    \u2514\u2500\u2500 get_user_stats()\n</code></pre>"},{"location":"reference/project-structure/#model-layer","title":"Model Layer","text":"<pre><code>app/models/\n\u251c\u2500\u2500 movie.py               # Movie data model\n\u251c\u2500\u2500 rating.py              # Rating data model\n\u2514\u2500\u2500 user.py                # User data model\n</code></pre>"},{"location":"reference/project-structure/#ml-module-structure","title":"\ud83e\udde0 ML Module Structure","text":""},{"location":"reference/project-structure/#model-organization","title":"Model Organization","text":"<pre><code>movie_genie/\n\u251c\u2500\u2500 ranking/               # Sequential models\n\u2502   \u251c\u2500\u2500 bert4rec_model.py  # BERT4Rec implementation\n\u2502   \u2514\u2500\u2500 train_bert4rec.py  # Training script\n\u251c\u2500\u2500 retrieval/             # Collaborative filtering\n\u2502   \u251c\u2500\u2500 two_tower_model.py # Two-Tower implementation\n\u2502   \u2514\u2500\u2500 train_two_tower.py # Training script\n\u2514\u2500\u2500 search/                # Content-based search\n    \u251c\u2500\u2500 semantic_engine.py # Search implementation\n    \u2514\u2500\u2500 setup_semantic_search.py # Setup script\n</code></pre>"},{"location":"reference/project-structure/#model-interface-pattern","title":"Model Interface Pattern","text":"<pre><code># Standardized model interface\nclass BaseRecommender:\n    def __init__(self, model_path: str):\n        self.model = self.load_model(model_path)\n\n    def predict(self, user_id: int, **kwargs) -&gt; List[Dict]:\n        \"\"\"Return recommendations for user\"\"\"\n        pass\n\n    def load_model(self, path: str):\n        \"\"\"Load trained model from disk\"\"\"\n        pass\n</code></pre>"},{"location":"reference/project-structure/#deployment-structure","title":"\ud83d\udce6 Deployment Structure","text":""},{"location":"reference/project-structure/#docker-structure","title":"Docker Structure","text":"<pre><code>Dockerfile                 # Multi-stage Docker build\n\u251c\u2500\u2500 Frontend Build Stage   # Build React application\n\u251c\u2500\u2500 Python Dependencies    # Install Python packages\n\u2514\u2500\u2500 Production Stage       # Final runtime image\n</code></pre>"},{"location":"reference/project-structure/#environment-configuration","title":"Environment Configuration","text":"<pre><code>.env files:\n\u251c\u2500\u2500 .env.development       # Development settings\n\u251c\u2500\u2500 .env.production        # Production settings\n\u2514\u2500\u2500 .env.example           # Template for environment variables\n</code></pre>"},{"location":"reference/project-structure/#testing-structure","title":"\ud83e\uddea Testing Structure","text":""},{"location":"reference/project-structure/#test-organization","title":"Test Organization","text":"<pre><code>tests/\n\u251c\u2500\u2500 test_ml_integration.py    # ML model integration tests\n\u251c\u2500\u2500 test_api_integration.py   # API endpoint tests\n\u251c\u2500\u2500 test_data_pipeline.py     # Data processing tests\n\u2514\u2500\u2500 fixtures/                 # Test data\n    \u251c\u2500\u2500 sample_movies.json\n    \u2514\u2500\u2500 sample_ratings.json\n\nmovie_genie/backend/tests/\n\u251c\u2500\u2500 test_api.py               # Backend API tests\n\u251c\u2500\u2500 test_services.py          # Service layer tests\n\u2514\u2500\u2500 test_models.py            # Database model tests\n\nmovie_genie/frontend/src/\n\u2514\u2500\u2500 __tests__/                # Frontend component tests\n    \u251c\u2500\u2500 MovieThumbnail.test.tsx\n    \u2514\u2500\u2500 SearchResultsGrid.test.tsx\n</code></pre>"},{"location":"reference/project-structure/#metrics-and-monitoring","title":"\ud83d\udcc8 Metrics and Monitoring","text":""},{"location":"reference/project-structure/#results-structure","title":"Results Structure","text":"<pre><code>results/\n\u251c\u2500\u2500 model_comparison.json     # Performance comparison\n\u251c\u2500\u2500 ablation_studies/         # Feature importance\n\u2502   \u251c\u2500\u2500 genre_importance.json\n\u2502   \u2514\u2500\u2500 sequence_length_study.json\n\u2514\u2500\u2500 experiment_logs/          # Detailed logs\n    \u251c\u2500\u2500 bert4rec_training.log\n    \u2514\u2500\u2500 two_tower_training.log\n\nmetrics/\n\u251c\u2500\u2500 bert4rec_metrics.json     # BERT4Rec evaluation\n\u251c\u2500\u2500 two_tower_metrics.json    # Two-Tower evaluation\n\u2514\u2500\u2500 comparison_report.json    # Model comparison\n</code></pre>"},{"location":"reference/project-structure/#development-workflow","title":"\ud83c\udfaf Development Workflow","text":""},{"location":"reference/project-structure/#adding-new-features","title":"Adding New Features","text":""},{"location":"reference/project-structure/#1-backend-api-endpoint","title":"1. Backend API Endpoint","text":"<pre><code># 1. Add route handler\nmovie_genie/backend/app/api/new_feature.py\n\n# 2. Add business logic\nmovie_genie/backend/app/services/new_feature_service.py\n\n# 3. Add tests\nmovie_genie/backend/tests/test_new_feature.py\n</code></pre>"},{"location":"reference/project-structure/#2-frontend-component","title":"2. Frontend Component","text":"<pre><code># 1. Add component\nmovie_genie/frontend/src/components/NewFeature.tsx\n\n# 2. Add to main app\nmovie_genie/frontend/src/App.tsx\n\n# 3. Add tests\nmovie_genie/frontend/src/__tests__/NewFeature.test.tsx\n</code></pre>"},{"location":"reference/project-structure/#3-ml-model","title":"3. ML Model","text":"<pre><code># 1. Add model implementation\nmovie_genie/new_model/model.py\n\n# 2. Add training script\nmovie_genie/new_model/train.py\n\n# 3. Update DVC pipeline\ndvc.yaml\n\n# 4. Add configuration\nconfigs/new_model_config.yaml\n</code></pre> <p>This project structure balances organization with simplicity, making it easy to navigate while maintaining clear separation of concerns. Each directory and file has a specific purpose and follows established conventions. \ud83d\udcc1</p>"},{"location":"reference/technology-stack/","title":"\ud83d\udee0\ufe0f Technology Stack","text":"<p>Complete reference of all technologies, frameworks, and tools used in Movie Genie.</p>"},{"location":"reference/technology-stack/#stack-overview","title":"\ud83c\udfaf Stack Overview","text":"<p>Movie Genie is built using modern, industry-standard technologies that demonstrate best practices in ML engineering and full-stack development.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Frontend      \u2502    \u2502    Backend      \u2502    \u2502   ML/Data       \u2502\n\u2502                 \u2502    \u2502                 \u2502    \u2502                 \u2502\n\u2502 \u2022 React 18      \u2502    \u2502 \u2022 Flask 2.3     \u2502    \u2502 \u2022 PyTorch 2.0   \u2502\n\u2502 \u2022 TypeScript    \u2502    \u2502 \u2022 Python 3.9+   \u2502    \u2502 \u2022 Transformers  \u2502\n\u2502 \u2022 Vite 4        \u2502    \u2502 \u2022 SQLite 3      \u2502    \u2502 \u2022 Pandas        \u2502\n\u2502 \u2022 Tailwind CSS \u2502    \u2502 \u2022 SQLAlchemy    \u2502    \u2502 \u2022 DVC           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"reference/technology-stack/#frontend-technologies","title":"\ud83c\udfa8 Frontend Technologies","text":""},{"location":"reference/technology-stack/#core-framework","title":"Core Framework","text":"Technology Version Purpose Why Chosen React 18.2+ UI Framework Component-based architecture, excellent ecosystem TypeScript 5.0+ Type Safety Catch errors at compile time, better IDE support Vite 4.4+ Build Tool Fast development server, optimized builds"},{"location":"reference/technology-stack/#styling-and-ui","title":"Styling and UI","text":"Technology Version Purpose Why Chosen Tailwind CSS 3.3+ Styling Framework Utility-first, rapid prototyping, consistent design Headless UI 1.7+ Accessible Components Unstyled, accessible UI components Heroicons 2.0+ Icon Library Beautiful SVG icons, React components"},{"location":"reference/technology-stack/#development-tools","title":"Development Tools","text":"Technology Version Purpose Why Chosen ESLint 8.45+ Code Linting Code quality and consistency Prettier 3.0+ Code Formatting Automatic code formatting Vitest 0.34+ Testing Framework Fast unit testing for Vite projects"},{"location":"reference/technology-stack/#package-management","title":"Package Management","text":"<pre><code>{\n  \"dependencies\": {\n    \"react\": \"^18.2.0\",\n    \"react-dom\": \"^18.2.0\",\n    \"typescript\": \"^5.0.2\"\n  },\n  \"devDependencies\": {\n    \"@vitejs/plugin-react\": \"^4.0.3\",\n    \"vite\": \"^4.4.5\",\n    \"tailwindcss\": \"^3.3.0\"\n  }\n}\n</code></pre>"},{"location":"reference/technology-stack/#backend-technologies","title":"\ud83d\udd27 Backend Technologies","text":""},{"location":"reference/technology-stack/#core-framework_1","title":"Core Framework","text":"Technology Version Purpose Why Chosen Flask 2.3+ Web Framework Lightweight, flexible, perfect for APIs Python 3.9+ Programming Language ML ecosystem, readable, productive SQLite 3.36+ Database Embedded, zero-config, perfect for demos"},{"location":"reference/technology-stack/#api-and-data","title":"API and Data","text":"Technology Version Purpose Why Chosen Flask-CORS 4.0+ Cross-Origin Requests Enable frontend-backend communication SQLAlchemy 2.0+ ORM Database abstraction, query building Pandas 2.0+ Data Manipulation Data processing and analysis"},{"location":"reference/technology-stack/#development-tools_1","title":"Development Tools","text":"Technology Version Purpose Why Chosen Black 23.0+ Code Formatting Automatic Python code formatting Flake8 6.0+ Code Linting Python code quality checks Pytest 7.4+ Testing Framework Comprehensive Python testing"},{"location":"reference/technology-stack/#production-tools","title":"Production Tools","text":"Technology Version Purpose Why Chosen Gunicorn 21.0+ WSGI Server Production Python web server Docker 24.0+ Containerization Consistent deployment environments"},{"location":"reference/technology-stack/#machine-learning-stack","title":"\ud83e\udde0 Machine Learning Stack","text":""},{"location":"reference/technology-stack/#core-ml-framework","title":"Core ML Framework","text":"Technology Version Purpose Why Chosen PyTorch 2.0+ Deep Learning Research-friendly, dynamic computation graphs Transformers 4.30+ Pre-trained Models State-of-the-art NLP models, BERT implementation Sentence-BERT 2.2+ Text Embeddings Semantic similarity, text search"},{"location":"reference/technology-stack/#data-processing","title":"Data Processing","text":"Technology Version Purpose Why Chosen Pandas 2.0+ Data Manipulation DataFrame operations, data cleaning NumPy 1.24+ Numerical Computing Efficient array operations, mathematical functions Scikit-learn 1.3+ Traditional ML Evaluation metrics, preprocessing utilities"},{"location":"reference/technology-stack/#model-training","title":"Model Training","text":"Technology Version Purpose Why Chosen PyTorch Lightning 2.0+ Training Framework Simplified training loops, distributed training Optuna 3.2+ Hyperparameter Tuning Automated hyperparameter optimization TensorBoard 2.13+ Experiment Tracking Training visualization, model monitoring"},{"location":"reference/technology-stack/#mlops-and-data-pipeline","title":"\ud83d\udd04 MLOps and Data Pipeline","text":""},{"location":"reference/technology-stack/#data-version-control","title":"Data Version Control","text":"Technology Version Purpose Why Chosen DVC 3.0+ Data/Model Versioning Git-like workflows for ML artifacts Git 2.40+ Code Version Control Standard version control for code"},{"location":"reference/technology-stack/#data-storage","title":"Data Storage","text":"Technology Version Purpose Why Chosen Parquet - Data Format Columnar storage, efficient compression SQLite 3.36+ Structured Data Relational data, ACID compliance HDF5 1.10+ Large Arrays Efficient storage for large numerical datasets"},{"location":"reference/technology-stack/#pipeline-orchestration","title":"Pipeline Orchestration","text":"Technology Version Purpose Why Chosen DVC Pipelines 3.0+ Workflow Management Reproducible ML pipelines Make 4.3+ Build Automation Simple task automation"},{"location":"reference/technology-stack/#deployment-and-devops","title":"\ud83d\ude80 Deployment and DevOps","text":""},{"location":"reference/technology-stack/#containerization","title":"Containerization","text":"Technology Version Purpose Why Chosen Docker 24.0+ Containerization Consistent environments, easy deployment Docker Compose 2.20+ Multi-container Apps Local development, service orchestration"},{"location":"reference/technology-stack/#cloud-deployment","title":"Cloud Deployment","text":"Platform Purpose Why Suitable AWS Cloud Platform ECS, RDS, S3 for scalable deployment Google Cloud Cloud Platform Cloud Run, BigQuery for ML workloads Heroku PaaS Simple deployment for demos and prototypes"},{"location":"reference/technology-stack/#monitoring","title":"Monitoring","text":"Technology Version Purpose Why Chosen Prometheus 2.45+ Metrics Collection Industry standard monitoring Grafana 10.0+ Visualization Beautiful dashboards and alerting"},{"location":"reference/technology-stack/#data-sources-and-datasets","title":"\ud83d\udcca Data Sources and Datasets","text":""},{"location":"reference/technology-stack/#primary-dataset","title":"Primary Dataset","text":"Dataset Size Description License MovieLens 100K 100,000 ratings User-movie ratings with timestamps MIT-like IMDB Data Variable Movie metadata and descriptions Research use"},{"location":"reference/technology-stack/#supplementary-data","title":"Supplementary Data","text":"Source Type Purpose The Movie Database (TMDB) Movie Metadata Posters, descriptions, cast information Open Movie Database Movie Info Additional movie metadata"},{"location":"reference/technology-stack/#development-environment","title":"\ud83d\udd27 Development Environment","text":""},{"location":"reference/technology-stack/#required-tools","title":"Required Tools","text":"Tool Minimum Version Purpose Python 3.8+ Backend and ML development Node.js 16+ Frontend development Git 2.30+ Version control Docker 20+ Containerization"},{"location":"reference/technology-stack/#recommended-ides","title":"Recommended IDEs","text":"IDE Best For Extensions VS Code Full-stack development Python, TypeScript, Docker PyCharm Python/ML development Built-in ML support WebStorm Frontend development React, TypeScript support"},{"location":"reference/technology-stack/#system-requirements","title":"System Requirements","text":"Component Minimum Recommended RAM 8GB 16GB+ CPU 4 cores 8+ cores Storage 10GB 50GB+ GPU None (CPU only) NVIDIA GPU for faster training"},{"location":"reference/technology-stack/#package-management_1","title":"\ud83d\udce6 Package Management","text":""},{"location":"reference/technology-stack/#python-dependencies-requirementstxt","title":"Python Dependencies (<code>requirements.txt</code>)","text":"<pre><code># Core Framework\nflask&gt;=2.3.0\nflask-cors&gt;=4.0.0\nsqlalchemy&gt;=2.0.0\n\n# ML Libraries\ntorch&gt;=2.0.0\ntransformers&gt;=4.30.0\nsentence-transformers&gt;=2.2.0\npandas&gt;=2.0.0\nnumpy&gt;=1.24.0\nscikit-learn&gt;=1.3.0\n\n# Data Pipeline\ndvc&gt;=3.0.0\n\n# Development\npytest&gt;=7.4.0\nblack&gt;=23.0.0\nflake8&gt;=6.0.0\n\n# Production\ngunicorn&gt;=21.0.0\n</code></pre>"},{"location":"reference/technology-stack/#frontend-dependencies-packagejson","title":"Frontend Dependencies (<code>package.json</code>)","text":"<pre><code>{\n  \"dependencies\": {\n    \"react\": \"^18.2.0\",\n    \"react-dom\": \"^18.2.0\"\n  },\n  \"devDependencies\": {\n    \"@types/react\": \"^18.2.15\",\n    \"@types/react-dom\": \"^18.2.7\",\n    \"@vitejs/plugin-react\": \"^4.0.3\",\n    \"autoprefixer\": \"^10.4.14\",\n    \"eslint\": \"^8.45.0\",\n    \"postcss\": \"^8.4.27\",\n    \"prettier\": \"^3.0.0\",\n    \"tailwindcss\": \"^3.3.0\",\n    \"typescript\": \"^5.0.2\",\n    \"vite\": \"^4.4.5\",\n    \"vitest\": \"^0.34.0\"\n  }\n}\n</code></pre>"},{"location":"reference/technology-stack/#architecture-patterns","title":"\ud83c\udfd7\ufe0f Architecture Patterns","text":""},{"location":"reference/technology-stack/#design-patterns-used","title":"Design Patterns Used","text":"Pattern Implementation Purpose MVC Flask routes + services + models Separation of concerns Service Layer Business logic encapsulation Testable, reusable logic Repository Data access abstraction Database independence Factory ML model loading Flexible model instantiation"},{"location":"reference/technology-stack/#frontend-patterns","title":"Frontend Patterns","text":"Pattern Implementation Purpose Component Composition React components Reusable UI elements State Management React hooks Predictable state updates Service Layer Data access services API abstraction"},{"location":"reference/technology-stack/#ml-patterns","title":"ML Patterns","text":"Pattern Implementation Purpose Pipeline DVC stages Reproducible workflows Model Registry Versioned model artifacts Model lifecycle management Feature Store Processed data files Reusable feature engineering"},{"location":"reference/technology-stack/#security-considerations","title":"\ud83d\udd12 Security Considerations","text":""},{"location":"reference/technology-stack/#security-technologies","title":"Security Technologies","text":"Technology Purpose Implementation HTTPS Encrypted communication Production deployment CORS Cross-origin security Flask-CORS configuration Input Validation Prevent injection attacks SQLAlchemy parameterized queries"},{"location":"reference/technology-stack/#best-practices","title":"Best Practices","text":"<ul> <li>Environment Variables: Sensitive configuration</li> <li>No Hardcoded Secrets: All secrets externalized</li> <li>SQL Injection Prevention: Parameterized queries only</li> <li>XSS Prevention: React's built-in protection</li> </ul>"},{"location":"reference/technology-stack/#performance-technologies","title":"\ud83d\udcc8 Performance Technologies","text":""},{"location":"reference/technology-stack/#optimization-tools","title":"Optimization Tools","text":"Technology Purpose Usage SQLite Indexes Fast database queries Movie and user lookups React.memo Component optimization Prevent unnecessary re-renders Bundle Splitting Faster initial load Vite code splitting Model Caching ML inference speed In-memory model storage"},{"location":"reference/technology-stack/#monitoring_1","title":"Monitoring","text":"Metric Tool Purpose Response Time Flask logging API performance Memory Usage psutil Resource monitoring Bundle Size Vite analyzer Frontend optimization"},{"location":"reference/technology-stack/#technology-roadmap","title":"\ud83d\udd2e Technology Roadmap","text":""},{"location":"reference/technology-stack/#short-term-next-3-months","title":"Short Term (Next 3 months)","text":"<ul> <li> Redis for caching frequently accessed data</li> <li> PostgreSQL for production database</li> <li> Celery for background task processing</li> <li> React Query for better data fetching</li> </ul>"},{"location":"reference/technology-stack/#medium-term-3-6-months","title":"Medium Term (3-6 months)","text":"<ul> <li> Kubernetes for container orchestration</li> <li> MLflow for experiment tracking</li> <li> Apache Kafka for real-time data streaming</li> <li> GraphQL for flexible API queries</li> </ul>"},{"location":"reference/technology-stack/#long-term-6-months","title":"Long Term (6+ months)","text":"<ul> <li> Ray for distributed ML training</li> <li> Apache Spark for big data processing</li> <li> TensorFlow Serving for model deployment</li> <li> Apache Airflow for complex workflow orchestration</li> </ul>"},{"location":"reference/technology-stack/#technology-decisions","title":"\ud83e\udd14 Technology Decisions","text":""},{"location":"reference/technology-stack/#why-these-choices","title":"Why These Choices?","text":""},{"location":"reference/technology-stack/#frontend-react-typescript","title":"Frontend: React + TypeScript","text":"<ul> <li>\u2705 Component-based: Reusable, maintainable UI</li> <li>\u2705 Type Safety: Catch errors early, better tooling</li> <li>\u2705 Ecosystem: Massive community, extensive libraries</li> <li>\u2705 Learning Value: Industry-standard skills</li> </ul>"},{"location":"reference/technology-stack/#backend-flask-python","title":"Backend: Flask + Python","text":"<ul> <li>\u2705 ML Ecosystem: PyTorch, transformers, pandas integration</li> <li>\u2705 Simplicity: Minimal boilerplate, easy to understand</li> <li>\u2705 Flexibility: Can scale from prototype to production</li> <li>\u2705 Documentation: Excellent learning resources</li> </ul>"},{"location":"reference/technology-stack/#ml-pytorch-transformers","title":"ML: PyTorch + Transformers","text":"<ul> <li>\u2705 Research-Friendly: Dynamic graphs, easy experimentation</li> <li>\u2705 State-of-the-art: Latest BERT implementations</li> <li>\u2705 Community: Strong research and industry adoption</li> <li>\u2705 Flexibility: Custom model architectures possible</li> </ul>"},{"location":"reference/technology-stack/#data-dvc-sqlite","title":"Data: DVC + SQLite","text":"<ul> <li>\u2705 Reproducibility: Version control for data and models</li> <li>\u2705 Simplicity: SQLite requires no setup</li> <li>\u2705 Scalability: Can migrate to PostgreSQL easily</li> <li>\u2705 Learning: Demonstrates MLOps best practices</li> </ul> <p>This technology stack provides a solid foundation for learning modern ML engineering while being practical enough for real-world applications. Each choice balances learning value with industry relevance. \ud83d\udee0\ufe0f</p>"},{"location":"troubleshooting/","title":"\ud83c\udd98 Troubleshooting Guide","text":"<p>Common issues and solutions for Movie Genie development, deployment, and operation.</p>"},{"location":"troubleshooting/#quick-problem-solving","title":"\ud83c\udfaf Quick Problem Solving","text":""},{"location":"troubleshooting/#most-common-issues-90-of-problems","title":"Most Common Issues (90% of problems)","text":"Problem Quick Fix Section Frontend popup button grayed out Check backend is running on port 5001 Frontend Issues \"Module not found\" errors Run <code>pip install -e .</code> in project root Installation Issues API not responding Check <code>curl http://127.0.0.1:5001/api/health</code> Backend Issues Models not loading Run <code>dvc repro</code> to train models ML Model Issues Database errors Delete and recreate: <code>rm movie_genie.db &amp;&amp; dvc repro</code> Database Issues"},{"location":"troubleshooting/#documentation-sections","title":"\ud83d\udccb Documentation Sections","text":""},{"location":"troubleshooting/#ml-model-issues","title":"\ud83e\udde0 ML Model Issues","text":"<p>For: Model training failures, prediction errors, memory issues - Model loading and initialization problems - Training pipeline failures - Memory and GPU issues - Performance optimization</p>"},{"location":"troubleshooting/#backend-issues","title":"\ud83d\udd27 Backend Issues","text":"<p>For: Flask API problems, database connections, service errors - API endpoint failures - Database connectivity issues - Service layer problems - Authentication and permissions</p>"},{"location":"troubleshooting/#frontend-issues","title":"\ud83c\udfa8 Frontend Issues","text":"<p>For: React app problems, build failures, UI bugs - Component rendering issues - Build and deployment problems - State management bugs - Styling and responsive design</p>"},{"location":"troubleshooting/#installation-issues","title":"\ud83d\udd27 Installation Issues","text":""},{"location":"troubleshooting/#python-environment-problems","title":"Python Environment Problems","text":""},{"location":"troubleshooting/#no-module-named-movie_genie","title":"\"No module named 'movie_genie'\"","text":"<pre><code># Solution: Install in development mode\npip install -e .\n\n# If still failing, check virtual environment\nwhich python\n# Should point to .venv/bin/python\n\n# Activate virtual environment if needed\nsource .venv/bin/activate  # macOS/Linux\n.venv\\Scripts\\activate     # Windows\n</code></pre>"},{"location":"troubleshooting/#permission-denied-during-installation","title":"\"Permission denied\" during installation","text":"<pre><code># Solution: Use virtual environment (preferred)\npython -m venv .venv\nsource .venv/bin/activate\npip install -e .\n\n# Or install for user only\npip install --user -e .\n</code></pre>"},{"location":"troubleshooting/#python-version-conflicts","title":"Python version conflicts","text":"<pre><code># Check Python version\npython --version  # Should be 3.8+\n\n# If wrong version, use specific Python\npython3.9 -m venv .venv\nsource .venv/bin/activate\npip install -e .\n</code></pre>"},{"location":"troubleshooting/#nodejs-and-frontend-issues","title":"Node.js and Frontend Issues","text":""},{"location":"troubleshooting/#npm-install-failures","title":"\"npm install\" failures","text":"<pre><code># Clear npm cache\nnpm cache clean --force\n\n# Delete node_modules and reinstall\nrm -rf movie_genie/frontend/node_modules\ncd movie_genie/frontend\nnpm install\n\n# If still failing, check Node.js version\nnode --version  # Should be 16+\n</code></pre>"},{"location":"troubleshooting/#eacces-permission-errors","title":"\"EACCES\" permission errors","text":"<pre><code># Fix npm permissions\nnpm config set prefix ~/.npm-global\necho 'export PATH=~/.npm-global/bin:$PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>"},{"location":"troubleshooting/#dvc-issues","title":"DVC Issues","text":""},{"location":"troubleshooting/#dvc-not-initialized","title":"\"DVC not initialized\"","text":"<pre><code># Initialize DVC in project root\ncd movie-genie\ndvc init\n\n# If git repository, use:\ndvc init --no-scm\n</code></pre>"},{"location":"troubleshooting/#stage-not-found-errors","title":"\"Stage not found\" errors","text":"<pre><code># Check dvc.yaml exists\nls -la dvc.yaml\n\n# Verify stage names\ndvc dag\n\n# Run specific stage\ndvc repro stage_name\n</code></pre>"},{"location":"troubleshooting/#connection-issues","title":"\ud83d\udd0c Connection Issues","text":""},{"location":"troubleshooting/#port-conflicts","title":"Port Conflicts","text":""},{"location":"troubleshooting/#port-5001-already-in-use","title":"\"Port 5001 already in use\"","text":"<pre><code># Find process using port\nlsof -ti:5001\n\n# Kill the process\nlsof -ti:5001 | xargs kill -9\n\n# Or use different port\nFLASK_PORT=5002 python movie_genie/backend/app.py\n</code></pre>"},{"location":"troubleshooting/#frontend-cant-reach-backend","title":"Frontend can't reach backend","text":"<pre><code># Check backend is running\ncurl http://127.0.0.1:5001/api/health\n\n# Check frontend environment\ncat movie_genie/frontend/.env.development\n# Should have: VITE_API_URL=http://127.0.0.1:5001/api\n\n# Restart both services\n# Terminal 1:\ncd movie_genie/backend &amp;&amp; python app.py\n\n# Terminal 2:\ncd movie_genie/frontend &amp;&amp; npm run dev\n</code></pre>"},{"location":"troubleshooting/#network-and-firewall-issues","title":"Network and Firewall Issues","text":""},{"location":"troubleshooting/#api-calls-timing-out","title":"API calls timing out","text":"<pre><code># Check firewall settings\n# macOS:\nsudo pfctl -s all\n\n# Linux:\nsudo ufw status\n\n# Windows:\nnetsh advfirewall show allprofiles\n</code></pre>"},{"location":"troubleshooting/#cors-errors-in-browser","title":"CORS errors in browser","text":"<pre><code># Backend app.py should have:\nfrom flask_cors import CORS\napp = Flask(__name__)\nCORS(app)  # Enable CORS for all routes\n</code></pre>"},{"location":"troubleshooting/#database-issues","title":"\ud83d\udcbe Database Issues","text":""},{"location":"troubleshooting/#sqlite-database-problems","title":"SQLite Database Problems","text":""},{"location":"troubleshooting/#database-is-locked","title":"\"Database is locked\"","text":"<pre><code># Check if other processes are using database\nlsof movie_genie/backend/movie_genie.db\n\n# Kill processes if needed\npkill -f movie_genie\n\n# Remove lock file if exists\nrm movie_genie/backend/movie_genie.db-journal\n</code></pre>"},{"location":"troubleshooting/#no-such-table-errors","title":"\"No such table\" errors","text":"<pre><code># Recreate database\nrm movie_genie/backend/movie_genie.db*\ndvc repro setup_database\n\n# Verify tables exist\nsqlite3 movie_genie/backend/movie_genie.db \".tables\"\n</code></pre>"},{"location":"troubleshooting/#database-corruption","title":"Database corruption","text":"<pre><code># Check database integrity\nsqlite3 movie_genie/backend/movie_genie.db \"PRAGMA integrity_check;\"\n\n# If corrupted, restore from backup or recreate\nrm movie_genie/backend/movie_genie.db\ndvc repro data_processing setup_database\n</code></pre>"},{"location":"troubleshooting/#data-validation-issues","title":"Data Validation Issues","text":""},{"location":"troubleshooting/#no-data-found-errors","title":"\"No data found\" errors","text":"<pre><code># Check data files exist\nls -la data/raw/ml-100k/\nls -la data/processed/\n\n# If missing, run data processing\ndvc repro data_processing\n\n# Verify data quality\npython -c \"\nimport pandas as pd\ndf = pd.read_parquet('data/processed/movies.parquet')\nprint(f'Movies: {len(df)}')\nprint(f'Columns: {df.columns.tolist()}')\n\"\n</code></pre>"},{"location":"troubleshooting/#performance-issues","title":"\ud83d\ude80 Performance Issues","text":""},{"location":"troubleshooting/#slow-application-response","title":"Slow Application Response","text":""},{"location":"troubleshooting/#backend-api-slow","title":"Backend API slow","text":"<pre><code># Check system resources\ntop\nhtop\n\n# Monitor database queries\n# Add to app.py:\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre>"},{"location":"troubleshooting/#frontend-slow-loading","title":"Frontend slow loading","text":"<pre><code># Check bundle size\ncd movie_genie/frontend\nnpm run build\nls -lh dist/assets/\n\n# Analyze bundle\nnpm install --save-dev webpack-bundle-analyzer\nnpm run build-analyze\n</code></pre>"},{"location":"troubleshooting/#memory-issues","title":"Memory Issues","text":""},{"location":"troubleshooting/#out-of-memory-during-training","title":"\"Out of memory\" during training","text":"<pre><code># Reduce batch sizes in configs/bert4rec_config.yaml\nbatch_size: 128  # Instead of 512\n\n# Reduce model size\nhidden_size: 64  # Instead of 128\nnum_layers: 2    # Instead of 4\n</code></pre>"},{"location":"troubleshooting/#high-memory-usage-in-production","title":"High memory usage in production","text":"<pre><code># Add memory monitoring to app.py\nimport psutil\n\n@app.route('/api/health')\ndef health():\n    memory = psutil.virtual_memory()\n    return {\n        'status': 'healthy',\n        'memory_usage': f'{memory.percent}%',\n        'available_memory': f'{memory.available / 1024**3:.1f}GB'\n    }\n</code></pre>"},{"location":"troubleshooting/#debugging-tools-and-techniques","title":"\ud83d\udd0d Debugging Tools and Techniques","text":""},{"location":"troubleshooting/#backend-debugging","title":"Backend Debugging","text":""},{"location":"troubleshooting/#enable-debug-mode","title":"Enable debug mode","text":"<pre><code># In app.py\napp.config['DEBUG'] = True\napp.run(debug=True, host='127.0.0.1', port=5001)\n</code></pre>"},{"location":"troubleshooting/#add-request-logging","title":"Add request logging","text":"<pre><code>import logging\nfrom flask import request\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n@app.before_request\ndef log_request_info():\n    logger.info(f'{request.method} {request.url}')\n</code></pre>"},{"location":"troubleshooting/#database-query-debugging","title":"Database query debugging","text":"<pre><code># Add query logging\nimport sqlite3\n\ndef debug_query(query, params=None):\n    print(f\"SQL: {query}\")\n    if params:\n        print(f\"Params: {params}\")\n    return query\n</code></pre>"},{"location":"troubleshooting/#frontend-debugging","title":"Frontend Debugging","text":""},{"location":"troubleshooting/#browser-developer-tools","title":"Browser developer tools","text":"<pre><code>// Add to MovieDataService\nstatic async searchMovies(query) {\n    console.log('\ud83d\udd0d Searching for:', query);\n\n    try {\n        const response = await fetch(`${API_URL}/search/semantic?q=${query}`);\n        console.log('\ud83d\udce1 API Response:', response.status);\n\n        const data = await response.json();\n        console.log('\ud83d\udcc4 Response Data:', data);\n\n        return data;\n    } catch (error) {\n        console.error('\u274c Search failed:', error);\n        throw error;\n    }\n}\n</code></pre>"},{"location":"troubleshooting/#react-component-debugging","title":"React component debugging","text":"<pre><code>// Add to components\nimport { useEffect } from 'react';\n\nfunction MovieThumbnail({ movie }) {\n    useEffect(() =&gt; {\n        console.log('\ud83c\udfac Rendering movie:', movie.title);\n    }, [movie]);\n\n    return (\n        &lt;div onClick={() =&gt; console.log('\ud83d\uddb1\ufe0f Clicked movie:', movie.id)}&gt;\n            {/* component content */}\n        &lt;/div&gt;\n    );\n}\n</code></pre>"},{"location":"troubleshooting/#ml-model-debugging","title":"ML Model Debugging","text":""},{"location":"troubleshooting/#test-model-loading","title":"Test model loading","text":"<pre><code># Create test script\npython -c \"\ntry:\n    from movie_genie.ranking.bert4rec_model import BERT4RecReranker\n    model = BERT4RecReranker('models/bert4rec/')\n    print('\u2705 BERT4Rec loaded successfully')\nexcept Exception as e:\n    print(f'\u274c BERT4Rec failed: {e}')\n\"\n</code></pre>"},{"location":"troubleshooting/#check-model-files","title":"Check model files","text":"<pre><code># Verify model artifacts\nls -la models/\nls -la models/bert4rec/\nls -la models/two_tower/\n\n# Check file sizes\ndu -sh models/*\n</code></pre>"},{"location":"troubleshooting/#logging-and-monitoring","title":"\ud83d\udcdd Logging and Monitoring","text":""},{"location":"troubleshooting/#application-logs","title":"Application Logs","text":""},{"location":"troubleshooting/#backend-logging-setup","title":"Backend logging setup","text":"<pre><code># Enhanced logging in app.py\nimport logging\nfrom logging.handlers import RotatingFileHandler\n\nif not app.debug:\n    file_handler = RotatingFileHandler('logs/app.log', maxBytes=10240, backupCount=10)\n    file_handler.setFormatter(logging.Formatter(\n        '%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]'\n    ))\n    file_handler.setLevel(logging.INFO)\n    app.logger.addHandler(file_handler)\n    app.logger.setLevel(logging.INFO)\n</code></pre>"},{"location":"troubleshooting/#monitor-logs","title":"Monitor logs","text":"<pre><code># Real-time log monitoring\ntail -f movie_genie/backend/logs/app.log\n\n# Filter for errors\ngrep ERROR movie_genie/backend/logs/app.log\n\n# Check access patterns\ngrep \"GET\\|POST\" movie_genie/backend/logs/app.log | tail -20\n</code></pre>"},{"location":"troubleshooting/#system-monitoring","title":"System Monitoring","text":""},{"location":"troubleshooting/#resource-usage","title":"Resource usage","text":"<pre><code># Monitor Python processes\nps aux | grep python\n\n# Monitor memory usage\nfree -h\n\n# Monitor disk usage\ndf -h\ndu -sh data/ models/ results/\n</code></pre>"},{"location":"troubleshooting/#performance-profiling","title":"Performance profiling","text":"<pre><code># Profile Python code\npython -m cProfile -o profile.stats movie_genie/ranking/train_bert4rec.py\n\n# Analyze profile\npython -c \"\nimport pstats\nstats = pstats.Stats('profile.stats')\nstats.sort_stats('cumulative')\nstats.print_stats(10)\n\"\n</code></pre>"},{"location":"troubleshooting/#emergency-recovery","title":"\ud83c\udd98 Emergency Recovery","text":""},{"location":"troubleshooting/#complete-system-reset","title":"Complete System Reset","text":""},{"location":"troubleshooting/#nuclear-option-fresh-start","title":"Nuclear option - fresh start","text":"<pre><code># \u26a0\ufe0f This will delete all generated data and models\n\n# 1. Backup important files\ncp movie_genie/backend/movie_genie.db backup_db.db 2&gt;/dev/null || true\n\n# 2. Clean everything\nrm -rf .venv/ models/ data/processed/ results/\nrm -f movie_genie/backend/movie_genie.db*\n\n# 3. Fresh installation\npython -m venv .venv\nsource .venv/bin/activate\npip install -e .\n\n# 4. Rebuild everything\ndvc repro\n\n# 5. Verify everything works\ncurl http://127.0.0.1:5001/api/health\n</code></pre>"},{"location":"troubleshooting/#partial-recovery","title":"Partial Recovery","text":""},{"location":"troubleshooting/#reset-just-the-models","title":"Reset just the models","text":"<pre><code># Remove and retrain models only\nrm -rf models/\ndvc repro train_bert4rec train_two_tower setup_semantic_search\n\n# Test model loading\npython -c \"\nfrom movie_genie.ranking.bert4rec_model import BERT4RecReranker\nprint('Models loaded successfully')\n\"\n</code></pre>"},{"location":"troubleshooting/#reset-just-the-database","title":"Reset just the database","text":"<pre><code># Remove and recreate database only\nrm movie_genie/backend/movie_genie.db*\ndvc repro setup_database\n\n# Verify database\nsqlite3 movie_genie/backend/movie_genie.db \"SELECT COUNT(*) FROM movies;\"\n</code></pre>"},{"location":"troubleshooting/#backup-and-restore","title":"Backup and Restore","text":""},{"location":"troubleshooting/#create-backup","title":"Create backup","text":"<pre><code># Create backup script\ncat &gt; scripts/backup.sh &lt;&lt; 'EOF'\n#!/bin/bash\nBACKUP_DIR=\"backups/$(date +%Y%m%d_%H%M%S)\"\nmkdir -p $BACKUP_DIR\n\n# Backup database\ncp movie_genie/backend/movie_genie.db $BACKUP_DIR/ 2&gt;/dev/null || true\n\n# Backup models\ncp -r models/ $BACKUP_DIR/ 2&gt;/dev/null || true\n\n# Backup processed data\ncp -r data/processed/ $BACKUP_DIR/ 2&gt;/dev/null || true\n\necho \"Backup created in $BACKUP_DIR\"\nEOF\n\nchmod +x scripts/backup.sh\n./scripts/backup.sh\n</code></pre>"},{"location":"troubleshooting/#restore-from-backup","title":"Restore from backup","text":"<pre><code># List available backups\nls -la backups/\n\n# Restore from specific backup\nBACKUP_DATE=\"20240101_120000\"\ncp backups/$BACKUP_DATE/movie_genie.db movie_genie/backend/\ncp -r backups/$BACKUP_DATE/models/ .\ncp -r backups/$BACKUP_DATE/data/processed/ data/\n\n# Verify restore\ndvc status\n</code></pre>"},{"location":"troubleshooting/#getting-additional-help","title":"\ud83d\udcde Getting Additional Help","text":""},{"location":"troubleshooting/#self-diagnostic-checklist","title":"Self-Diagnostic Checklist","text":"<p>Before asking for help, run through this checklist:</p> <ul> <li> Environment: Virtual environment activated and dependencies installed</li> <li> Services: Backend running on port 5001, frontend on 5173</li> <li> Data: Database exists and contains data</li> <li> Models: ML models trained and loadable</li> <li> Network: API endpoints responding to curl tests</li> <li> Logs: Check application logs for specific error messages</li> </ul>"},{"location":"troubleshooting/#useful-diagnostic-commands","title":"Useful Diagnostic Commands","text":"<pre><code># Complete system check\necho \"=== System Check ===\"\npython --version\nnode --version\npip list | grep movie-genie\nls -la movie_genie/backend/movie_genie.db\ncurl -s http://127.0.0.1:5001/api/health | jq .\n\n# DVC status\necho \"=== DVC Status ===\"\ndvc status\n\n# Model verification\necho \"=== Model Check ===\"\nls -la models/\npython -c \"import torch; print('PyTorch:', torch.__version__)\"\n\n# Database check\necho \"=== Database Check ===\"\nsqlite3 movie_genie/backend/movie_genie.db \"\nSELECT 'Movies:' as table_name, COUNT(*) as count FROM movies\nUNION ALL\nSELECT 'Users:', COUNT(*) FROM users\nUNION ALL\nSELECT 'Ratings:', COUNT(*) FROM ratings;\n\"\n</code></pre>"},{"location":"troubleshooting/#reporting-issues","title":"Reporting Issues","text":"<p>When reporting issues, include:</p> <ol> <li>Environment: OS, Python version, Node.js version</li> <li>Steps to reproduce: Exact commands that cause the issue</li> <li>Error messages: Complete error output, not just snippets</li> <li>Logs: Relevant log entries from application logs</li> <li>System state: Output of diagnostic commands above</li> </ol> <p>This troubleshooting guide covers the most common issues you'll encounter. Remember: most problems have simple solutions, and systematic debugging usually reveals the root cause quickly. \ud83c\udd98</p>"}]}