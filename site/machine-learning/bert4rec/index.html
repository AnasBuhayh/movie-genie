<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="AI-powered movie recommendation system - Complete learning reference"><meta name=author content="Movie Genie Team"><link href=https://your-username.github.io/movie-genie/machine-learning/bert4rec/ rel=canonical><link href=../models-overview/ rel=prev><link href=../semantic-search/ rel=next><link rel=icon href=../../assets/favicon.ico><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.20"><title>BERT4Rec - Movie Genie Documentation</title><link rel=stylesheet href=../../assets/stylesheets/main.e53b48f4.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config",""),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#bert4rec-architecture-mathematical-foundations-and-sequential-understanding class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Movie Genie Documentation" class="md-header__button md-logo" aria-label="Movie Genie Documentation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m18 4 2 4h-3l-2-4h-2l2 4h-3l-2-4H8l2 4H7L5 4H4a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V4z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Movie Genie Documentation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> BERT4Rec </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/your-username/movie-genie title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> movie-genie </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../getting-started/ class=md-tabs__link> Getting Started </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../index.md class=md-tabs__link> Machine Learning </a> </li> <li class=md-tabs__item> <a href=../../data-pipeline/index.md class=md-tabs__link> Data Pipeline </a> </li> <li class=md-tabs__item> <a href=../../backend-frontend/index.md class=md-tabs__link> Backend & Frontend </a> </li> <li class=md-tabs__item> <a href=../../deployment/index.md class=md-tabs__link> Deployment </a> </li> <li class=md-tabs__item> <a href=../../configuration/index.md class=md-tabs__link> Configuration </a> </li> <li class=md-tabs__item> <a href=../../troubleshooting/index.md class=md-tabs__link> Troubleshooting </a> </li> <li class=md-tabs__item> <a href=../../reference/index.md class=md-tabs__link> Reference </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Movie Genie Documentation" class="md-nav__button md-logo" aria-label="Movie Genie Documentation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m18 4 2 4h-3l-2-4h-2l2 4h-3l-2-4H8l2 4H7L5 4H4a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V4z"/></svg> </a> Movie Genie Documentation </label> <div class=md-nav__source> <a href=https://github.com/your-username/movie-genie title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> movie-genie </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../getting-started/ class=md-nav__link> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> Machine Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Machine Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../index.md class=md-nav__link> <span class=md-ellipsis> None </span> </a> </li> <li class=md-nav__item> <a href=../models-overview/ class=md-nav__link> <span class=md-ellipsis> Models Overview </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> BERT4Rec </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> BERT4Rec </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#understanding-the-sequential-recommendation-challenge class=md-nav__link> <span class=md-ellipsis> Understanding the Sequential Recommendation Challenge </span> </a> </li> <li class=md-nav__item> <a href=#the-mathematical-foundation-of-sequential-modeling class=md-nav__link> <span class=md-ellipsis> The Mathematical Foundation of Sequential Modeling </span> </a> </li> <li class=md-nav__item> <a href=#why-bidirectional-context-revolutionizes-sequential-understanding class=md-nav__link> <span class=md-ellipsis> Why Bidirectional Context Revolutionizes Sequential Understanding </span> </a> </li> <li class=md-nav__item> <a href=#the-transformer-architecture-attention-as-preference-understanding class=md-nav__link> <span class=md-ellipsis> The Transformer Architecture: Attention as Preference Understanding </span> </a> </li> <li class=md-nav__item> <a href=#multi-head-attention-capturing-different-aspects-of-preference class=md-nav__link> <span class=md-ellipsis> Multi-Head Attention: Capturing Different Aspects of Preference </span> </a> </li> <li class=md-nav__item> <a href=#the-masking-strategy-learning-through-contextual-prediction class=md-nav__link> <span class=md-ellipsis> The Masking Strategy: Learning Through Contextual Prediction </span> </a> </li> <li class=md-nav__item> <a href=#content-feature-integration-bridging-collaborative-and-content-understanding class=md-nav__link> <span class=md-ellipsis> Content Feature Integration: Bridging Collaborative and Content Understanding </span> </a> </li> <li class=md-nav__item> <a href=#transformer-layers-building-hierarchical-understanding class=md-nav__link> <span class=md-ellipsis> Transformer Layers: Building Hierarchical Understanding </span> </a> </li> <li class=md-nav__item> <a href=#training-dynamics-and-optimization-challenges class=md-nav__link> <span class=md-ellipsis> Training Dynamics and Optimization Challenges </span> </a> </li> <li class=md-nav__item> <a href=#integration-with-your-two-tower-architecture class=md-nav__link> <span class=md-ellipsis> Integration with Your Two-Tower Architecture </span> </a> </li> <li class=md-nav__item> <a href=#why-this-architecture-succeeds-for-movie-recommendation class=md-nav__link> <span class=md-ellipsis> Why This Architecture Succeeds for Movie Recommendation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../two-tower.md class=md-nav__link> <span class=md-ellipsis> Two-Tower </span> </a> </li> <li class=md-nav__item> <a href=../semantic-search/ class=md-nav__link> <span class=md-ellipsis> Semantic Search </span> </a> </li> <li class=md-nav__item> <a href=../evaluation/ class=md-nav__link> <span class=md-ellipsis> Model Evaluation </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../data-pipeline/index.md class=md-nav__link> <span class=md-ellipsis> Data Pipeline </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../backend-frontend/index.md class=md-nav__link> <span class=md-ellipsis> Backend & Frontend </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../deployment/index.md class=md-nav__link> <span class=md-ellipsis> Deployment </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../configuration/index.md class=md-nav__link> <span class=md-ellipsis> Configuration </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../troubleshooting/index.md class=md-nav__link> <span class=md-ellipsis> Troubleshooting </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../reference/index.md class=md-nav__link> <span class=md-ellipsis> Reference </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#understanding-the-sequential-recommendation-challenge class=md-nav__link> <span class=md-ellipsis> Understanding the Sequential Recommendation Challenge </span> </a> </li> <li class=md-nav__item> <a href=#the-mathematical-foundation-of-sequential-modeling class=md-nav__link> <span class=md-ellipsis> The Mathematical Foundation of Sequential Modeling </span> </a> </li> <li class=md-nav__item> <a href=#why-bidirectional-context-revolutionizes-sequential-understanding class=md-nav__link> <span class=md-ellipsis> Why Bidirectional Context Revolutionizes Sequential Understanding </span> </a> </li> <li class=md-nav__item> <a href=#the-transformer-architecture-attention-as-preference-understanding class=md-nav__link> <span class=md-ellipsis> The Transformer Architecture: Attention as Preference Understanding </span> </a> </li> <li class=md-nav__item> <a href=#multi-head-attention-capturing-different-aspects-of-preference class=md-nav__link> <span class=md-ellipsis> Multi-Head Attention: Capturing Different Aspects of Preference </span> </a> </li> <li class=md-nav__item> <a href=#the-masking-strategy-learning-through-contextual-prediction class=md-nav__link> <span class=md-ellipsis> The Masking Strategy: Learning Through Contextual Prediction </span> </a> </li> <li class=md-nav__item> <a href=#content-feature-integration-bridging-collaborative-and-content-understanding class=md-nav__link> <span class=md-ellipsis> Content Feature Integration: Bridging Collaborative and Content Understanding </span> </a> </li> <li class=md-nav__item> <a href=#transformer-layers-building-hierarchical-understanding class=md-nav__link> <span class=md-ellipsis> Transformer Layers: Building Hierarchical Understanding </span> </a> </li> <li class=md-nav__item> <a href=#training-dynamics-and-optimization-challenges class=md-nav__link> <span class=md-ellipsis> Training Dynamics and Optimization Challenges </span> </a> </li> <li class=md-nav__item> <a href=#integration-with-your-two-tower-architecture class=md-nav__link> <span class=md-ellipsis> Integration with Your Two-Tower Architecture </span> </a> </li> <li class=md-nav__item> <a href=#why-this-architecture-succeeds-for-movie-recommendation class=md-nav__link> <span class=md-ellipsis> Why This Architecture Succeeds for Movie Recommendation </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/your-username/movie-genie/edit/main/docs/machine-learning/bert4rec.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/your-username/movie-genie/raw/main/docs/machine-learning/bert4rec.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=bert4rec-architecture-mathematical-foundations-and-sequential-understanding>BERT4Rec Architecture: Mathematical Foundations and Sequential Understanding<a class=headerlink href=#bert4rec-architecture-mathematical-foundations-and-sequential-understanding title="Permanent link">&para;</a></h1> <p><em>A comprehensive guide to bidirectional transformer-based sequential recommendation for movie discovery</em></p> <h2 id=understanding-the-sequential-recommendation-challenge>Understanding the Sequential Recommendation Challenge<a class=headerlink href=#understanding-the-sequential-recommendation-challenge title="Permanent link">&para;</a></h2> <p>Let me start by helping you understand why we need BERT4Rec when we already have a working two-tower model. Think about how you actually choose movies to watch. Your decision isn't just based on what you generally like - it's heavily influenced by what you've been watching recently, what mood you're in, and how your tastes are evolving over time.</p> <p>Consider this example: You've been on a Christopher Nolan binge, watching "Inception," "Interstellar," and "The Dark Knight" over the past few weeks. Then you watch a romantic comedy with friends. A traditional collaborative filtering system might think your preferences have shifted toward romantic comedies. But a human would understand that you're still interested in complex, thought-provoking films - the romantic comedy was just a temporary diversion.</p> <p>Your two-tower model captures what you generally like based on your overall interaction history. It learns that you enjoy science fiction, complex narratives, and high production values. But it treats each rating as an independent signal. It doesn't understand the sequential logic of how your preferences unfold over time or how context influences what you want to watch next.</p> <p>This limitation becomes particularly important for movie recommendation because film consumption involves deliberate exploration patterns. Users go through phases - maybe a month of exploring film noir, followed by a documentary phase, then returning to action movies. These temporal patterns contain crucial information about user intent that static models cannot capture.</p> <h2 id=the-mathematical-foundation-of-sequential-modeling>The Mathematical Foundation of Sequential Modeling<a class=headerlink href=#the-mathematical-foundation-of-sequential-modeling title="Permanent link">&para;</a></h2> <p>Let's formalize this problem mathematically. Instead of treating user preferences as a static function, we need to model them as sequences that evolve over time.</p> <p>Traditional collaborative filtering models user-item compatibility as: <span class=arithmatex>\(<span class=arithmatex>\(\hat{r}_{ui} = f(u, i, \Theta)\)</span>\)</span></p> <p>where user <span class=arithmatex>\(u\)</span> and item <span class=arithmatex>\(i\)</span> are treated as independent entities. Sequential recommendation extends this to consider the user's interaction history as a sequence:</p> <div class=arithmatex>\[\mathbf{s}_u = [i_1, i_2, \ldots, i_t]\]</div> <p>where <span class=arithmatex>\(\mathbf{s}_u\)</span> represents user <span class=arithmatex>\(u\)</span>'s chronologically ordered interaction sequence. The sequential prediction task becomes:</p> <div class=arithmatex>\[\hat{r}_{u,i_{t+1}} = f(\mathbf{s}_u, i_{t+1}, \Theta)\]</div> <p>This formulation acknowledges that predicting what user <span class=arithmatex>\(u\)</span> will like next depends on their entire interaction sequence, not just their static preferences.</p> <p>The challenge lies in learning function <span class=arithmatex>\(f\)</span> that can capture complex temporal dependencies, handle variable-length sequences, and understand how user preferences evolve over time. This is where BERT4Rec's transformer architecture provides a breakthrough solution.</p> <h2 id=why-bidirectional-context-revolutionizes-sequential-understanding>Why Bidirectional Context Revolutionizes Sequential Understanding<a class=headerlink href=#why-bidirectional-context-revolutionizes-sequential-understanding title="Permanent link">&para;</a></h2> <p>Most sequential models process user interactions from left to right, predicting what comes next based on what came before. This approach seems intuitive since time moves forward, but it misses crucial information about user preferences.</p> <p>BERT4Rec takes a radically different approach inspired by BERT's success in natural language processing. Instead of only looking backward in time, it uses bidirectional attention to understand user preferences by considering the complete context around each interaction.</p> <p>Let me illustrate why this matters with a concrete example:</p> <p><strong>User Sequence</strong>: The Matrix → Love Actually → The Notebook → Blade Runner → Her</p> <p>A left-to-right model processing this sequence might interpret the romantic movies as a shift away from science fiction. But a bidirectional model can see both the earlier "Matrix" and later "Blade Runner" and "Her," recognizing that the user's interest in thoughtful science fiction persists across the romantic movie phase.</p> <p>Mathematically, instead of computing: <span class=arithmatex>\(<span class=arithmatex>\(p(i_t | i_1, i_2, \ldots, i_{t-1})\)</span>\)</span></p> <p>BERT4Rec computes: <span class=arithmatex>\(<span class=arithmatex>\(p(i_t | i_1, i_2, \ldots, i_{t-1}, i_{t+1}, \ldots, i_T)\)</span>\)</span></p> <p>This bidirectional conditioning enables much richer understanding of user preference patterns by leveraging the complete sequence context during training.</p> <h2 id=the-transformer-architecture-attention-as-preference-understanding>The Transformer Architecture: Attention as Preference Understanding<a class=headerlink href=#the-transformer-architecture-attention-as-preference-understanding title="Permanent link">&para;</a></h2> <p>The heart of BERT4Rec lies in its use of transformer architecture, specifically the multi-head attention mechanism. To understand how this works, let's think about what your mind does when deciding what to watch next.</p> <p>You don't give equal weight to every movie you've ever seen. Instead, you focus on recent viewings that indicate your current interests, memorable films that shaped your preferences, and movies that relate thematically to your current mood. Some past interactions matter more than others for predicting future preferences, and the relevance of different interactions changes based on context.</p> <p>The attention mechanism automates this selective focusing process. For each position in a user's interaction sequence, attention computes three types of representations:</p> <p><strong>Queries (Q)</strong>: What information am I looking for to understand this user's preferences? <strong>Keys (K)</strong>: What information is available from other movies in this user's history? <strong>Values (V)</strong>: What is the actual preference information at each position?</p> <p>The mathematical computation involves:</p> <div class=arithmatex>\[\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V\]</div> <p>The <span class=arithmatex>\(QK^T\)</span> operation computes similarity scores between the query at each position and keys from all other positions. The softmax function converts these scores into attention weights that sum to one, creating a probability distribution over sequence positions.</p> <p>Let's walk through what this means in practice. Suppose we're trying to understand a user's current preferences at the point where they watched "Blade Runner." The attention mechanism might assign high weights to: - Recent science fiction films (temporal relevance) - Movies with similar visual aesthetics (content similarity) - Films with philosophical themes (thematic consistency)</p> <p>The final representation combines information from all positions, weighted by these computed attention scores. This creates contextualized understanding that captures both the user's stable preferences and their current trajectory.</p> <h2 id=multi-head-attention-capturing-different-aspects-of-preference>Multi-Head Attention: Capturing Different Aspects of Preference<a class=headerlink href=#multi-head-attention-capturing-different-aspects-of-preference title="Permanent link">&para;</a></h2> <p>BERT4Rec uses multi-head attention, which runs several attention computations in parallel. Think of each attention head as focusing on different aspects of user preferences:</p> <ul> <li><strong>Head 1</strong>: Recent interactions and temporal patterns</li> <li><strong>Head 2</strong>: Genre preferences and content similarity </li> <li><strong>Head 3</strong>: Thematic coherence and narrative complexity</li> <li><strong>Head 4</strong>: Production quality and directorial style</li> </ul> <p>Mathematically, each head <span class=arithmatex>\(h\)</span> computes its own attention:</p> <div class=arithmatex>\[\text{head}_h = \text{Attention}(QW_h^Q, KW_h^K, VW_h^V)\]</div> <p>where <span class=arithmatex>\(W_h^Q\)</span>, <span class=arithmatex>\(W_h^K\)</span>, and <span class=arithmatex>\(W_h^V\)</span> are learned projection matrices specific to head <span class=arithmatex>\(h\)</span>. The outputs from all heads get concatenated and projected:</p> <div class=arithmatex>\[\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \ldots, \text{head}_H)W^O\]</div> <p>This multi-head approach enables the model to attend to different types of patterns simultaneously, creating richer understanding of user preferences than single-head attention could achieve.</p> <h2 id=the-masking-strategy-learning-through-contextual-prediction>The Masking Strategy: Learning Through Contextual Prediction<a class=headerlink href=#the-masking-strategy-learning-through-contextual-prediction title="Permanent link">&para;</a></h2> <p>BERT4Rec's training process uses a sophisticated masking strategy that teaches the model to understand user preferences through contextual prediction. Instead of simply predicting the next item in a sequence, the model learns to predict masked items based on bidirectional context.</p> <p>During training, we randomly mask certain movies in user interaction sequences and train the model to predict what the masked items should be. This creates a learning task that directly mirrors what we want the model to do: understand user preferences well enough to predict which movies would naturally fit into specific contexts.</p> <p>The masking process becomes particularly sophisticated for movie recommendation. We preferentially mask movies that users rated positively, since these represent the clearest preference signals. The model learns to identify patterns like:</p> <p><strong>Masked Sequence</strong>: The Matrix → [MASK] → Blade Runner → Her <strong>Learning Task</strong>: Predict that "Ghost in the Shell" or "Ex Machina" would fit the masked position</p> <p>The mathematical objective involves maximizing the likelihood of observed items at masked positions:</p> <div class=arithmatex>\[\mathcal{L} = -\sum_{i \in \text{masked}} \log p(i | \text{context})\]</div> <p>where the probability <span class=arithmatex>\(p(i | \text{context})\)</span> is computed using the bidirectional transformer representations.</p> <h2 id=content-feature-integration-bridging-collaborative-and-content-understanding>Content Feature Integration: Bridging Collaborative and Content Understanding<a class=headerlink href=#content-feature-integration-bridging-collaborative-and-content-understanding title="Permanent link">&para;</a></h2> <p>Your BERT4Rec implementation integrates the rich content features you developed during TMDB processing. This integration happens at the item representation level, where each movie gets represented by combining learned embeddings with explicit content features.</p> <p>For each movie <span class=arithmatex>\(i\)</span>, the input representation becomes:</p> <div class=arithmatex>\[\mathbf{h}_i^{(0)} = \mathbf{W}_{\text{item}} \cdot \text{one\_hot}(i) + \mathbf{W}_{\text{content}} \cdot \mathbf{c}_i + \mathbf{W}_{\text{pos}} \cdot \text{pos}_i\]</div> <p>where: - <span class=arithmatex>\(\mathbf{W}_{\text{item}} \cdot \text{one\_hot}(i)\)</span> represents learned collaborative embeddings - <span class=arithmatex>\(\mathbf{W}_{\text{content}} \cdot \mathbf{c}_i\)</span> projects your TMDB and text features - <span class=arithmatex>\(\mathbf{W}_{\text{pos}} \cdot \text{pos}_i\)</span> encodes the sequence position</p> <p>This integration strategy provides several crucial advantages. The model can understand preferences along multiple dimensions simultaneously: collaborative patterns learned from user behavior and content patterns derived from movie characteristics. When a user shows interest in Christopher Nolan films, the content features help the model understand that the relevant patterns involve complex narratives, high production values, and specific visual styles.</p> <p>The attention mechanism can then identify thematic connections, stylistic similarities, and content-based relationships that inform preference predictions. This enables recommendations of new releases that lack interaction history, discovery of niche films through content similarity, and understanding of why certain users gravitate toward specific types of content.</p> <h2 id=transformer-layers-building-hierarchical-understanding>Transformer Layers: Building Hierarchical Understanding<a class=headerlink href=#transformer-layers-building-hierarchical-understanding title="Permanent link">&para;</a></h2> <p>BERT4Rec stacks multiple transformer layers to build increasingly sophisticated representations of user preferences. Each layer can refine and enhance the representations learned by previous layers.</p> <p>The computation at each layer <span class=arithmatex>\(l\)</span> follows:</p> <div class=arithmatex>\[\mathbf{h}^{(l)} = \text{LayerNorm}(\mathbf{h}^{(l-1)} + \text{MultiHeadAttention}(\mathbf{h}^{(l-1)}))$$ $$\mathbf{h}^{(l)} = \text{LayerNorm}(\mathbf{h}^{(l)} + \text{FFN}(\mathbf{h}^{(l)}))\]</div> <p>where FFN represents a position-wise feed-forward network. The residual connections (the addition operations) enable information to flow directly from early layers to later layers, preventing the vanishing gradient problem that can plague deep networks.</p> <p>Think of each layer as adding a level of understanding: - <strong>Layer 1</strong>: Basic item similarities and recent interaction patterns - <strong>Layer 2</strong>: Thematic relationships and genre preferences<br> - <strong>Layer 3</strong>: Complex narrative preferences and stylistic patterns - <strong>Layer 4</strong>: Sophisticated preference logic and contextual understanding</p> <p>This hierarchical learning enables BERT4Rec to capture both simple patterns (like genre preferences) and complex relationships (like the connection between Christopher Nolan films and users who enjoy puzzle-like narratives).</p> <h2 id=training-dynamics-and-optimization-challenges>Training Dynamics and Optimization Challenges<a class=headerlink href=#training-dynamics-and-optimization-challenges title="Permanent link">&para;</a></h2> <p>Training BERT4Rec involves several sophisticated optimization considerations that differ from simpler recommendation models. The bidirectional nature of the model creates a complex parameter space where the model must learn to balance multiple competing objectives.</p> <p>The optimization landscape becomes challenging because the model must develop accurate understanding of individual user preferences while learning generalizable patterns that apply across different users and contexts. The masking strategy creates additional complexity because the model cannot simply memorize sequence patterns but must develop robust understanding that generalizes to new contexts.</p> <p>The learning rate scheduling becomes particularly important for transformer training. The model typically uses a warmup period with gradually increasing learning rates, followed by decay:</p> <div class=arithmatex>\[\text{lr}(t) = \frac{d_{\text{model}}^{-0.5} \cdot \min(t^{-0.5}, t \cdot \text{warmup\_steps}^{-1.5})}{\sqrt{\text{warmup\_steps}}}\]</div> <p>This scheduling helps the transformer converge to good solutions by preventing early training instability while enabling fine-tuning of learned representations in later epochs.</p> <h2 id=integration-with-your-two-tower-architecture>Integration with Your Two-Tower Architecture<a class=headerlink href=#integration-with-your-two-tower-architecture title="Permanent link">&para;</a></h2> <p>Understanding how BERT4Rec integrates with your two-tower model requires thinking about the complementary strengths each component brings to the complete recommendation pipeline. This integration represents one of the most sophisticated aspects of modern recommendation system design.</p> <p>Your two-tower model excels at efficiently scanning large catalogs to identify potentially relevant candidates. It operates at the scale of your complete movie database using fast similarity computations between learned user and item embeddings. This retrieval stage filters your 80,000+ movie catalog down to manageable candidate sets of 100-200 items within computational constraints suitable for real-time serving.</p> <p>BERT4Rec operates on these candidate sets, focusing its computational intensity on the ranking task where sophisticated understanding provides the most value. Instead of processing 80,000 items, BERT4Rec analyzes perhaps 100 carefully selected candidates, using its attention mechanisms and sequential understanding to determine optimal ordering.</p> <p>The mathematical pipeline involves two distinct but complementary prediction tasks:</p> <p><strong>Two-Tower Prediction</strong>: <span class=arithmatex>\(\text{score}_{\text{retrieval}}(u, i) = \mathbf{e}_u^T \mathbf{e}_i\)</span> <strong>BERT4Rec Prediction</strong>: <span class=arithmatex>\(\text{score}_{\text{ranking}}(u, i | \mathbf{s}_u) = \text{BERT4Rec}(\mathbf{s}_u, i)\)</span></p> <p>During recommendation generation, these models work sequentially: 1. Two-tower generates candidates based on embedding similarity 2. BERT4Rec ranks these candidates using sequential context and content features 3. The final recommendations represent the top-ranked items from this two-stage process</p> <p>This division of labor enables you to leverage the computational efficiency of two-tower retrieval while applying the sophisticated preference understanding of BERT4Rec where it matters most: distinguishing between good candidates and great candidates based on temporal user behavior patterns.</p> <h2 id=why-this-architecture-succeeds-for-movie-recommendation>Why This Architecture Succeeds for Movie Recommendation<a class=headerlink href=#why-this-architecture-succeeds-for-movie-recommendation title="Permanent link">&para;</a></h2> <p>Movie recommendation presents several unique characteristics that make BERT4Rec particularly well-suited compared to other sequential modeling approaches. Understanding these characteristics helps you appreciate why this architecture represents an optimal choice for your movie recommendation system.</p> <p>Movie consumption involves longer, more deliberate interaction sessions compared to domains like e-commerce browsing or music streaming. Users typically spend considerable time choosing what to watch, and their choices reflect thoughtful preferences rather than impulsive decisions. This deliberate nature means that sequential patterns in movie viewing carry strong predictive signals about user preferences.</p> <p>The temporal patterns in movie viewing align well with BERT4Rec's bidirectional modeling approach. Users often explore themes, directors, or genres across multiple viewings, creating coherent preference episodes that might span weeks or months. Your Netflix thumbs rating system provides particularly clear training signals that eliminate the ambiguity present in implicit feedback systems.</p> <p>The rich content features you developed from TMDB and EmbeddingGemma processing provide sophisticated item representations that enhance BERT4Rec's ability to understand preference patterns. Movies possess rich metadata including genre information, cast details, plot summaries, and production characteristics that enable content-based understanding beyond simple collaborative patterns.</p> <p>These characteristics combine to create an ideal environment for BERT4Rec's bidirectional attention mechanisms to learn meaningful patterns about user preference evolution, thematic exploration, and content-based similarity that drive effective movie recommendations.</p> <p>The integration of collaborative filtering signals from interaction sequences with rich content understanding creates a recommendation system that can handle both the discovery of new content and the refinement of preferences based on temporal user behavior patterns. This combination addresses the core challenges of movie recommendation: helping users discover films they'll enjoy while accounting for the evolving nature of taste and context that influences viewing decisions.</p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="September 26, 2025 18:54:36 UTC">September 26, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="September 26, 2025 18:54:36 UTC">September 26, 2025</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../models-overview/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Models Overview"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Models Overview </div> </div> </a> <a href=../semantic-search/ class="md-footer__link md-footer__link--next" aria-label="Next: Semantic Search"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Semantic Search </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 Movie Genie </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/your-username/movie-genie target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://pypi.org/project/movie-genie/ target=_blank rel=noopener title=pypi.org class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8"/></svg> </a> <a href=https://twitter.com/your-username target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.f55a23d4.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>