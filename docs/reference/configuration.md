# Configuration Reference

Complete reference for all configuration files in Movie Genie. This document explains every parameter, when to change them, and how they interact with each other.

---

## Configuration Files Overview

| File | Purpose | When to Modify |
|------|---------|----------------|
| `configs/semantic_search.yaml` | Semantic search engine settings | Changing embedding model, tuning search |
| `configs/data.yaml` | Data processing and embedding generation | Changing dataset, embedding model |
| `configs/bert4rec.yaml` | BERT4Rec model training | Training hyperparameters |
| `configs/two_tower.yaml` | Two-Tower model training | Training hyperparameters |
| `movie_genie/frontend/.env.development` | Frontend environment variables | API endpoints, feature flags |

---

## Semantic Search Configuration

**File**: `configs/semantic_search.yaml`

### Complete Configuration

```yaml
# Model and encoding
model_name: "sentence-transformers/all-MiniLM-L6-v2"
normalize_vectors: true
cache_size: 1000

# Data paths
movies_path: "data/processed/content_features.parquet"

# Search settings
default_results: 20
max_results: 100

# Reranking configuration
reranker:
  enabled: true
  type: "bert4rec"  # Options: bert4rec, two_tower, none
  model_path: "models/bert4rec/bert4rec_model.pth"
  data_artifacts_path: "models/bert4rec/data_artifacts.pkl"

  # Score combination weights
  semantic_weight: 0.6
  personalization_weight: 0.4

# Text preprocessing
abbreviations:
  "sci-fi": "science fiction"
  "rom-com": "romantic comedy"
  "ai": "artificial intelligence"
```

### Parameter Descriptions

#### Model Settings

**`model_name`** (string, required)
- **Description**: HuggingFace model identifier for text embeddings
- **Current**: `"sentence-transformers/all-MiniLM-L6-v2"` (384-dimensional)
- **Previous**: `"google/embeddinggemma-300M"` (768-dimensional) - DEPRECATED
- **Impact**: Changes embedding dimension and search quality
- **When to change**: Never (unless you have a better model)
- **After changing**: Must run `dvc repro content_features` to regenerate embeddings

**`normalize_vectors`** (boolean, default: true)
- **Description**: Whether to normalize embeddings to unit length
- **Recommendation**: Always `true` for cosine similarity
- **Impact**: Affects similarity score range and computation

**`cache_size`** (integer, default: 1000)
- **Description**: Number of queries to cache
- **Recommendation**: 1000-5000 for typical usage
- **Impact**: Memory usage vs. query speed

#### Data Paths

**`movies_path`** (string, required)
- **Description**: Path to parquet file containing movie metadata and embeddings
- **Default**: `"data/processed/content_features.parquet"`
- **Generated by**: `dvc repro content_features`
- **Must contain**: `text_embedding` column with 384-dim vectors

#### Search Settings

**`default_results`** (integer, default: 20)
- **Description**: Default number of results when `k` not specified
- **Range**: 1-100
- **Typical**: 10-20 for UI display

**`max_results`** (integer, default: 100)
- **Description**: Maximum allowed results per query
- **Purpose**: Prevent excessive computation
- **Recommendation**: 100-200

#### Reranking Configuration

**`reranker.enabled`** (boolean, default: true)
- **Description**: Whether to use ML-based reranking
- **Impact**: Personalization quality vs. speed
- **Set to `false`**: For faster, non-personalized search

**`reranker.type`** (string, options: "bert4rec" | "two_tower" | "none")
- **Description**: Which ML model to use for reranking
- **Current**: `"bert4rec"` (sequential recommendations)
- **Alternatives**:
  - `"two_tower"`: Content-based reranking
  - `"none"`: Disable reranking (faster)

**`reranker.semantic_weight`** (float, 0.0-1.0, default: 0.6)
- **Description**: Weight for semantic similarity score
- **Higher**: More emphasis on query match
- **Lower**: More emphasis on personalization

**`reranker.personalization_weight`** (float, 0.0-1.0, default: 0.4)
- **Description**: Weight for personalization score
- **Higher**: More user-specific results
- **Lower**: More generic relevant results
- **Note**: `semantic_weight + personalization_weight` should equal 1.0

#### Text Preprocessing

**`abbreviations`** (dict, optional)
- **Description**: Query text replacement mappings
- **Purpose**: Normalize common abbreviations
- **Example**: "sci-fi" â†’ "science fiction"
- **When to add**: Common search terms that should be expanded

---

## Data Processing Configuration

**File**: `configs/data.yaml`

### Complete Configuration

```yaml
data_sources:
  movielens:
    dataset_size: "ml-latest-small"  # Options: ml-latest-small, ml-25m
    cache_dir: "data/processed"

processing:
  force_reprocess: false     # Override cache when needed
  sequence_multiplier: 2.5   # Adaptive window scaling factor
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"  # Must match semantic_search.yaml
```

### Parameter Descriptions

#### Data Sources

**`data_sources.movielens.dataset_size`** (string)
- **Options**:
  - `"ml-latest-small"`: 100K ratings, 610 users, 9,742 movies (development)
  - `"ml-25m"`: 25M ratings, 162K users, 62K movies (production)
- **Current**: `"ml-latest-small"`
- **Impact**: Dataset size, memory usage, training time
- **After changing**: Run `dvc repro` to reprocess entire pipeline

**`data_sources.movielens.cache_dir`** (string)
- **Description**: Where to store processed data
- **Default**: `"data/processed"`
- **Recommendation**: Don't change unless you have storage constraints

#### Processing Settings

**`processing.force_reprocess`** (boolean, default: false)
- **Description**: Ignore cached data and reprocess from scratch
- **When to set `true`**:
  - After changing data transformations
  - After fixing data bugs
  - Testing pipeline changes
- **Warning**: Slow! Will regenerate all embeddings

**`processing.sequence_multiplier`** (float, default: 2.5)
- **Description**: Factor for adaptive window sizing in sequential data
- **Range**: 1.0-5.0
- **Higher**: Longer sequences (more context, slower training)
- **Lower**: Shorter sequences (less context, faster training)

**`processing.embedding_model`** (string, required)
- **Description**: Model for generating text embeddings
- **CRITICAL**: **Must match** `model_name` in `semantic_search.yaml`
- **Current**: `"sentence-transformers/all-MiniLM-L6-v2"`
- **After changing**: Run `dvc repro content_features`

---

## Frontend Environment Variables

**File**: `movie_genie/frontend/.env.development`

### Complete Configuration

```bash
# API Configuration
VITE_API_URL=http://127.0.0.1:5001/api

# Feature Flags (Real Data vs Mock Data)
# NOTE: These use Vite's import.meta.env, NOT process.env
# Logic: !== 'false' means default is TRUE (opt-out, not opt-in)
VITE_USE_REAL_POPULAR=true
VITE_USE_REAL_SEARCH=true
VITE_USE_REAL_RECOMMENDATIONS=true
VITE_USE_REAL_MOVIE_DETAILS=true
```

### Parameter Descriptions

#### API Configuration

**`VITE_API_URL`** (string, required)
- **Description**: Backend API base URL
- **Development**: `http://127.0.0.1:5001/api`
- **Production**: Update to production URL
- **Format**: No trailing slash

#### Feature Flags

**IMPORTANT**: Vite uses `import.meta.env`, NOT `process.env`!

All feature flags use **opt-out logic** (default = true):
```typescript
// In movieDataService.ts
const enabled = import.meta.env.VITE_USE_REAL_SEARCH !== 'false';
// If undefined: enabled = true
// If 'true': enabled = true
// If 'false': enabled = false
```

**`VITE_USE_REAL_POPULAR`** (string: "true" | "false")
- **Description**: Use real API for popular movies
- **Default**: `true`
- **Set to `"false"`**: Use mock data (for frontend development without backend)

**`VITE_USE_REAL_SEARCH`** (string: "true" | "false")
- **Description**: Use real API for search
- **Default**: `true`
- **Impact**: Semantic search vs. mock search results

**`VITE_USE_REAL_RECOMMENDATIONS`** (string: "true" | "false")
- **Description**: Use real API for personalized recommendations
- **Default**: `true`
- **Impact**: BERT4Rec recommendations vs. mock data

**`VITE_USE_REAL_MOVIE_DETAILS`** (string: "true" | "false")
- **Description**: Use real API for movie details
- **Default**: `true`
- **Impact**: Real metadata vs. mock data

---

## BERT4Rec Configuration

**File**: `configs/bert4rec.yaml`

### Key Parameters

```yaml
model:
  hidden_dim: 256        # Embedding dimension
  num_layers: 2          # Transformer layers
  num_heads: 4           # Attention heads
  dropout: 0.1           # Regularization

training:
  learning_rate: 0.001   # Optimizer learning rate
  num_epochs: 50         # Training iterations
  batch_size: 128        # Samples per batch
  mask_prob: 0.2         # Masking probability
```

**When to modify**: Only when training/fine-tuning BERT4Rec model

---

## Two-Tower Configuration

**File**: `configs/two_tower.yaml`

### Key Parameters

```yaml
model:
  embedding_dim: 128     # Embedding dimension
  hidden_dims: [256, 128] # Tower hidden layers

training:
  learning_rate: 0.001   # Optimizer learning rate
  num_epochs: 30         # Training iterations
  batch_size: 512        # Samples per batch
```

**When to modify**: Only when training/fine-tuning Two-Tower model

---

## Configuration Interactions

### Critical Dependencies

1. **Embedding Model Consistency** (CRITICAL!)
   ```yaml
   # These MUST match:
   configs/semantic_search.yaml:
     model_name: "sentence-transformers/all-MiniLM-L6-v2"

   configs/data.yaml:
     embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
   ```
   **Why**: Search engine expects same embeddings as stored in parquet
   **Symptom if mismatched**: "No valid text embeddings found" error

2. **Reranker Model Paths**
   ```yaml
   configs/semantic_search.yaml:
     reranker:
       model_path: "models/bert4rec/bert4rec_model.pth"
       data_artifacts_path: "models/bert4rec/data_artifacts.pkl"
   ```
   **Must exist**: Generated by `dvc repro bert4rec_training`
   **Symptom if missing**: Reranking disabled, warning in logs

3. **Dataset Size Consistency**
   ```yaml
   configs/data.yaml:
     dataset_size: "ml-latest-small"  # Must be same everywhere
   ```
   **Impact**: User ID range (1-610 for small, 1-162K for full)

---

## Common Configuration Scenarios

### Scenario 1: Change Embedding Model

```bash
# 1. Update both configs (they MUST match!)
vim configs/semantic_search.yaml  # Change model_name
vim configs/data.yaml              # Change embedding_model

# 2. Regenerate embeddings
dvc repro content_features

# 3. Restart backend
dvc repro backend_server

# 4. Test
curl "http://127.0.0.1:5001/api/search/semantic?q=test&k=5"
```

### Scenario 2: Disable Personalization (Faster Search)

```yaml
# configs/semantic_search.yaml
reranker:
  enabled: false  # Disable BERT4Rec reranking
```

Restart backend - search will be faster but not personalized.

### Scenario 3: Frontend Development Without Backend

```bash
# movie_genie/frontend/.env.development
VITE_USE_REAL_POPULAR=false
VITE_USE_REAL_SEARCH=false
VITE_USE_REAL_RECOMMENDATIONS=false
VITE_USE_REAL_MOVIE_DETAILS=false
```

Now frontend uses mock data, no backend needed.

### Scenario 4: Switch to Production Dataset

```yaml
# configs/data.yaml
data_sources:
  movielens:
    dataset_size: "ml-25m"  # 25M ratings
```

**Warning**: Takes hours to process! Plan accordingly.

---

## Configuration Validation

### Check if Configs are Consistent

```bash
# 1. Check embedding model matches
grep model_name configs/semantic_search.yaml
grep embedding_model configs/data.yaml
# Output should be identical

# 2. Check dataset size is consistent
grep dataset_size configs/data.yaml
grep dataset_size configs/bert4rec.yaml  # If it exists

# 3. Verify model files exist
ls -la models/bert4rec/
ls -la models/two_tower/

# 4. Check parquet file has embeddings
python3 -c "
import pandas as pd
import numpy as np
df = pd.read_parquet('data/processed/content_features.parquet')
print(f'Movies: {len(df)}')
print(f'Has embeddings: {\"text_embedding\" in df.columns}')
if 'text_embedding' in df.columns:
    emb = np.array(df['text_embedding'].iloc[0])
    print(f'Embedding dim: {len(emb)}')
"
```

---

## Troubleshooting Configuration Issues

### Issue: "No valid text embeddings found"

**Cause**: Embedding dimension mismatch or missing embeddings

**Fix**:
```bash
# Check dimension
python3 -c "import pandas as pd; import numpy as np; df = pd.read_parquet('data/processed/content_features.parquet'); print(np.array(df['text_embedding'].iloc[0]).shape)"

# Should be (384,) for all-MiniLM-L6-v2
# If different, regenerate:
dvc repro content_features
```

### Issue: Environment Variables Not Working

**Cause**: Using `process.env` instead of `import.meta.env` in Vite

**Fix**: All Vite env vars use `import.meta.env.VITE_*`, not `process.env.VITE_*`

### Issue: Search Returns Empty Results

**Cause**: `movies_path` pointing to wrong file

**Fix**:
```bash
# Verify path in config
grep movies_path configs/semantic_search.yaml

# Check file exists
ls -la data/processed/content_features.parquet
```

---

*Last Updated: January 2025*
*See also: docs/machine-learning/semantic-search.md for detailed search configuration*
